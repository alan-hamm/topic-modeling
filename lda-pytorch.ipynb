{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code was written using CDC AI Chatbot. A variety of prompts were used, including questions and prompts to \n",
    "    correct bugs, memory issues(ie too little resources available), generate comments, etc.\n",
    "\n",
    "maintenance: alan hamm(pqn7)\n",
    "apr 2024\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # PyTorch library for deep learning and GPU acceleration\n",
    "from torch.utils.data import DataLoader  # Provides an iterator over a dataset for efficient batch processing\n",
    "from tqdm import tqdm  # Creates progress bars to visualize the progress of loops or tasks\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # Converts text documents into numerical representations\n",
    "from sklearn.decomposition import LatentDirichletAllocation  # Implements Latent Dirichlet Allocation (LDA) for topic modeling\n",
    "from gensim.models import LdaModel  # Implements LDA for topic modeling using the Gensim library\n",
    "from gensim.corpora import Dictionary  # Represents a collection of text documents as a bag-of-words corpus\n",
    "import os  # Provides functions for interacting with the operating system, such as creating directories\n",
    "import pickle  # Allows objects to be serialized and deserialized to/from disk\n",
    "import itertools  # Provides various functions for efficient iteration and combination of elements\n",
    "import numpy as np  # Library for numerical computing in Python, used for array operations and calculations\n",
    "from time import time  # Measures the execution time of code snippets or functions\n",
    "import pprint as pp  # Pretty-printing library, used here to format output in a readable way\n",
    "import multiprocessing\n",
    "import pickle\n",
    "#import dask.array as da\n",
    "#from dask.diagnostics import ProgressBar\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of number of topics for LDA and step size\n",
    "start_topics = 50\n",
    "end_topics = 150\n",
    "step_size = 5\n",
    "\n",
    "# Specify output directories for log file, model outputs, and images generated.\n",
    "log_dir = \"C:/_harvester/data/lda-models/2010s_html.json/\"\n",
    "model_dir = \"C:/_harvester/data/lda-models/2010s_html.json/lda-models/\"\n",
    "image_dir = \"C:/_harvester/data/lda-models/2010s_html.json/visuals/\"\n",
    "\n",
    "# Create directories if they don't exist.\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(image_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 1\n",
      "\n",
      "GPU Device 0 Properties:\n",
      "Device Name: NVIDIA RTX A3000 12GB Laptop GPU\n",
      "Total Memory: 12.00 GB\n",
      "Multiprocessor Count: 32\n",
      "CUDA Capability Major Version: 8\n",
      "CUDA Capability Minor Version: 6\n",
      "PyTorch is using the GPU.\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {num_gpus}\")\n",
    "    \n",
    "    for i in range(num_gpus):\n",
    "        # Get the properties of each GPU device\n",
    "        gpu_properties = torch.cuda.get_device_properties(i)\n",
    "        \n",
    "        print(f\"\\nGPU Device {i} Properties:\")\n",
    "        print(f\"Device Name: {gpu_properties.name}\")\n",
    "        print(f\"Total Memory: {gpu_properties.total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"Multiprocessor Count: {gpu_properties.multi_processor_count}\")\n",
    "        print(f\"CUDA Capability Major Version: {gpu_properties.major}\")\n",
    "        print(f\"CUDA Capability Minor Version: {gpu_properties.minor}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# verify if CUDA is being used or the CPU\n",
    "if device is not None:\n",
    "    # Check if PyTorch is currently using the GPU\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        print(\"PyTorch is using the GPU.\")\n",
    "    else:\n",
    "        print(\"PyTorch is using the CPU.\")\n",
    "else:\n",
    "    print(\"The device is neither using the GPU nor CPU. An error has ocurred.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() - 1 # Count the number of cores in a computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameter `alpha` in Latent Dirichlet Allocation (LDA) represents the concentration parameter of the Dirichlet \n",
    "# prior distribution for the topic-document distribution.\n",
    "# It controls the sparsity of the resulting document-topic distributions.\n",
    "\n",
    "# A lower value of `alpha` leads to sparser distributions, meaning that each document is likely to be associated with fewer topics.\n",
    "# Conversely, a higher value of `alpha` encourages documents to be associated with more topics, resulting in denser distributions.\n",
    "\n",
    "# The choice of `alpha` affects the balance between topic diversity and document specificity in LDA modeling.\n",
    "alpha_values = np.arange(0.01, 1, 0.3).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Latent Dirichlet Allocation (LDA) topic analysis, the beta parameter represents the concentration \n",
    "# parameter of the Dirichlet distribution used to model the topic-word distribution. It controls the \n",
    "# sparsity of topics by influencing how likely a given word is to be assigned to a particular topic.\n",
    "\n",
    "# A higher value of beta encourages topics to have a more uniform distribution over words, resulting in more \n",
    "# general and diverse topics. Conversely, a lower value of beta promotes sparser topics with fewer dominant words.\n",
    "\n",
    "# The choice of beta can impact the interpretability and granularity of the discovered topics in LDA.\n",
    "beta_values = np.arange(0.01, 1, 0.3).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_threshold_values = np.arange(0.001, 0.011, 0.001).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your dataset as a list of a list of tokenized sentences or load data from a file\n",
    "with open(r\"C:\\_harvester\\data\\lda-models\\2010s_html.json\\word2vec-2010s\\tokenized-texts-out\\tokenized_sents-w-bigrams.pkl\", \"rb\") as fp:\n",
    "    texts_out = pickle.load(fp)\n",
    "\n",
    "# Convert tokenized sentences to text documents by joining tokens with space separator\n",
    "documents = [' '.join(tokens) for tokens in texts_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Begin the vectorization...'\n",
      "'Vectorization completed in 0.08 minutes.'\n"
     ]
    }
   ],
   "source": [
    "# Convert text data to numerical representation using CountVectorizer\n",
    "pp.pprint(\"Begin the vectorization...\")\n",
    "started = time()\n",
    "\n",
    "# CountVectorizer is a class in scikit-learn used to convert text documents into numerical representations.\n",
    "# It builds a vocabulary of known words from the text data and transforms each document into a sparse matrix\n",
    "# representing the frequency of each word in the document.\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "\n",
    "# The fit_transform() method of CountVectorizer performs two steps:\n",
    "# 1. It learns the vocabulary from the input documents and assigns a unique integer index to each word in the vocabulary.\n",
    "# 2. It transforms the input documents into a sparse matrix representation, where each row corresponds to a document,\n",
    "#    and each column represents the count of a specific word in that document.\n",
    "# The resulting X is a sparse matrix (specifically, a scipy.sparse.csr_matrix) where each row represents a document,\n",
    "# and each column represents a unique word in the vocabulary. The values in X indicate the frequency of each word in\n",
    "# the corresponding document.\n",
    "# Note: The fit_transform() method both fits the model to the data (learns vocabulary) and transforms it (creates matrix).\n",
    "X = vectorizer.fit_transform(documents) # Convert text documents into numerical representations using CountVectorizer\n",
    "pp.pprint(f\"Vectorization completed in {round((time() - started) / 60, 2) } minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create COO format sparse tensor from the sparse matrix and move it to the device\n",
    "\n",
    "The following code creates a COO (Coordinate) format sparse tensor from a given sparse matrix, represented by X. \n",
    "This conversion is performed to optimize storage and computation efficiency when working with large-scale data, \n",
    "especially on devices like GPUs that offer parallel processing capabilities.\n",
    "\n",
    "To create the COO format sparse tensor, several steps are involved:\n",
    "1. Extracting the row and column indices of non-zero elements in the sparse matrix X using `nonzero()` method.\n",
    "2. Stacking these row and column indices vertically to create a 2D numpy array where each column represents an index pair.\n",
    "3. Converting this index pairs numpy array into a PyTorch tensor, ensuring that the data type is set as long integer.\n",
    "4. Extracting the non-zero values from the sparse matrix X using `.data` attribute.\n",
    "5. Converting these non-zero values numpy array into a PyTorch tensor, ensuring that the data type is set as float.\n",
    "6. Obtaining the shape of the sparse matrix X as a tuple representing (number of rows, number of columns).\n",
    "7. Creating a `torch.Size` object encapsulating the shape information for creating a COO format sparse tensor.\n",
    "\n",
    "Finally, all these components - COO indices, values, and shape - are used to create a COO format sparse tensor \n",
    "using `torch.sparse_coo_tensor()`. The resulting tensor is then moved to the specified device (e.g., GPU) \n",
    "using `.to(device)` for efficient computation if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Begin creation of sparse tensor...'\n",
      "'Create COO format sparse tensor completed in 0.0 minutes.'\n"
     ]
    }
   ],
   "source": [
    "# Create COO format sparse tensor from the sparse matrix and move it to the device\n",
    "pp.pprint(\"Begin creation of sparse tensor...\")\n",
    "started = time()\n",
    "\n",
    "# The purpose of this code is to create a COO (Coordinate) format sparse tensor from a given sparse matrix, represented by X.\n",
    "# In this specific line, we are extracting the indices of non-zero elements in the sparse matrix X using `nonzero()` method.\n",
    "# The `nonzero()` method returns a tuple of arrays, where each array represents the indices of non-zero elements along a particular dimension.\n",
    "# np.vstack() function vertically stacks these arrays obtained from `nonzero()` to create a 2D array where each column represents the row and \n",
    "# column indices of a non-zero element.\n",
    "# torch.from_numpy() converts this 2D numpy array into a PyTorch tensor. We use `.long()` to ensure that the data type is set as long integer.\n",
    "# Finally, `.to(device)` moves the resulting tensor to the specified device (e.g., GPU) for efficient computation if available.\n",
    "# This conversion to COO format and moving it to the device is often necessary when working with large sparse matrices in deep learning or \n",
    "# other computations.\n",
    "# It allows for efficient storage and computation on devices like GPUs, which can significantly speed up operations involving large-scale data.\n",
    "coo_indices = torch.from_numpy(np.vstack((X.nonzero()[0], X.nonzero()[1]))).long().to(device)\n",
    "\n",
    "\n",
    "# The purpose of this code is to create a COO (Coordinate) format sparse tensor from a given sparse matrix, represented by X, \n",
    "# specifically for the values of non-zero elements.\n",
    "# In this specific line, we are extracting the non-zero values from the sparse matrix X using `.data` attribute.\n",
    "# `X.data` returns an array containing only the non-zero values of X.\n",
    "# torch.from_numpy() converts this numpy array into a PyTorch tensor. We use `.float()` to ensure that the data type is set as float.\n",
    "# Finally, `.to(device)` moves the resulting tensor to the specified device (e.g., GPU) for efficient computation if available.\n",
    "# This conversion to COO format and moving it to the device is often necessary when working with large sparse matrices in deep \n",
    "# learning or other computations.\n",
    "# It allows for efficient storage and computation on devices like GPUs, which can significantly speed up operations involving large-scale data.\n",
    "coo_values = torch.from_numpy(X.data).float().to(device)\n",
    "\n",
    "\n",
    "# The purpose of this code is to create a `torch.Size` object representing the shape of a COO (Coordinate) format sparse tensor.\n",
    "# In this specific line, we are creating a `torch.Size` object using `X.shape`.\n",
    "# `X.shape` returns a tuple representing the shape of the sparse matrix X, where the first element is the number of rows and the second \n",
    "# element is the number of columns.\n",
    "# The resulting `torch.Size` object, `coo_shape`, encapsulates this shape information.\n",
    "# This step is needed when creating a COO format sparse tensor because it requires specifying the shape of the resulting tensor.\n",
    "# By obtaining and storing this shape information in `coo_shape`, we can ensure that our COO format sparse tensor has the correct dimensions.\n",
    "# Having accurate shape information is crucial for performing operations on tensors and ensuring compatibility with other tensors or operations \n",
    "# in subsequent steps.\n",
    "coo_shape = torch.Size(X.shape)\n",
    "\n",
    "\n",
    "# The purpose of this code is to create a COO (Coordinate) format sparse tensor from the given COO indices, values, and shape.\n",
    "# It also moves the resulting tensor to the specified device (e.g., GPU) for efficient computation if available.\n",
    "# In this specific line, we are using `torch.sparse_coo_tensor()` to create a sparse tensor in COO format.\n",
    "# The function takes three arguments:\n",
    "# - `coo_indices`: The indices of non-zero elements in the sparse tensor.\n",
    "# - `coo_values`: The values corresponding to each index in `coo_indices`.\n",
    "# - `coo_shape`: The shape of the resulting sparse tensor.\n",
    "# Finally, `.to(device)` moves the resulting tensor to the specified device (e.g., GPU) for efficient computation if available.\n",
    "# This step is needed when working with large sparse matrices in deep learning or other computations.\n",
    "# Sparse tensors allow us to efficiently represent and operate on matrices that have a significant number of zero elements,\n",
    "# which can be common in many real-world datasets. By creating a COO format sparse tensor and moving it to a device like GPU,\n",
    "# we can perform computations more efficiently and take advantage of parallel processing capabilities offered by GPUs.\n",
    "X_tensor = torch.sparse_coo_tensor(coo_indices, coo_values, coo_shape).to(device)\n",
    "pp.pprint(f\"Create COO format sparse tensor completed in {round((time() - started) / 60, 2) } minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Begin the sklearn LDA modeling...'\n",
      "'The sklearn LDA modelling completed in 0.0 minutes.'\n",
      "'Fit the model on the data...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109953b6647c4fd6afdb626bb4bfb46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training scikit-learn LDA with 50 topics:   0%|          | 0/26047 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[38;5;66;03m# Reshape the input array\u001b[39;00m\n\u001b[0;32m     68\u001b[0m             reshaped_array \u001b[38;5;241m=\u001b[39m dense_b_cpu\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m             \u001b[43mlda_model_sklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreshaped_array\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass the reshaped array to partial_fit\u001b[39;00m\n\u001b[0;32m     72\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Save the output using pickle\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:617\u001b[0m, in \u001b[0;36mLatentDirichletAllocation.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mas\u001b[39;00m parallel:\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx_slice \u001b[38;5;129;01min\u001b[39;00m gen_batches(n_samples, batch_size):\n\u001b[1;32m--> 617\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_em_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx_slice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtotal_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_update\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:524\u001b[0m, in \u001b[0;36mLatentDirichletAllocation._em_step\u001b[1;34m(self, X, total_samples, batch_update, parallel)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"EM update for 1 iteration.\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \n\u001b[0;32m    499\u001b[0m \u001b[38;5;124;03mupdate `_component` by batch VB or online VB.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;124;03m    Unnormalized document topic distribution.\u001b[39;00m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# E-step\u001b[39;00m\n\u001b[1;32m--> 524\u001b[0m _, suff_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcal_sstats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;66;03m# M-step\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_update:\n",
      "File \u001b[1;32mc:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:467\u001b[0m, in \u001b[0;36mLatentDirichletAllocation._e_step\u001b[1;34m(self, X, cal_sstats, random_init, parallel)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parallel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 467\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_update_doc_distribution\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx_slice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp_dirichlet_component_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoc_topic_prior_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_doc_update_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean_change_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcal_sstats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx_slice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen_even_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;66;03m# merge result\u001b[39;00m\n\u001b[0;32m    481\u001b[0m doc_topics, sstats_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults)\n",
      "File \u001b[1;32mc:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import pyLDAvis\n",
    "# Create a Gensim Dictionary from the tokenized sentences\n",
    "dictionary = Dictionary(texts_out)\n",
    "\n",
    "# here is a custom method to be used to avoid this runtime error...\n",
    "# RuntimeError: Batches of sparse tensors are not currently supported by the default collate_fn; \n",
    "def custom_collate(batch):\n",
    "    # Coalesce and concatenate the entire batch of sparse tensors\n",
    "    coalesced_batch = torch.cat([b.coalesce().unsqueeze(0) for b in batch], dim=0)\n",
    "    return coalesced_batch\n",
    "\n",
    "def coherence_score(X, topics, metric='c_v', vectorizer=None):\n",
    "    # Convert X to a list of documents\n",
    "    documents = [list(doc) for doc in X]\n",
    "\n",
    "    # Create a dictionary and corpus from the documents\n",
    "    dictionary = gensim.corpora.Dictionary(documents)\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "\n",
    "    # Create a topic model using the given topics\n",
    "    topic_model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=len(set(topics)), random_state=42)\n",
    "    \n",
    "    # Compute the coherence score using the CoherenceModel\n",
    "    coherence_model = CoherenceModel(model=topic_model, texts=documents, dictionary=dictionary, coherence=metric)\n",
    "    \n",
    "    return coherence_model.get_coherence()\n",
    "\n",
    "for n_topics in range(start_topics, end_topics + 1, step_size):\n",
    "    ################################\n",
    "    #   MODEL WITH SCIKIT- LEARN   #\n",
    "    ################################\n",
    "    # Initialize LDA model using scikit-learn\n",
    "    pp.pprint(\"Begin the sklearn LDA modeling...\")\n",
    "    started = time()\n",
    "\n",
    "    # Convert text documents into a matrix of token counts using Dask array\n",
    "    #X_dask = da.from_array(X.toarray(), chunks=(7500, X.shape[1]))# X is the vectorized documents\n",
    "\n",
    "    # n_jobs is an integer, specifying the maximum number of concurrently running workers. If 1 is given, \n",
    "    # no joblib parallelism is used at all, which is useful for debugging. If set to -1, all CPUs are \n",
    "    # used. For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. For example with n_jobs=-2, all CPUs but one are used.\n",
    "    lda_model_sklearn = LatentDirichletAllocation(n_components=n_topics, learning_method='online', n_jobs=-2)\n",
    "    pp.pprint(f\"The sklearn LDA modelling completed in {round((time() - started) / 60, 2) } minutes.\")\n",
    "\n",
    "    # Transfer the trained model to GPU if available\n",
    "    #pp.pprint(\"Begin transfer of trained model to GPU if available...\")\n",
    "    #if torch.cuda.is_available():\n",
    "    #    lda_model_torch = lda_model_sklearn.transform(X_tensor.to_dense().to(device))\n",
    "    #    pp.pprint(\"The trained model was successfully transferred to the GPU\")\n",
    "    #else:\n",
    "    #    lda_model_torch = lda_model_sklearn.transform(X_tensor.to_dense())\n",
    "    #    pp.pprint(\"The trained model was not transferred to the GPU\")\n",
    "\n",
    "    # Fit the model on your data\n",
    "    pp.pprint(\"Fit the model on the data...\")\n",
    "    started = time()\n",
    "    # Train scikit-learn LDA model with progress bar visualization\n",
    "    dataloader_sklearn = DataLoader(X_tensor, batch_size=16, shuffle=True, collate_fn=custom_collate)\n",
    "\n",
    "    with tqdm(total=len(dataloader_sklearn), desc=f\"Training scikit-learn LDA with {n_topics} topics\", leave=False) as pbar:\n",
    "        for batch in dataloader_sklearn:\n",
    "            # Perform partial_fit on each sparse tensor in the batch\n",
    "            for b in batch:\n",
    "                dense_b = b.to_dense()  # Convert sparse tensor to dense tensor\n",
    "                dense_b_cpu = dense_b.cpu()  # Copy dense tensor from GPU to CPU\n",
    "                    \n",
    "                # Reshape the input array\n",
    "                reshaped_array = dense_b_cpu.numpy().reshape(-1, 1)\n",
    "                    \n",
    "                lda_model_sklearn.partial_fit(reshaped_array)  # Pass the reshaped array to partial_fit\n",
    "\n",
    "            pbar.update(1)\n",
    "        \n",
    "    # Save the output using pickle\n",
    "    with open(f\"C:/_harvester/data/lda-models/2010s_html.json/sklearn-fit-output/fit-output-{n_topics}.pkl\", 'wb') as file:\n",
    "        pickle.dump(lda_model_sklearn, file)\n",
    "    pp.pprint(f\"Model fitting completed in {round((time() - started) / 60, 2) } minutes.\")\n",
    "\n",
    "    # Set the topic-word distributions of the scikit-learn LDA model to random values\n",
    "    pp.pprint(\"Begin set the topic-word distributions of the scikit-learn LDA model to random values\")\n",
    "    started = time()\n",
    "    lda_model_sklearn.components_ = torch.randn((n_topics, X.shape[1]), device=device)\n",
    "    pp.pprint(f\"Set the topic-word distributions completed in {round((time() - started) / 60, 2) } minutes.\")\n",
    "\n",
    "    # Get topic-word distributions from trained scikit-learn LDA model\n",
    "    pp.pprint(\"Begin get topic-word distributions from trained scikit-learn LDA model\")\n",
    "    started = time()\n",
    "    topic_word_distributions_sklearn = lda_model_sklearn.components_\n",
    "    pp.pprint(f\"Get of topic-word distributions completed in {round((time() - started) / 60, 2) } minutes.\")\n",
    "                    \n",
    "    # Save the generated scikit-learn LDA model\n",
    "    model_filename = os.path.join(model_dir, f\"lda_model_sklearn_{n_topics}_topics.model\")\n",
    "    started = time()\n",
    "    torch.save(lda_model_sklearn, model_filename)\n",
    "    pp.pprint(f\"Model saving completed in {round(time() - started, 2)} seconds.\")\n",
    "\n",
    "    ###########################\n",
    "    #   MODEL WITH GENSIM     #\n",
    "    ###########################\n",
    "    for alpha, beta, gamma_threshold in itertools.product(alpha_values, beta_values, gamma_threshold_values):\n",
    "\n",
    "\n",
    "        # Train Gensim LDA model with progress bar visualization\n",
    "        corpus = [dictionary.doc2bow(doc) for doc in texts_out]\n",
    "        \n",
    "        #pbar_gensim = tqdm(total=len(corpus), desc=f\"Training Gensim LDA with {n_topics} topics\", leave=False)\n",
    "        \n",
    "        started = time()\n",
    "        lda_model_gensim = LdaModel(corpus=corpus, \n",
    "                                    id2word=dictionary, \n",
    "                                    num_topics=n_topics,\n",
    "                                    alpha=alpha, \n",
    "                                    eta=beta, \n",
    "                                    random_state=75,\n",
    "                                    passes=10,\n",
    "                                    chunksize=int(len(corpus)/cores+1),\n",
    "                                    gamma_threshold=gamma_threshold, \n",
    "                                    per_words_topics=True).to(device)\n",
    "        \n",
    "        # Get the total number of iterations\n",
    "        total_iterations = lda_model_gensim.passes * len(corpus)\n",
    "\n",
    "        # Create a progress bar with total iterations\n",
    "        with tqdm(total=total_iterations, desc=\"Training LDA model\", leave=False) as pbar:\n",
    "            # Iterate over each pass and corpus\n",
    "            for i in range(lda_model_gensim.passes):\n",
    "                for doc in corpus:\n",
    "                    # Train the LDA model on each document\n",
    "                    lda_model_gensim.update([doc])\n",
    "                    \n",
    "                    # Update the progress bar\n",
    "                    pbar.update(1)\n",
    "\n",
    "        pp.pprint(f\"Gensim LDA model for {n_topics} topics completed in {round((time() - started) / 60, 2) } minutes.\")\n",
    "\n",
    "        convergence_score = lda_model_gensim.bound(corpus)\n",
    "\n",
    "        perplexity_score = lda_model_gensim.log_perplexity(corpus)\n",
    "\n",
    "        #pbar_gensim.close()\n",
    "\n",
    "        # Get topic-word distributions from trained Gensim LDA model\n",
    "        pp.pprint(\"Begin get topic-word distributions from trained Gensim LDA model\")\n",
    "        started = time()\n",
    "        topic_word_distributions_gensim = lda_model_gensim.get_topics()\n",
    "        pp.pprint(f\"Get of topic-word distributions completed in {round((time() - started) / 60, 2) } minutes.\")\n",
    "\n",
    "        # Compare metrics and update best model if necessary\n",
    "        pp.pprint(\"Begin comparison of metrics and updating of model if necessary\")\n",
    "        c_v_score_sklearn = coherence_score(X=X.toarray(), topics=topic_word_distributions_sklearn.argmax(axis=1), metric='c_v', vectorizer=vectorizer)\n",
    "        pp.pprint(f\"Metric comparison completed in {round((time() - started) / 60, 2) } minutes.\")\n",
    "    \n",
    "        c_v_score_gensim = 0\n",
    "        pbar_coherence = tqdm(total=len(texts_out), desc=\"Calculating Coherence Value - Gensim\")\n",
    "        \n",
    "        for doc in texts_out:\n",
    "            bow = dictionary.doc2bow(doc)\n",
    "            c_v_score_gensim += coherence_score(topics=lda_model_gensim.get_document_topics(bow), texts=[doc], dictionary=dictionary, coherence='c_v')\n",
    "            pbar_coherence.update(1)\n",
    "            \n",
    "        pbar_coherence.close()\n",
    "            \n",
    "        c_v_score_gensim /= len(texts_out)\n",
    "\n",
    "        print(f\"Comparison of scikit-learn LDA and Gensim LDA with {n_topics}:\")\n",
    "        print(f\"Coherence Value (c_v) - scikit-learn: {c_v_score_sklearn}\")\n",
    "        print(f\"Coherence Value (c_v) - Gensim: {c_v_score_gensim}\")\n",
    "\n",
    "        # Save the best Gensim LDA model\n",
    "        best_model_gensim_filename = os.path.join(model_dir, f\"best_model_gensim_{n_topics}_topics.model\")\n",
    "        lda_model_gensim.save(best_model_gensim_filename)\n",
    "\n",
    "        # Generate and save a visualization for the best Gensim LDA model\n",
    "        vis_data = pyLDAvis.gensim.prepare(lda_model_gensim, corpus, dictionary)\n",
    "        vis_html_filename = os.path.join(image_dir, f\"lda_visualization_{n_topics}_topics.html\")\n",
    "        pyLDAvis.save_html(vis_data, vis_html_filename)\n",
    "\n",
    "        # Log metrics to a file\n",
    "        log_filename = os.path.join(log_dir, \"lda_metrics.log\")\n",
    "\n",
    "        with open(log_filename, 'a') as log_file:\n",
    "            log_file.write(f\"Number of Topics: {n_topics}\\n\")\n",
    "            log_file.write(f\"Alpha: {alpha}\\n\")\n",
    "            log_file.write(f\"Beta: {beta}\\n\")\n",
    "            log_file.write(f\"Gamma Threshold: {gamma_threshold}\\n\")\n",
    "            log_file.write(f\"Coherence Value (c_v) - scikit-learn: {c_v_score_sklearn}\\n\")\n",
    "            log_file.write(f\"Coherence Value (c_v) - Gensim: {c_v_score_gensim}\\n\")\n",
    "            log_file.write(f\"Convergence Score - Gensim: {convergence_score}\\n\")\n",
    "            log_file.write(f\"Log Perplexity - Gensim: {perplexity_score}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate visualizations for each saved LDA model\n",
    "for n_topics in range(start_topics, end_topics + 1, step_size):\n",
    "    \n",
    "        # Load the saved LDA model\n",
    "    model_filename = os.path.join(model_dir, f\"lda_model_{n_topics}_topics.pth\")\n",
    "    lda_model = torch.load(model_filename)\n",
    "\n",
    "    # Generate pyLDAvis visualization\n",
    "    vis_data = pyLDAvis.sklearn.prepare(lda_model, X.toarray(), vectorizer)\n",
    "    \n",
    "     # Save pyLDAvis visualization as HTML file\n",
    "     vis_html_filename = os.path.join(model_dir, f\"lda_visualization_{n_topics}_topics.html\")\n",
    "     pyLDAvis.save_html(vis_data, vis_html_filename)\n",
    "\n",
    "     # Generate t-SNE plot for topic-word distributions\n",
    "     tsne_plot(lda_model.components_, vectorizer.get_feature_names(), n_topics)\n",
    "\n",
    "     # Generate word cloud for each topic\n",
    "     for topic_idx in range(n_topics):\n",
    "         generate_word_cloud(lda_model.components_[topic_idx], vectorizer.get_feature_names(), topic_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(topic_word_distributions, feature_names, n_topics):\n",
    "    \"\"\"\n",
    "    Generates a t-SNE plot for the given topic-word distributions.\n",
    "    \n",
    "    Args:\n",
    "        topic_word_distributions (ndarray): Topic-word distributions from LDA model.\n",
    "        feature_names (list): List of feature names from CountVectorizer.\n",
    "        n_topics (int): Number of topics in LDA model.\n",
    "    \"\"\"\n",
    "    tsne = TSNE(n_components=2)\n",
    "    tsne_results = tsne.fit_transform(topic_word_distributions.T)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for i in range(n_topics):\n",
    "        plt.scatter(tsne_results[:, 0], tsne_results[:, 1], label=f\"Topic {i+1}\")\n",
    "        \n",
    "        for j, txt in enumerate(feature_names):\n",
    "            plt.annotate(txt, (tsne_results[j, 0], tsne_results[j, 1]))\n",
    "            \n",
    "    plt.title(\"t-SNE Plot of Topic-Word Distributions\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_cloud(topic_distribution, feature_names, topic_idx):\n",
    "   \"\"\"\n",
    "   Generates a word cloud based on the given topic distribution and feature names.\n",
    "\n",
    "   Args:\n",
    "       topic_distribution (ndarray): Topic distribution from LDA model.\n",
    "       feature_names (list): List of feature names from CountVectorizer.\n",
    "       topic_idx (int): Index of the topic.\n",
    "   \"\"\"\n",
    "   # Create a dictionary of words and their corresponding weights in the topic distribution\n",
    "   word_weights = {feature_names[i]: weight for i, weight in enumerate(topic_distribution)}\n",
    "\n",
    "   # Generate word cloud visualization\n",
    "   wc = WordCloud(background_color='white')\n",
    "   wc.generate_from_frequencies(word_weights)\n",
    "\n",
    "   # Plot the word cloud\n",
    "   plt.figure(figsize=(8, 6))\n",
    "   plt.imshow(wc, interpolation='bilinear')\n",
    "   plt.axis('off')\n",
    "   plt.title(f\"Word Cloud for Topic {topic_idx + 1}\")\n",
    "   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "def compare_models_sklearn_gensim(sklearn_models, gensim_models, data):\n",
    "    \"\"\"\n",
    "    Compares scikit-learn's LatentDirichletAllocation (LDA) models with gensim's LdaModel.\n",
    "    \n",
    "    Args:\n",
    "        sklearn_models (list): List of scikit-learn LDA models.\n",
    "        gensim_models (list): List of gensim LdaModel.\n",
    "        data (list): List of tokenized sentences.\n",
    "    \"\"\"\n",
    "    # Convert tokenized sentences to text documents by joining tokens with space separator\n",
    "    documents = [' '.join(tokens) for tokens in data]\n",
    "\n",
    "    # Convert text data to numerical representation using CountVectorizer\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(documents)\n",
    "\n",
    "    # Create a PyTorch tensor from the sparse matrix and move it to the device\n",
    "    X_tensor = torch.from_numpy(X.toarray()).float()\n",
    "\n",
    "    # Create a Gensim Dictionary from the tokenized sentences\n",
    "    dictionary = Dictionary(data)\n",
    "    \n",
    "    for i, (sk_model, gs_model) in enumerate(zip(sklearn_models, gensim_models)):\n",
    "        print(f\"Comparison for Model {i+1}:\")\n",
    "        \n",
    "        # Compare coherence values using Gensim's CoherenceModel\n",
    "        coherence_sk = sk_model.score(X)\n",
    "        \n",
    "        pbar = tqdm(total=len(data), desc=\"Calculating Coherence Value - Gensim\")\n",
    "        coherence_gs = 0\n",
    "        \n",
    "        for doc in data:\n",
    "            bow = dictionary.doc2bow(doc)\n",
    "            coherence_gs += gs_model.log_perplexity([bow])\n",
    "            pbar.update(1)\n",
    "        \n",
    "        pbar.close()\n",
    "        \n",
    "        coherence_gs /= len(data)\n",
    "        \n",
    "        print(f\"Coherence Value - scikit-learn: {coherence_sk}\")\n",
    "        print(f\"Coherence Value - Gensim: {coherence_gs}\\n\")\n",
    "\n",
    "# Example usage:\n",
    "sklearn_models = [lda_model_100_topics, lda_model_200_topics]\n",
    "gensim_models = [lda_gensim_100_topics, lda_gensim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
