{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    script: JournalLDA.ipynb\n",
    "    @author alan hamm(pqn7)\n",
    "\n",
    "    resources:\n",
    "        Applied Text Analysis with Python by Benjamin Bengfort, Rebecca Bilbro, \n",
    "        and Tony Ojeda(O'Reilly). 978-1-491-96304-3.\n",
    "\n",
    "        https://radimrehurek.com/gensim/auto_examples/howtos/run_compare_lda.html\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.api import CorpusReader\n",
    "from nltk.corpus.reader.api import CategorizedCorpusReader\n",
    "import nltk.data\n",
    "from nltk import sent_tokenize, pos_tag, wordpunct_tokenize\n",
    "import en_core_web_lg\n",
    "import gensim\n",
    "from gensim.models import ldamulticore\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "# https://github.com/buriy/python-readability\n",
    "from readability.readability import Unparseable\n",
    "from readability.readability import Document as Paper\n",
    "\n",
    "# https://docs.python.org/3/library/time.html\n",
    "import time\n",
    "\n",
    "# https://beautiful-soup-4.readthedocs.io/en/latest/\n",
    "import bs4\n",
    "\n",
    "# https://docs.python.org/3/library/codecs.html\n",
    "import codecs\n",
    "\n",
    "# https://docs.python.org/3/library/json.html\n",
    "import json\n",
    "\n",
    "import re \n",
    "\n",
    "import os\n",
    "\n",
    "import pprint as pp\n",
    "\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from time import time  # To time our operations\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "#import modin.pandas as pd\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import csv\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# we create a list to contain the json files that are to be processed\n",
    "\n",
    "#year = 2019\n",
    "#DOC_ID=list()\n",
    "#for x in os.listdir(r\"C:/_harvester/data/html-by-year/10s\"):\n",
    "#    if x.endswith(\".json\") and x[:4] in ['2019']:\n",
    "#        DOC_ID.append(x)\n",
    "#print(DOC_ID)\n",
    "DOC_ID =r'.*([\\d]+_html\\.json)'\n",
    "\n",
    "\n",
    "# we create a list of categories/keywords/tags to\n",
    "#cat_pattern = r'(.*)[\\d]_html\\.json'\n",
    "#cat_pattern = r'(.*?)(\\d{,4}?_html\\.json'\n",
    "#CAT_PATTERN = r'(.*?)\\d{,4}\\.[\\w]+'\n",
    "CAT_PATTERN = r'^(.*?)[\\W]*?\\d{,4}?_html\\.json'\n",
    "\n",
    "\n",
    "# we mark the HTML tags to be used for \n",
    "# extacting the desired article, etc. text\n",
    "# don't include 'li' tag e.g. <li>The Centers for Disease Control and Prevention (CDC) cannot attest to the accuracy of a non-federal website.</li>\n",
    "TAGS = ['p']\n",
    "#TAGS = ['h1']\n",
    "\n",
    "# stop words\n",
    "stop_words = stopwords.words('english')\n",
    "# observed findings \n",
    "stop_words.extend(['icon', 'website', 'mmwr', 'citation', 'author', 'report', 'formatting', \"format\",'regarding',\n",
    "                   'system', 'datum', 'link', 'linking', 'federal', 'data', 'tract', 'census', 'study',\"question\",\n",
    "                   'conduct', 'report', 'including', 'top', 'summary', 'however', 'name', 'known', 'figure', 'return', \n",
    "                   'page', 'view', 'affiliation', 'pdf', 'law', 'version', 'list', 'endorsement', \"review\",\n",
    "                   'article', 'download', 'reference', 'publication', 'discussion', 'table', 'vol', \"message\",\n",
    "                   'information', 'web', 'notification', 'policy', 'policie', #spaCy lemmatization can make errors with pluralization(e.g. rabie for rabies)\n",
    "                   'acknowledgment', 'altmetric',\n",
    "                   'abbreviation', 'figure', \"service\",\"imply\",\"current\",\"source\",\n",
    "                   \"trade\",\"address\", \"addresses\",\"program\",\"organization\" ,\"provided\", \"copyrighted\", \"copyright\",\n",
    "                   \"already\", \"topic\", \"art\", 'e.g', 'eg'])\n",
    "\n",
    "# pretrained model for POS tagging/filtering\n",
    "nlp = en_core_web_lg.load( disable=['parser','ner'])\n",
    "\n",
    "# set encoding for CorpusReader class\n",
    "ENCODING = 'utf8'\n",
    "\n",
    "# SET DIR PATHS\n",
    "JSON_OUT = \"C:/_harvester/data/json-outputs/\"\n",
    "\n",
    "# set the minimum number of topics to find\n",
    "MIN_TOPICS = 100\n",
    "\n",
    "# set the maximum number of topics to find\n",
    "MAX_TOPICS = 505\n",
    "\n",
    "# set the step by value\n",
    "STEP_BY = 2\n",
    "\n",
    "# set value to determine if lemmatization will be performed\n",
    "LEMMATIZATION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "import bs4\n",
    "import re\n",
    "import nltk\n",
    "from time import time\n",
    "import dask.distributed as dd\n",
    "from dask.distributed import Client, LocalCluster #, LocalCUDACluster\n",
    "import dask\n",
    "\n",
    "class JOURNALCorpusReader(CategorizedCorpusReader, CorpusReader):\n",
    "    \"\"\" a corpus reader for CDC Journal articles \"\"\"\n",
    "    \n",
    "    def __init__(self, root, tags=TAGS, fileids=DOC_ID, encoding=ENCODING, **kwargs):\n",
    "        if not any(key.startswith('cat_') for key in kwargs.keys()):\n",
    "            kwargs['cat_pattern'] = CAT_PATTERN\n",
    "\n",
    "        CategorizedCorpusReader.__init__(self, kwargs)\n",
    "        CorpusReader.__init__(self, root, fileids, encoding)\n",
    "        \n",
    "        self.tags = tags\n",
    "\n",
    "    def resolve(self, fileids=None, categories=None):\n",
    "        if categories is not None:\n",
    "            return self.fileids(categories)\n",
    "        \n",
    "        return fileids\n",
    "\n",
    "    def docs(self,fileids=None, categories=None):\n",
    "        fileids = self.resolve(self.fileids(), self.categories())\n",
    "        \n",
    "        for path, encoding in self.abspaths(self.fileids(), include_encoding=True):\n",
    "            with codecs.open(path, 'r', encoding=encoding) as f:\n",
    "                yield json.load(f)\n",
    "\n",
    "    def html(self, fileids=None, categories=None):\n",
    "        for idx, doc in enumerate(self.docs(fileids=fileids,categories=categories)):\n",
    "            #pp.pprint(f\"The file {self.fileids()[idx]} is being processed in HTML()\")\n",
    "            for sentence in doc:\n",
    "                try:\n",
    "                    yield Paper(sentence).summary()\n",
    "                except Unparseable as e:\n",
    "                    print(\"Could not parse HTML: {}\".format(e))\n",
    "                    print(f\"the fileid {self.fileids()[idx]}\")\n",
    "                    pp.pprint(sentence)\n",
    "                    print(\"\\n\")\n",
    "                    continue\n",
    "   \n",
    "    def paras(self,fileids=None,categories=None):\n",
    "        for html in self.html(fileids=fileids,categories=categories):\n",
    "            soup=bs4.BeautifulSoup(html,'html.parser')\n",
    "            for element in soup.find_all(TAGS):\n",
    "                yield element.text\n",
    "            soup.decompose()\n",
    "              \n",
    "    def sents(self,fileids=None,categories=None):\n",
    "        for paragraph in self.paras(fileids=fileids,categories=categories):\n",
    "            for sentence in sent_tokenize(paragraph):\n",
    "                yield sentence\n",
    "                \n",
    "    def words(self, fileids=None, categories=None):\n",
    "        for paragraph in self.paras(fileids=fileids, categories=categories):\n",
    "            for sentence in self.sents(fileids=fileids, categories=categories):\n",
    "                for token in wordpunct_tokenize(sentence):\n",
    "                    yield token\n",
    "\n",
    "    def generate(self, fileids=None, categories=None):\n",
    "        started = time()\n",
    "\n",
    "        # Specify the local directory path\n",
    "        DASK_DIR = '/_harvester/tmp-dask-out'\n",
    "\n",
    "        # Deploy a Single-Machine Multi-GPU Cluster\n",
    "        # https://medium.com/@aryan.gupta18/end-to-end-recommender-systems-with-merlin-part-1-89fabe2fa05b\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Specify GPU device IDs\n",
    "        protocol = \"tcp\"  # \"tcp\" or \"ucx\"\n",
    "        num_gpus = 1\n",
    "        NUM_GPUS=[0]\n",
    "        cores = multiprocessing.cpu_count() - 1 # Count the number of cores in a computer\n",
    "        visible_devices = \",\".join([str(n) for n in NUM_GPUS])  # Select devices to place workers\n",
    "        device_limit_frac = 0.7  # Spill GPU-Worker memory to host at this limit.\n",
    "        device_pool_frac = 0.8\n",
    "        part_mem_frac = 0.15\n",
    "\n",
    "        # Manually specify the total device memory size (in bytes)\n",
    "        device_size = 10 * 1024 * 1024 * 1024  # GPU has 12GB but setting at 10GB\n",
    "                \n",
    "        ram_memory_limit = \"75GB\" # Set the RAM memory limit (per worker)\n",
    "        device_limit = int(device_limit_frac * device_size)\n",
    "        device_pool_size = int(device_pool_frac * device_size)\n",
    "        part_size = int(part_mem_frac * device_size)\n",
    "\n",
    "        cluster = LocalCluster(\n",
    "                n_workers=(multiprocessing.cpu_count()-2),\n",
    "                threads_per_worker=2,\n",
    "                #processes=False,\n",
    "                memory_limit=ram_memory_limit,\n",
    "                local_directory=DASK_DIR,\n",
    "                dashboard_address=\":8787\",\n",
    "                protocol=\"tcp\",\n",
    "        )\n",
    "\n",
    "        client = dd.Client(cluster)  # Connect to the local cluster\n",
    "\n",
    "        # Get information about workers from scheduler\n",
    "        workers_info = client.scheduler_info()[\"workers\"]\n",
    "\n",
    "        # Iterate over workers and set their memory limits\n",
    "        for worker_id, worker_info in workers_info.items():\n",
    "            worker_info[\"memory_limit\"] = ram_memory_limit\n",
    "\n",
    "        # Verify that memory limits have been set correctly\n",
    "        #for worker_id, worker_info in workers_info.items():\n",
    "        #    print(f\"Worker {worker_id}: Memory Limit - {worker_info['memory_limit']}\")\n",
    "\n",
    "        # verify that Dask is being used in your code, you can check the following:\n",
    "        # Check if the Dask client is connected to a scheduler:\n",
    "        if client.status == \"running\":\n",
    "            print(\"Dask client is connected to a scheduler.\")\n",
    "            # Scatter the embedding vectors across Dask workers\n",
    "        else:\n",
    "            print(\"Dask client is not connected to a scheduler.\")\n",
    "\n",
    "        # Check if Dask workers are running:\n",
    "        if len(client.scheduler_info()[\"workers\"]) > 0:\n",
    "            print(\"Dask workers are running.\")\n",
    "        else:\n",
    "            print(\"No Dask workers are running.\")\n",
    "\n",
    "        # Structures to perform counting\n",
    "        counts = nltk.FreqDist()\n",
    "        tokens = nltk.FreqDist()\n",
    "        \n",
    "        # Create Dask delayed objects for each method\n",
    "        paras_list = list(self.paras(fileids=fileids, categories=categories))\n",
    "        sents_list = list(self.sents(fileids=fileids, categories=categories))\n",
    "        words_list = list(self.words(fileids=fileids, categories=categories))\n",
    "\n",
    "        paras_delayed = dask.delayed(paras_list)\n",
    "        sents_delayed = dask.delayed(sents_list)\n",
    "        words_delayed = dask.delayed(words_list)\n",
    "\n",
    "        # Enable the Dask progress bar\n",
    "        ProgressBar().register()\n",
    "\n",
    "        # Compute the delayed objects in parallel using Dask's distributed scheduler\n",
    "        with ProgressBar():\n",
    "            para_dict = dict(enumerate(paras_delayed.compute(), desc=\"Processing paragraphs\"))\n",
    "            sent_dict = dict(enumerate(sents_delayed.compute(), desc=\"Processing sentences\"))\n",
    "            word_dict = dict(enumerate(words_delayed.compute(), desc=\"Processing words\"))\n",
    "\n",
    "        # Compute the number of files\n",
    "        n_fileids = len(self.resolve(fileids, categories) or self.fileids())\n",
    "\n",
    "        # Return data structure with information\n",
    "        meta = {\n",
    "            'files': self.fileids(),\n",
    "            'nfiles': n_fileids,\n",
    "            'paras': len(para_dict),\n",
    "            'sents': len(sent_dict),\n",
    "            'words': len(word_dict),\n",
    "            'vocab': len(tokens),\n",
    "            'lexdiv': float(len(word_dict)) / float(len(tokens)),\n",
    "            'wdps': float(len(word_dict)) / float(len(sent_dict)),\n",
    "            'sppar': float(len(sent_dict)) / float(len(para_dict)),\n",
    "            'mins': round((time() - started) / 60, 2)\n",
    "         }\n",
    "\n",
    "        # Close connection to the Dask client and cluster\n",
    "        client.close()\n",
    "        cluster.close()\n",
    "\n",
    "        return meta, para_dict, sent_dict, word_dict, counts, tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2010_html.json',\n",
       " '2011_html.json',\n",
       " '2012_html.json',\n",
       " '2013_html.json',\n",
       " '2014_html.json',\n",
       " '2015_html.json',\n",
       " '2016_html.json',\n",
       " '2017_html.json',\n",
       " '2018_html.json',\n",
       " '2019_html.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_corpus = JOURNALCorpusReader('/_harvester/data/html-by-year/10s')\n",
    "#print(_corpus.categories())\n",
    "_corpus.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask client is connected to a scheduler.\n",
      "Dask workers are running.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 04:11:55,269 - tornado.application - ERROR - Uncaught exception GET /status/ws (::1)\n",
      "HTTPServerRequest(protocol='http', host='localhost:8787', method='GET', uri='/status/ws', version='HTTP/1.1', remote_ip='::1')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\web.py\", line 1713, in _execute\n",
      "    result = await result\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\websocket.py\", line 277, in get\n",
      "    await self.ws_connection.accept_connection(self)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\websocket.py\", line 867, in accept_connection\n",
      "    await self._accept_connection(handler)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\websocket.py\", line 950, in _accept_connection\n",
      "    await self._receive_frame_loop()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\websocket.py\", line 1109, in _receive_frame_loop\n",
      "    self.handler.on_ws_connection_close(self.close_code, self.close_reason)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\websocket.py\", line 575, in on_ws_connection_close\n",
      "    self.on_connection_close()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\websocket.py\", line 567, in on_connection_close\n",
      "    self.on_close()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\views\\ws.py\", line 308, in on_close\n",
      "    self.connection.session.notify_connection_lost()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\connection.py\", line 65, in session\n",
      "    assert self._session is not None\n",
      "AssertionError\n",
      "2024-04-15 04:12:51,442 - bokeh.server.protocol_handler - ERROR - error handling message\n",
      " message: Message 'PATCH-DOC' content: {'events': [{'kind': 'ModelChanged', 'model': {'id': 'p3317'}, 'attr': 'start', 'new': -1.2050000000000018}, {'kind': 'ModelChanged', 'model': {'id': 'p3317'}, 'attr': 'end', 'new': 25.305000000000003}]} \n",
      " error: AssertionError()\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\protocol_handler.py\", line 97, in handle\n",
      "    work = await handler(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\session.py\", line 295, in patch\n",
      "    return connection.session._handle_patch(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\connection.py\", line 65, in session\n",
      "    assert self._session is not None\n",
      "AssertionError\n",
      "2024-04-15 04:12:51,512 - bokeh.server.protocol_handler - ERROR - error handling message\n",
      " message: Message 'PATCH-DOC' content: {'events': [{'kind': 'ModelChanged', 'model': {'id': 'p3122'}, 'attr': 'inner_width', 'new': 322}, {'kind': 'ModelChanged', 'model': {'id': 'p3122'}, 'attr': 'inner_height', 'new': 178}, {'kind': 'ModelChanged', 'model': {'id': 'p3122'}, 'attr': 'outer_width', 'new': 342}, {'kind': 'ModelChanged', 'model': {'id': 'p3122'}, 'attr': 'outer_height', 'new': 258}]} \n",
      " error: AssertionError()\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\protocol_handler.py\", line 97, in handle\n",
      "    work = await handler(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\session.py\", line 295, in patch\n",
      "    return connection.session._handle_patch(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\connection.py\", line 65, in session\n",
      "    assert self._session is not None\n",
      "AssertionError\n",
      "2024-04-15 04:12:51,525 - bokeh.server.protocol_handler - ERROR - error handling message\n",
      " message: Message 'PATCH-DOC' content: {'events': [{'kind': 'ModelChanged', 'model': {'id': 'p3225'}, 'attr': 'inner_width', 'new': 322}, {'kind': 'ModelChanged', 'model': {'id': 'p3225'}, 'attr': 'inner_height', 'new': 178}, {'kind': 'ModelChanged', 'model': {'id': 'p3225'}, 'attr': 'outer_width', 'new': 342}, {'kind': 'ModelChanged', 'model': {'id': 'p3225'}, 'attr': 'outer_height', 'new': 258}]} \n",
      " error: AssertionError()\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\protocol_handler.py\", line 97, in handle\n",
      "    work = await handler(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\session.py\", line 295, in patch\n",
      "    return connection.session._handle_patch(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\connection.py\", line 65, in session\n",
      "    assert self._session is not None\n",
      "AssertionError\n",
      "2024-04-15 04:12:51,538 - bokeh.server.protocol_handler - ERROR - error handling message\n",
      " message: Message 'PATCH-DOC' content: {'events': [{'kind': 'ModelChanged', 'model': {'id': 'p3266'}, 'attr': 'inner_width', 'new': 322}, {'kind': 'ModelChanged', 'model': {'id': 'p3266'}, 'attr': 'inner_height', 'new': 178}, {'kind': 'ModelChanged', 'model': {'id': 'p3266'}, 'attr': 'outer_width', 'new': 342}, {'kind': 'ModelChanged', 'model': {'id': 'p3266'}, 'attr': 'outer_height', 'new': 258}]} \n",
      " error: AssertionError()\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\protocol_handler.py\", line 97, in handle\n",
      "    work = await handler(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\session.py\", line 295, in patch\n",
      "    return connection.session._handle_patch(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\connection.py\", line 65, in session\n",
      "    assert self._session is not None\n",
      "AssertionError\n",
      "2024-04-15 04:12:51,649 - bokeh.server.protocol_handler - ERROR - error handling message\n",
      " message: Message 'PATCH-DOC' content: {'events': [{'kind': 'ModelChanged', 'model': {'id': 'p3315'}, 'attr': 'inner_width', 'new': 322}, {'kind': 'ModelChanged', 'model': {'id': 'p3315'}, 'attr': 'inner_height', 'new': 178}, {'kind': 'ModelChanged', 'model': {'id': 'p3315'}, 'attr': 'outer_width', 'new': 342}, {'kind': 'ModelChanged', 'model': {'id': 'p3315'}, 'attr': 'outer_height', 'new': 258}]} \n",
      " error: AssertionError()\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\protocol_handler.py\", line 97, in handle\n",
      "    work = await handler(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\session.py\", line 295, in patch\n",
      "    return connection.session._handle_patch(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\connection.py\", line 65, in session\n",
      "    assert self._session is not None\n",
      "AssertionError\n",
      "2024-04-15 04:12:51,910 - bokeh.server.protocol_handler - ERROR - error handling message\n",
      " message: Message 'PATCH-DOC' content: {'events': [{'kind': 'ModelChanged', 'model': {'id': 'p3375'}, 'attr': 'start', 'new': 1713168753.4732578}, {'kind': 'ModelChanged', 'model': {'id': 'p3375'}, 'attr': 'end', 'new': 1713168753.5732577}]} \n",
      " error: AssertionError()\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\protocol_handler.py\", line 97, in handle\n",
      "    work = await handler(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\session.py\", line 295, in patch\n",
      "    return connection.session._handle_patch(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\connection.py\", line 65, in session\n",
      "    assert self._session is not None\n",
      "AssertionError\n",
      "2024-04-15 04:12:52,124 - bokeh.server.protocol_handler - ERROR - error handling message\n",
      " message: Message 'PATCH-DOC' content: {'events': [{'kind': 'ModelChanged', 'model': {'id': 'p3376'}, 'attr': 'start', 'new': -0.2}, {'kind': 'ModelChanged', 'model': {'id': 'p3376'}, 'attr': 'end', 'new': 0.2}]} \n",
      " error: AssertionError()\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\protocol_handler.py\", line 97, in handle\n",
      "    work = await handler(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\session.py\", line 295, in patch\n",
      "    return connection.session._handle_patch(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\connection.py\", line 65, in session\n",
      "    assert self._session is not None\n",
      "AssertionError\n",
      "2024-04-15 04:12:52,129 - bokeh.server.protocol_handler - ERROR - error handling message\n",
      " message: Message 'PATCH-DOC' content: {'events': [{'kind': 'ModelChanged', 'model': {'id': 'p3377'}, 'attr': 'inner_width', 'new': 1006}, {'kind': 'ModelChanged', 'model': {'id': 'p3377'}, 'attr': 'inner_height', 'new': 364}, {'kind': 'ModelChanged', 'model': {'id': 'p3377'}, 'attr': 'outer_width', 'new': 1026}, {'kind': 'ModelChanged', 'model': {'id': 'p3377'}, 'attr': 'outer_height', 'new': 444}]} \n",
      " error: AssertionError()\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\protocol_handler.py\", line 97, in handle\n",
      "    work = await handler(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\session.py\", line 295, in patch\n",
      "    return connection.session._handle_patch(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\connection.py\", line 65, in session\n",
      "    assert self._session is not None\n",
      "AssertionError\n",
      "2024-04-15 04:12:52,132 - bokeh.server.protocol_handler - ERROR - error handling message\n",
      " message: Message 'PATCH-DOC' content: {'events': [{'kind': 'ModelChanged', 'model': {'id': 'p3437'}, 'attr': 'start', 'new': 0}, {'kind': 'ModelChanged', 'model': {'id': 'p3437'}, 'attr': 'end', 'new': 0.9}]} \n",
      " error: AssertionError()\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\protocol_handler.py\", line 97, in handle\n",
      "    work = await handler(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\session.py\", line 295, in patch\n",
      "    return connection.session._handle_patch(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\connection.py\", line 65, in session\n",
      "    assert self._session is not None\n",
      "AssertionError\n",
      "2024-04-15 04:12:52,135 - bokeh.server.protocol_handler - ERROR - error handling message\n",
      " message: Message 'PATCH-DOC' content: {'events': [{'kind': 'ModelChanged', 'model': {'id': 'p3439'}, 'attr': 'inner_width', 'new': 1006}, {'kind': 'ModelChanged', 'model': {'id': 'p3439'}, 'attr': 'inner_height', 'new': 149}, {'kind': 'ModelChanged', 'model': {'id': 'p3439'}, 'attr': 'outer_width', 'new': 1026}, {'kind': 'ModelChanged', 'model': {'id': 'p3439'}, 'attr': 'outer_height', 'new': 229}]} \n",
      " error: AssertionError()\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\protocol_handler.py\", line 97, in handle\n",
      "    work = await handler(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\session.py\", line 295, in patch\n",
      "    return connection.session._handle_patch(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\connection.py\", line 65, in session\n",
      "    assert self._session is not None\n",
      "AssertionError\n",
      "2024-04-15 04:12:52,141 - bokeh.server.protocol_handler - ERROR - error handling message\n",
      " message: Message 'PATCH-DOC' content: {'events': [{'kind': 'MessageSent', 'msg_type': 'bokeh_event', 'msg_data': {'type': 'event', 'name': 'document_ready', 'values': {'type': 'map'}}}]} \n",
      " error: AssertionError()\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\protocol_handler.py\", line 97, in handle\n",
      "    work = await handler(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\session.py\", line 295, in patch\n",
      "    return connection.session._handle_patch(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\connection.py\", line 65, in session\n",
      "    assert self._session is not None\n",
      "AssertionError\n",
      "2024-04-15 04:12:52,143 - tornado.application - ERROR - Uncaught exception GET /status/ws (::1)\n",
      "HTTPServerRequest(protocol='http', host='localhost:8787', method='GET', uri='/status/ws', version='HTTP/1.1', remote_ip='::1')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\web.py\", line 1713, in _execute\n",
      "    result = await result\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\websocket.py\", line 277, in get\n",
      "    await self.ws_connection.accept_connection(self)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\websocket.py\", line 867, in accept_connection\n",
      "    await self._accept_connection(handler)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\websocket.py\", line 950, in _accept_connection\n",
      "    await self._receive_frame_loop()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\websocket.py\", line 1109, in _receive_frame_loop\n",
      "    self.handler.on_ws_connection_close(self.close_code, self.close_reason)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\websocket.py\", line 575, in on_ws_connection_close\n",
      "    self.on_connection_close()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\websocket.py\", line 567, in on_connection_close\n",
      "    self.on_close()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\views\\ws.py\", line 308, in on_close\n",
      "    self.connection.session.notify_connection_lost()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\connection.py\", line 65, in session\n",
      "    assert self._session is not None\n",
      "AssertionError\n",
      "2024-04-15 04:13:05,093 - bokeh.server.protocol_handler - ERROR - error handling message\n",
      " message: Message 'PATCH-DOC' content: {'events': [{'kind': 'MessageSent', 'msg_type': 'bokeh_event', 'msg_data': {'type': 'event', 'name': 'document_ready', 'values': {'type': 'map'}}}]} \n",
      " error: AssertionError()\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\protocol_handler.py\", line 97, in handle\n",
      "    work = await handler(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\session.py\", line 295, in patch\n",
      "    return connection.session._handle_patch(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\connection.py\", line 65, in session\n",
      "    assert self._session is not None\n",
      "AssertionError\n",
      "2024-04-15 04:13:06,358 - distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:08,000 - distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:08,643 - bokeh.server.protocol_handler - ERROR - error handling message\n",
      " message: Message 'PATCH-DOC' content: {'events': [{'kind': 'ModelChanged', 'model': {'id': 'p3738'}, 'attr': 'start', 'new': 1713168751993.1465}, {'kind': 'ModelChanged', 'model': {'id': 'p3738'}, 'attr': 'end', 'new': 1713168771993.1465}]} \n",
      " error: AssertionError()\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\protocol_handler.py\", line 97, in handle\n",
      "    work = await handler(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\session.py\", line 295, in patch\n",
      "    return connection.session._handle_patch(message, connection)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\connection.py\", line 65, in session\n",
      "    assert self._session is not None\n",
      "AssertionError\n",
      "2024-04-15 04:13:09,219 - tornado.application - ERROR - Uncaught exception GET /system/ws (::1)\n",
      "HTTPServerRequest(protocol='http', host='localhost:8787', method='GET', uri='/system/ws', version='HTTP/1.1', remote_ip='::1')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\web.py\", line 1713, in _execute\n",
      "    result = await result\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\websocket.py\", line 277, in get\n",
      "    await self.ws_connection.accept_connection(self)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\websocket.py\", line 867, in accept_connection\n",
      "    await self._accept_connection(handler)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\websocket.py\", line 950, in _accept_connection\n",
      "    await self._receive_frame_loop()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\websocket.py\", line 1109, in _receive_frame_loop\n",
      "    self.handler.on_ws_connection_close(self.close_code, self.close_reason)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\websocket.py\", line 575, in on_ws_connection_close\n",
      "    self.on_connection_close()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\tornado\\websocket.py\", line 567, in on_connection_close\n",
      "    self.on_close()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\views\\ws.py\", line 308, in on_close\n",
      "    self.connection.session.notify_connection_lost()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bokeh\\server\\connection.py\", line 65, in session\n",
      "    assert self._session is not None\n",
      "AssertionError\n",
      "2024-04-15 04:13:16,380 - distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:17,500 - distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:20,216 - distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:22,828 - distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:25,497 - distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:26,689 - distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:29,467 - distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:30,447 - distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:32,479 - distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:35,119 - distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:38,719 - distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:40,555 - distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:44,382 - distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:48,147 - distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:51,829 - distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:53,701 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:56,683 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:13:59,228 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:01,799 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:03,030 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:05,681 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:08,234 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:10,697 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:12,778 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:14,362 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:16,880 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:19,343 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:21,416 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:22,914 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:25,550 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:28,012 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:29,250 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:31,899 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:34,513 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:36,944 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:39,365 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:40,598 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:43,150 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:45,764 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:48,130 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:49,443 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:51,978 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:54,549 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:57,028 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:14:59,479 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:00,728 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:03,347 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:05,866 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:08,331 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:09,582 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:12,235 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:14,882 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:17,499 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:19,980 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:21,330 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:24,044 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:26,696 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:29,161 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:30,499 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:33,133 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:35,751 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:38,284 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:40,130 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:41,961 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:44,555 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:47,099 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:49,964 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:56,401 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:15:58,751 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:00,650 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:02,645 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:04,747 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:06,928 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:08,148 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:10,612 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:12,952 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:15,933 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:17,680 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:19,232 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:21,599 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:23,732 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:24,618 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:25,682 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:26,983 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:28,613 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:32,717 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:34,417 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:36,433 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:38,851 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:40,383 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:44,881 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:45,848 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:48,798 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:49,850 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:51,117 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:52,664 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:54,613 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:16:59,683 - distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:01,513 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:02,996 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:04,910 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:07,051 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:08,946 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:11,062 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:12,267 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:14,314 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:15,635 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:18,562 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:21,251 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:23,485 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:25,199 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:27,913 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:30,499 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:31,766 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:34,583 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:37,255 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:39,865 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:41,132 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:43,945 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:46,680 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:49,182 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:51,085 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:53,034 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:55,716 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:58,353 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:17:59,617 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:02,399 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:05,283 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:07,816 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:09,083 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:11,882 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:14,518 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:16,465 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:18,416 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:21,049 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:23,637 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:25,014 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:27,970 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:30,831 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:33,541 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:34,819 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:37,738 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:40,585 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:43,416 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:45,463 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:47,464 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:50,230 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:52,947 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:54,294 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:57,149 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:18:59,962 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:02,710 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:04,006 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:06,946 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:09,715 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:12,433 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:14,450 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:16,420 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:19,084 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:21,786 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:23,084 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:25,905 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:28,764 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:31,412 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:32,726 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:35,586 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:38,284 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:40,358 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:42,428 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:45,187 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:47,947 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:49,267 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:52,198 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:19:54,881 - distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:02,555 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:05,669 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:08,277 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:10,352 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:13,050 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:15,765 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:17,687 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:19,548 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:21,632 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:24,210 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:26,250 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:29,341 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:31,028 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:34,667 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:35,754 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:36,982 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:38,562 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:40,435 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:45,765 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:47,487 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:49,672 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:51,731 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:52,716 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:55,089 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:57,984 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:20:59,389 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:02,451 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:05,403 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:08,108 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:10,090 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:12,006 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:14,856 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:17,017 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:18,818 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:21,691 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:24,433 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:26,367 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:28,300 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:31,017 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:33,652 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:34,996 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:37,834 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:41,067 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:42,000 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:44,200 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:46,650 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:48,669 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:52,067 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:55,067 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:57,319 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:21:59,417 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:02,401 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:04,867 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:06,700 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:09,817 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:12,766 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:14,967 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:17,250 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:20,217 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:23,167 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:24,634 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:27,769 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:30,851 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:33,766 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:35,283 - distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:38,401 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:41,434 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:44,650 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:47,284 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:49,349 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:52,869 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:56,183 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:22:57,839 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:01,132 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:04,400 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:07,666 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:10,034 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:12,219 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:15,301 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:18,218 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:19,668 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:22,851 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:25,934 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:28,918 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:30,334 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:33,434 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:36,434 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:39,490 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:41,968 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:43,818 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:46,918 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:50,834 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:54,087 - distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:23:57,851 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:06,801 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:09,571 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:12,251 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:15,368 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:18,235 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:20,751 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:22,534 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:24,968 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:27,985 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:30,451 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:33,734 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:35,535 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:39,934 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:41,370 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:42,552 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:44,034 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:45,851 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:48,092 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:54,434 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:56,357 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:24:57,734 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:00,318 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:02,504 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:04,718 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:07,318 - distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:08,335 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:10,802 - distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:12,218 - distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:15,418 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:18,651 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:21,968 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:24,368 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:26,972 - distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:30,135 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:33,192 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:35,318 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:37,501 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:40,502 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:43,421 - distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:44,892 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:48,052 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:51,052 - distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "2024-04-15 04:25:54,254 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n",
      "Cell \u001b[1;32mIn[3], line 135\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m(self, fileids, categories)\u001b[0m\n",
      "Cell \u001b[1;32mIn[3], line 51\u001b[0m, in \u001b[0;36mparas\u001b[1;34m(self, fileids, categories)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bs4\\__init__.py:335\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39minitialize_soup(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 335\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bs4\\__init__.py:478\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;66;03m# Convert the document to Unicode.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m--> 478\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;66;03m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n",
      "File \u001b[1;32mc:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\site-packages\\bs4\\builder\\_htmlparser.py:380\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    378\u001b[0m parser\u001b[38;5;241m.\u001b[39msoup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoup\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m     parser\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;66;03m# html.parser raises AssertionError in rare cases to\u001b[39;00m\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;66;03m# indicate a fatal problem with the markup, especially\u001b[39;00m\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;66;03m# when there's an error in the doctype declaration.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\html\\parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03mas you want (may include '\\n').\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m+\u001b[39m data\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgoahead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\html\\parser.py:170\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[1;34m(self, end)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m startswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m, i):\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m starttagopen\u001b[38;5;241m.\u001b[39mmatch(rawdata, i): \u001b[38;5;66;03m# < + letter\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m         k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_starttag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[0;32m    172\u001b[0m         k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_endtag(i)\n",
      "File \u001b[1;32mc:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\html\\parser.py:302\u001b[0m, in \u001b[0;36mHTMLParser.parse_starttag\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_starttag\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__starttag_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m     endpos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_for_whole_start_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m endpos \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    304\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m endpos\n",
      "File \u001b[1;32mc:\\Users\\pqn7\\.conda\\envs\\nlp\\lib\\html\\parser.py:351\u001b[0m, in \u001b[0;36mHTMLParser.check_for_whole_start_tag\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m endpos\n\u001b[0;32m    349\u001b[0m \u001b[38;5;66;03m# Internal -- check to see if we have a complete starttag; return end\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# or -1 if incomplete.\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_for_whole_start_tag\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[0;32m    352\u001b[0m     rawdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata\n\u001b[0;32m    353\u001b[0m     m \u001b[38;5;241m=\u001b[39m locatestarttagend_tolerant\u001b[38;5;241m.\u001b[39mmatch(rawdata, i)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "corpus_tuple = _corpus.generate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(corpus_tuple[0])|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import spacy\n",
    "\n",
    "texts_out = []\n",
    "inner_text = []\n",
    "\n",
    "# number of stopwords found\n",
    "stopword_count = nltk.FreqDist()\n",
    "\n",
    "pp.pprint(f\"Executing POS/LEMMATIZATION for Year\")\n",
    "\n",
    "t = time()\n",
    "for key, paras in tqdm(corpus_tuple.items()):\n",
    "    doc = nlp(paras)\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_ in ['NOUN', 'ADJ', 'VERB', 'ADV']:\n",
    "            if len(token.text) > 1:\n",
    "                if token.text.lower() not in stop_words and token.lemma_.lower() not in stop_words: \n",
    "                    if LEMMATIZATION == False:\n",
    "                        inner_text.append(token.text) \n",
    "                    else:\n",
    "                        inner_text.append(token.lemma_) \n",
    "                else:\n",
    "                    if LEMMATIZATION == False:\n",
    "                        stopword_count[token.text] += 1\n",
    "                    else:\n",
    "                        stopword_count[token.lemma_] += 1\n",
    "\n",
    "    if len(inner_text) > 0:\n",
    "        texts_out.append(inner_text)\n",
    "    inner_text = []\n",
    "\n",
    "#pp.pprint(texts_out)\n",
    "pp.pprint('Time to finish spaCy filter: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "filename = f'C:/_harvester/data/tokenized-sentences/10s/tokenized_sents-wo-bigrams.json'\n",
    "with open(filename, 'w') as jsonfile:\n",
    "    json.dump(texts_out, jsonfile, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bigrams.\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(texts_out, min_count=20)\n",
    "\n",
    "# freqDist object for bigrams\n",
    "bigram_freq = nltk.FreqDist()\n",
    "\n",
    "# print bigrams\n",
    "for ngrams, _ in bigram.vocab.items():\n",
    "    #unicode_ngrams = ngrams.decode('utf-8')\n",
    "    if '_' in ngrams:\n",
    "        bigram_freq[ngrams]+=1\n",
    "        print(ngrams)\n",
    "\n",
    "# add bigrams to texts_out to be included in corpus\n",
    "for idx in range(len(texts_out)):\n",
    "    for token in bigram[texts_out[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            texts_out[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pp.pprint(texts_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_sents = pd.DataFrame(texts_out)\n",
    "#tokenized_sents.to_parquet(r\"C:\\_harvester\\data\\lda-models\\2010s_html.json\\tokenized_sents-w-bigrams.parquet\")\n",
    "#pp.pprint(texts_out)\n",
    "fliename2 = f\"C:/_harvester/data/tokenized-sentences/10s/tokenized_sents-w-bigrams.json\"\n",
    "with open(fliename2, 'w') as jsonfile:\n",
    "    json.dump(texts_out, jsonfile, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
