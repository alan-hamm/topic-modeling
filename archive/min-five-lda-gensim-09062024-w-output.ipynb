{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis code was written using chatGPT to a limited degree(~20%) -- practically, a Liliputian \"Hello, world\" script.\\n\\nSources: Official Gensim and Gensim communities, Dask documentation and Dask communities were used for review, along with a Brobdingnagian crawl of virtual-space(e.g. blogs, personal sites, stack exchange, etc.) which were \\non more occasions than not *several* years to the n^th degree old.\\n\\nauthors: alan hamm(pqn7)\\n         bertha(chatCDC)\\n         \\napr 2024\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code was written using chatGPT to a limited degree(~20%) -- practically, a Liliputian \"Hello, world\" script.\n",
    "\n",
    "Sources: Official Gensim and Gensim communities, Dask documentation and Dask communities were used for review, along with a Brobdingnagian crawl of virtual-space(e.g. blogs, personal sites, stack exchange, etc.) which were \n",
    "on more occasions than not *several* years to the n^th degree old.\n",
    "\n",
    "authors: alan hamm(pqn7)\n",
    "         bertha(chatCDC)\n",
    "         \n",
    "apr 2024\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TopicFutures by Alan Hamm and Bertha\n",
    "\n",
    "The provided script is a comprehensive Python program that utilizes several libraries to perform \\\n",
    "Latent Dirichlet Allocation (LDA) topic modeling on text data. The script includes functionality for \\\n",
    "data preprocessing, model training, evaluation, and visualization, as well as handling distributed computing with Dask.\n",
    "\n",
    "At the beginning of the script, various libraries are imported including pyLDAvis.gensim for interactive topic model \\\n",
    "visualization, torch for deep learning operations and GPU acceleration, gensim for LDA modeling and coherence \\\n",
    "computation, and dask.distributed for parallel and distributed computing.\\\n",
    "\n",
    "The script sets up directory paths for logging, models, and visuals based on a given decade (DECADE). It checks if these \\\n",
    "directories exist and contain data; if they do, it archives their contents into a ZIP file before removing the old \\\n",
    "subdirectories. New directories are then created for the current run.\n",
    "\n",
    "Logging configuration is established to record messages in a log file. Bokeh deprecation warnings are suppressed to avoid \\\n",
    "cluttering the output with irrelevant messages.\n",
    "\n",
    "Parameters such as alpha (document-topic density) and beta (word-topic density) are defined as lists of possible values \\\n",
    "that will be used during LDA model training. These parameters influence the sparsity or density of topics in documents \\\n",
    "or words associated with topics.\n",
    "\n",
    "A function named futures_create_lda_datasets() is defined to load data from a JSON file, shuffle it, split it into training \\\n",
    "and evaluation datasets based on a specified ratio (train_ratio), and return them as delayed objects ready for parallel processing with Dask.\n",
    "\n",
    "Another function called save_model_and_log() takes care of saving trained LDA models along with their metadata into \\\n",
    "specified directories. It also logs this information into CSV files.\n",
    "\n",
    "The core function train_model() performs the actual training of LDA models using Gensim's LdaModel. It processes text documents \\\n",
    "in batches to create dictionary mappings and trains an LDA model per batch. Model performance metrics like convergence score, \\\n",
    "perplexity score, and coherence score are calculated during this process.\n",
    "\n",
    "The main execution block initializes a Dask cluster with specified worker configurations such as number of cores (CORES) and \\\n",
    "memory limits (RAM_MEMORY_LIMIT). A Dask client is created to manage tasks across workers. Training and evaluation datasets \\\n",
    "are prepared by calling the aforementioned functions. These datasets are scattered across workers for efficient parallel processing.\n",
    "\n",
    "A series of nested loops iterate over combinations of topic numbers (n_topics), alpha values (alpha_values), \\\n",
    "and beta values (beta_values) to submit training tasks for both the training and evaluation datasets. These tasks are \\\n",
    "submitted to the Dask client, which distributes them across the available workers.\n",
    "\n",
    "The script employs a progress bar from tqdm to visualize the progress of model creation and saving. It uses a batch processing \\\n",
    "approach where it waits for a certain number of futures (asynchronous task results) to complete before processing their \\\n",
    "results. If some futures do not complete within a specified timeout (TIMEOUT), they are recorded as failed and an attempt is \\\n",
    "made to retry them with an extended timeout (EXTENDED_TIMEOUT).\n",
    "\n",
    "Once all models have been trained or reattempted, any remaining incomplete models' parameters are logged for review, indicating \\\n",
    "that these models did not successfully complete even after a second attempt.\n",
    "\n",
    "Throughout the script, various utility functions such as os, json, random, csv, and others are used for file operations, \\\n",
    "data manipulation, random shuffling of data, and logging results in CSV format.\n",
    "\n",
    "It's important to note that this script assumes certain global variables like DECADE, DATA_SOURCE, TRAIN_RATIO, CORES,\\\n",
    "THREADS_PER_CORE, etc., are defined elsewhere in the code or environment since they are referenced but not explicitly \\\n",
    "defined within the provided code snippet.\n",
    "\n",
    "Overall, this script is designed for robust LDA topic modeling with extensive parameter exploration while leveraging distributed \\\n",
    "computing resources efficiently. It includes error handling mechanisms such as retries for failed tasks and comprehensive\\\n",
    "logging which aids in debugging and optimizing model performance.\n",
    "\n",
    "The script is structured to handle large-scale topic modeling tasks in a distributed computing environment. After setting up\\\n",
    " the Dask client and workers, it proceeds to create training and evaluation datasets from a specified data source (DATA_SOURCE) \\\n",
    " using the futures_create_lda_datasets function. The resulting datasets are then scattered across the Dask cluster's workers \\\n",
    " for parallel processing.\n",
    "\n",
    "For model training, the script defines a train_model function that takes several parameters including the number of topics, \\\n",
    "alpha and beta values, and the dataset. This function processes text documents in batches, updating a global dictionary with \\\n",
    "each batch and training an LDA model using Gensim's LdaModel. It computes various performance metrics for each batch such as \\\n",
    "convergence score, perplexity score, and coherence score.\n",
    "\n",
    "The main execution loop iterates over different combinations of model hyperparameters (number of topics, alpha values, beta values) \\\n",
    "and submits two sets of futures to the Dask client: one for training models on the training data (train_futures) and another \\\n",
    "for evaluating models on the evaluation data (eval_futures). These futures are monitored for completion, with progress tracked by a tqdm progress bar.\n",
    "\n",
    "If any futures do not complete within the given timeout period (TIMEOUT), they are added to a list of failed model parameters \\\n",
    "(failed_model_params) for later analysis. The script includes functionality to retry processing these incomplete futures with \\\n",
    "an extended timeout (EXTENDED_TIMEOUT). Once all models have been processed or reattempted, any remaining incomplete models' \\\n",
    "parameters are logged using both standard output and a performance logger (perf_logger).\n",
    "\n",
    "Finally, upon completion or failure of all tasks, the script closes the Dask client and provides an overview of which model parameters \\\n",
    "did not complete successfully after retries. This information can be used to diagnose potential issues in model training or resource \\\n",
    "allocation within the distributed computing setup.\n",
    "\n",
    "In summary, this script is designed as an end-to-end solution for performing LDA topic modeling at scale. It incorporates best \\\n",
    "practices such as error handling through retries, logging important events and metrics for post-analysis, utilizing distributed\\\n",
    " computing resources effectively via Dask, and providing user feedback through progress bars. Users looking to employ this script \\\n",
    " should ensure they have set up their environment correctly with all necessary variables defined and have access to sufficient \\\n",
    " computational resources managed by Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim  # Library for interactive topic model visualization\n",
    "from tqdm import tqdm  # Creates progress bars to visualize the progress of loops or tasks\n",
    "from gensim.models import LdaModel  # Implements LDA for topic modeling using the Gensim library\n",
    "from gensim.corpora import Dictionary  # Represents a collection of text documents as a bag-of-words corpus\n",
    "from gensim.models import CoherenceModel  # Computes coherence scores for topic models\n",
    "import pyLDAvis\n",
    "import IProgress \n",
    "\n",
    "import os  # Provides functions for interacting with the operating system, such as creating directories\n",
    "import itertools  # Provides various functions for efficient iteration and combination of elements\n",
    "import numpy as np  # Library for numerical computing in Python, used for array operations and calculations\n",
    "from time import time, sleep # Measures the execution time of code snippets or functions\n",
    "import pprint as pp  # Pretty-printing library, used here to format output in a readable way\n",
    "import pandas as pd\n",
    "import logging # Logging module for generating log messages\n",
    "import sys # Provides access to some variables used or maintained by the interpreter and to functions that interact with the interpreter \n",
    "import shutil # High-level file operations such as copying and removal \n",
    "import zipfile # Provides tools to create, read, write, append, and list a ZIP file\n",
    "from tqdm.notebook import tqdm  # Creates progress bars in Jupyter Notebook environment\n",
    "from json import load\n",
    "import random\n",
    "import logging\n",
    "import csv\n",
    "import pprint as pp\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from typing import Union, List\n",
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "from dask.distributed import as_completed\n",
    "import dask   # Parallel computing library that scales Python workflows across multiple cores or machines \n",
    "from dask.distributed import Client, LocalCluster, wait   # Distributed computing framework that extends Dask functionality \n",
    "from dask.diagnostics import ProgressBar   # Visualizes progress of Dask computations\n",
    "from dask.distributed import progress\n",
    "from dask.delayed import Delayed # Decorator for creating delayed objects in Dask computations\n",
    "#from dask.distributed import as_completed\n",
    "from dask.bag import Bag\n",
    "from dask import delayed\n",
    "import dask.config\n",
    "#from dask.distributed import wait\n",
    "from dask.distributed import performance_report, wait, as_completed #,print\n",
    "from distributed import get_worker\n",
    "import gc\n",
    "import hashlib\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "DECADE_TO_PROCESS ='2010s'\n",
    "LOG_DIRECTORY = f\"C:/_harvester/data/lda-models/{DECADE_TO_PROCESS}_html/log/\"\n",
    "# Ensure the LOG_DIRECTORY exists\n",
    "os.makedirs(LOG_DIRECTORY, exist_ok=True)\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "# Format the date and time as per your requirement\n",
    "# Note: %w is the day of the week as a decimal (0=Sunday, 6=Saturday)\n",
    "#       %Y is the four-digit year\n",
    "#       %m is the two-digit month (01-12)\n",
    "#       %H%M is the hour (00-23) followed by minute (00-59) in 24hr format\n",
    "log_filename = now.strftime('log-%w-%m-%Y-%H%M.log')\n",
    "LOGFILE = os.path.join(LOG_DIRECTORY,log_filename)\n",
    "\n",
    "# Configure logging to write to a file with this name\n",
    "logging.basicConfig(\n",
    "    filename=LOGFILE,\n",
    "    filemode='a',  # Append mode if you want to keep adding to the same file during the day\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "# Now when you use logging.info(), logging.debug(), etc., it will write to that log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dask dashboard throws deprecation warnings w.r.t. Bokeh\n",
    "import warnings\n",
    "from bokeh.util.deprecation import BokehDeprecationWarning\n",
    "\n",
    "# Disable Bokeh deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\", category=BokehDeprecationWarning)\n",
    "# Filter out the specific warning message\n",
    "# Set the logging level for distributed.utils_perf to suppress warnings\n",
    "logging.getLogger('distributed.utils_perf').setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\", module=\"distributed.utils_perf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x17b5761eea0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the range of number of topics for LDA and step size\n",
    "START_TOPICS = 100\n",
    "END_TOPICS = 205\n",
    "STEP_SIZE = 5\n",
    "\n",
    "# define the decade that is being modelled \n",
    "DECADE = DECADE_TO_PROCESS\n",
    "\n",
    "# In the case of this machine, since it has an Intel Core i9 processor with 8 physical cores (16 threads with Hyper-Threading), \n",
    "# it would be appropriate to set the number of workers in Dask Distributed LocalCluster to 8 or slightly lower to allow some CPU \n",
    "# resources for other tasks running on your system.\n",
    "CORES = 10\n",
    "MAXIMUM_CORES = 12\n",
    "\n",
    "THREADS_PER_CORE = 2\n",
    "\n",
    "RAM_MEMORY_LIMIT = \"12GB\" \n",
    "\n",
    "# Specify the local directory path\n",
    "DASK_DIR = '/_harvester/tmp-dask-out'\n",
    "\n",
    "# specify the number of passes for Gensim LdaModel\n",
    "PASSES = 15\n",
    "\n",
    "# specify the number of iterations\n",
    "ITERATIONS = 50\n",
    "\n",
    "# Number of documents to be iterated through for each update. \n",
    "# Set to 0 for batch learning, > 1 for online iterative learning.\n",
    "UPDATE_EVERY = 5\n",
    "\n",
    "# Log perplexity is estimated every that many updates. \n",
    "# Setting this to one slows down training by ~2x.\n",
    "EVAL_EVERY = 10\n",
    "\n",
    "RANDOM_STATE = 75\n",
    "\n",
    "PER_WORD_TOPICS = True\n",
    "\n",
    "# number of documents to extract from the JSON source file when testing and developing\n",
    "NUM_DOCUMENTS = 25\n",
    "\n",
    "# the number of documents to read from the JSON source file per batch\n",
    "FUTURES_BATCH_SIZE = 300\n",
    "\n",
    "# Constants for adaptive batching and retries\n",
    "# Number of futures to process per iteration\n",
    "BATCH_SIZE = 500 # number of documents\n",
    "MAX_BATCH_SIZE = 650 \n",
    "INCREASE_FACTOR = 1.2  # Increase batch size by n% upon success\n",
    "DECREASE_FACTOR = .10 # Decrease batch size by p% upon failure or timeout\n",
    "MAX_RETRIES = 5        # Maximum number of retries per task\n",
    "BASE_WAIT_TIME = 1     # Base wait time in seconds for exponential backoff\n",
    "\n",
    "\n",
    "# Load data from the JSON file\n",
    "DATA_SOURCE = \"C:/_harvester/data/tokenized-sentences/10s/tokenized_min_three_word-w-bigrams-08312024.json\"\n",
    "TRAIN_RATIO = .80\n",
    "\n",
    "TIMEOUT = None #\"90 minutes\"\n",
    "\n",
    "EXTENDED_TIMEOUT = None #\"120 minutes\"\n",
    "\n",
    "CPU_UTILIZATION_THRESHOLD = 85 # ie 95%\n",
    "MEMORY_UTILIZATION_THRESHOLD = .6 # per worker\n",
    "\n",
    "# Enable serialization optimizations\n",
    "dask.config.set(scheduler='distributed', serialize=True)\n",
    "dask.config.set({'logging.distributed': 'error'})\n",
    "dask.config.set({\"distributed.scheduler.worker-ttl\": None})\n",
    "#dask.config.set({\"distributed.scheduler.worker-ttl\": None})"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Documentation for LDA Model Data Management System\n",
    "### Overview\n",
    "The LDA Model Data Management System is designed to efficiently store and manage large volumes of text data and associated \\\n",
    "metadata generated by Latent Dirichlet Allocation (LDA) models. The system allows for quick access to text data based on \\\n",
    "queries of the metadata, facilitating dynamic generation of pyLDAvis objects or other topic analysis visualizations. \n",
    "\n",
    "### System Structure\n",
    "The system comprises a top-level directory with several subdirectories designated for logs, visuals, metadata, and compressed \\\n",
    "text data. Each large body of text is stored as an individual ZIP file to save space, while metadata is stored in a Parquet \\\n",
    "file for efficient querying.\n",
    "\n",
    "**Directory Structure**\n",
    "* ROOT_DIR: The base directory containing all data related to the LDA models. \\\n",
    "* LOG_DIR: A subdirectory within ROOT_DIR that stores log files.\\\n",
    "* IMAGE_DIR: A subdirectory within ROOT_DIR that stores visualization files such as images or charts.\\\n",
    "* METADATA_DIR: A subdirectory within ROOT_DIR that stores metadata in a Parquet file.\\\n",
    "* TEXTS_ZIP_DIR: A subdirectory within ROOT_DIR where each text file is saved as an individual ZIP archive.\\\n",
    "\n",
    "**File Formats**\n",
    "* **Parquet**: Used for storing metadata due to its efficiency in storage size and speed when querying columns.\n",
    "* **ZIP**: Used for compressing individual text files to minimize disk space usage.\n",
    "\n",
    "### Functions\n",
    "**save_text_to_zip**(text_data) \\\n",
    "Saves a given string of text data into a ZIP file within the TEXTS_ZIP_DIR.\n",
    "**Parameters**:\n",
    "* text_data (str): The string content representing the body of text to be saved.\n",
    "**Returns**:\n",
    "* (str): The path to the created ZIP file containing the text data.\n",
    "\n",
    "**add_model_data_to_metadata**(model_data) \\\n",
    "Adds new model data entries to the existing metadata Parquet file. If no Parquet file exists, it creates one.\n",
    "**Parameters**:\n",
    "* model_data (dict): A dictionary containing model-related information including texts and various scores like convergence, perplexity, coherence, etc.\n",
    "**Side Effects**:\n",
    "* Updates or creates a Parquet file at METADATA_DIR/metadata.parquet.\n",
    "\n",
    "**get_text_from_zip**(zip_path)\n",
    "Reads and returns the content of a specified text from its corresponding ZIP archive.\n",
    "**Parameters**:\n",
    "* zip_path (str): The path to the ZIP archive containing the text data.\n",
    "**Returns**:\n",
    "* (str): The text content extracted from the ZIP file.\n",
    "\n",
    "**load_texts_for_analysis**(metadata_path, coherence_threshold=0.7) \n",
    "Loads metadata from a Parquet file and retrieves texts that meet specified criteria, such as a minimum coherence score.\\\n",
    "**Parameters**:\n",
    "* metadata_path (str): The path to the metadata Parquet file.\n",
    "* coherence_threshold (float, optional): The threshold for filtering records based on their coherence score. Defaults to 0.7.\n",
    "**Returns**:\n",
    "* (list of str): A list of text contents that meet the specified criteria.\n",
    "    \n",
    "### Usage\n",
    "To use this system, follow these steps:\n",
    "\n",
    "1. Ensure that all necessary directories (LOG_DIR, IMAGE_DIR, METADATA_DIR, TEXTS_ZIP_DIR) are created within the top-level directory (ROOT_DIR).\n",
    "2. When new model data is generated, create a dictionary with keys corresponding to metadata fields and a 'text' key containing a list of large bodies of text.\n",
    "3. Call add_model_data_to_metadata(new_model_data) to save the text data into individual ZIP files and update or create the metadata Parquet file with references to these ZIP files.\n",
    "4. To retrieve texts for analysis based on metadata queries, call load_texts_for_analysis(parquet_file_path). You can specify a different coherence threshold if needed.\n",
    "5. For any specific text retrieval based on its ZIP archive path, use get_text_from_zip(zip_path)\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "## Maintenance\n",
    "The system requires minimal maintenance:\n",
    "* Periodically check the available disk space in case the volume of stored texts grows significantly.\n",
    "* Backup important data regularly, especially the Parquet file containing metadata and references to text files.\n",
    "* Update directory paths and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def garbage_collection(development: bool, location: str):\n",
    "    if development:\n",
    "        # Enable debugging flags for leak statistics\n",
    "        gc.set_debug(gc.DEBUG_LEAK)\n",
    "\n",
    "    # Before calling collect, get a count of existing objects\n",
    "    before = len(gc.get_objects())\n",
    "\n",
    "    # Perform garbage collection\n",
    "    collected = gc.collect()\n",
    "\n",
    "    # After calling collect, get a new count of existing objects\n",
    "    after = len(gc.get_objects())\n",
    "\n",
    "    # Print or log before and after counts along with number collected\n",
    "    logging.info(f\"Garbage Collection at {location}:\")\n",
    "    logging.info(f\"  Before GC: {before} objects\")\n",
    "    logging.info(f\"  After GC: {after} objects\")\n",
    "    logging.info(f\"  Collected: {collected} objects\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "# Define the top-level directory and subdirectories\n",
    "DECADE = \"2010s\"  # Replace with your actual decade value\n",
    "ROOT_DIR = f\"C:/_harvester/data/lda-models/{DECADE}_html\"\n",
    "LOG_DIR = os.path.join(ROOT_DIR, \"log\")\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"visuals\")\n",
    "METADATA_DIR = os.path.join(ROOT_DIR, \"metadata\")\n",
    "TEXTS_ZIP_DIR = os.path.join(ROOT_DIR, \"texts_zip\")\n",
    "\n",
    "# Ensure that all necessary directories exist\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(IMAGE_DIR, exist_ok=True)\n",
    "os.makedirs(METADATA_DIR, exist_ok=True)\n",
    "os.makedirs(TEXTS_ZIP_DIR, exist_ok=True)\n",
    "\n",
    "# Function to save text data to a zip file and return the path\n",
    "def save_text_to_zip(text_data):\n",
    "    # Generate a unique filename based on current timestamp\n",
    "    timestamp_str = pd.Timestamp.now().strftime('%Y%m%d%H%M%S%f')\n",
    "    text_zip_filename = f\"{timestamp_str}.zip\"\n",
    "    \n",
    "    # Write the text content to a zip file within TEXTS_ZIP_DIR\n",
    "    zip_path = os.path.join(TEXTS_ZIP_DIR, text_zip_filename)\n",
    "    with zipfile.ZipFile(zip_path, mode='w', compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "        zf.writestr(\"text.txt\", text_data)\n",
    "    \n",
    "    return zip_path\n",
    "\n",
    "# Function to save text data and model to single ZIP file\n",
    "def save_to_zip(time, text_data, ldamodel):\n",
    "    # Generate a unique filename based on current timestamp\n",
    "    timestamp_str = hashlib.md5(time.strftime('%Y%m%d%H%M%S%f').encode()).hexdigest()\n",
    "    text_zip_filename = f\"{timestamp_str}.zip\"\n",
    "    \n",
    "    # Write the text content and model to a zip file within TEXTS_ZIP_DIR\n",
    "    zip_path = os.path.join(TEXTS_ZIP_DIR, text_zip_filename)\n",
    "    with zipfile.ZipFile(zip_path, mode='w', compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "        zf.writestr(f\"doc_{text_zip_filename}.txt\", text_data)\n",
    "        ldamodel_bytes = pickle.dumps(ldamodel)\n",
    "        zf.writestr(f\"model_{text_zip_filename}.pkl\", ldamodel_bytes)\n",
    "    \n",
    "    return zip_path\n",
    "\n",
    "# method to deserialize and return the LDA model object\n",
    "def load_pkl_from_zip(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "        pkl_files = [file for file in zf.namelist() if file.endswith('.pkl')]\n",
    "        if len(pkl_files) == 0:\n",
    "            raise ValueError(\"No pkl files found in the ZIP archive.\")\n",
    "        \n",
    "        pkl_file = pkl_files[0]\n",
    "        pkl_bytes = zf.read(pkl_file)\n",
    "        loaded_pkl = pickle.loads(pkl_bytes)\n",
    "    \n",
    "    return loaded_pkl\n",
    "\n",
    "# Function to add new model data to metadata Parquet file\n",
    "def add_model_data_to_metadata(model_data):\n",
    "    #print(\"we are in the add_model_data_to_metadata method()\")\n",
    "    # Save large body of text to zip and update model_data reference\n",
    "    texts_zipped = []\n",
    "    \n",
    "    #for text_list in model_data['text']:\n",
    "    for text_list in model_data['text']:\n",
    "        combined_text = ''.join([''.join(sent) for sent in text_list])  # Combine all sentences into one string\n",
    "        zip_path = save_to_zip(model_data['time'], combined_text, model_data['lda_model'])\n",
    "        texts_zipped.append(zip_path)\n",
    "    # Update model data with zipped paths\n",
    "    model_data['text'] = texts_zipped\n",
    "     # Ensure other fields are not lists, or if they are, they should have only one element per model\n",
    "    for key, value in model_data.items():\n",
    "        #if isinstance(value, list) and key != 'text':\n",
    "        if isinstance(value, list) and key not in ['text', 'top_words']:\n",
    "            assert len(value) == 1, f\"Field {key} has multiple elements\"\n",
    "            model_data[key] = value[0]  # Unwrap single-element list\n",
    "               \n",
    "    # Define the expected data types for each column\n",
    "    expected_dtypes = {\n",
    "        'type': str,\n",
    "        'batch_size': int,\n",
    "        'text': object,  # Use object dtype for lists of strings (file paths)\n",
    "        'text_sha256': str,\n",
    "        'text_md5': str,\n",
    "        'convergence': 'float32',\n",
    "        'perplexity': 'float32',\n",
    "        'coherence': 'float32',\n",
    "        'topics': int,\n",
    "        # Use pd.Categorical.dtype for categorical columns\n",
    "        # Ensure alpha and beta are already categorical when passed into this function\n",
    "        # They should not be wrapped again with CategoricalDtype here.\n",
    "        'alpha_str': str,\n",
    "        'n_alpha': 'float32',\n",
    "        'beta_str': str,\n",
    "        'n_beta': 'float32',\n",
    "        'passes': int,\n",
    "        'iterations': int,\n",
    "        'update_every': int,\n",
    "        'eval_every': int,\n",
    "        'chunksize': int,\n",
    "        'random_state': int,\n",
    "        'per_word_topics': bool,\n",
    "        'top_words': object,\n",
    "        'lda_model': object,\n",
    "        # Enforce datetime type for time\n",
    "        'time': 'datetime64[ns]',\n",
    "    }   \n",
    "\n",
    "    \n",
    "    try:\n",
    "        #df_new_metadata = pd.DataFrame({key: [value] if not isinstance(value, list) else value \n",
    "        #                                for key, value in model_data.items()}).astype(expected_dtypes)\n",
    "        # Create a new DataFrame without enforcing dtypes initially\n",
    "        df_new_metadata = pd.DataFrame({key: [value] if not isinstance(value, list) else value \n",
    "                                        for key, value in model_data.items()})\n",
    "        \n",
    "        # Apply type conversion selectively\n",
    "        #for col_name in ['convergence', 'perplexity', 'coherence', 'n_beta', 'n_alpha']:\n",
    "        for col_name in ['convergence', 'perplexity', 'coherence', 'n_beta', 'n_alpha']:\n",
    "            df_new_metadata[col_name] = df_new_metadata[col_name].astype('float64')\n",
    "            \n",
    "        df_new_metadata['topics'] = df_new_metadata['topics'].astype(int)\n",
    "        #df_new_metadata['time'] = pd.to_datetime(df_new_metadata['time'])\n",
    "        df_new_metadata['batch_size'] = BATCH_SIZE\n",
    "    except ValueError as e:\n",
    "        # Initialize an error message list\n",
    "        error_messages = [f\"Error converting model_data to DataFrame with enforced dtypes: {e}\"]\n",
    "        \n",
    "        \n",
    "        # Iterate over each item in model_data to collect its key, expected dtype, and actual value\n",
    "        for key, value in model_data.items():\n",
    "            expected_dtype = expected_dtypes.get(key, 'No expected dtype specified')\n",
    "            actual_dtype = type(value).__name__\n",
    "            error_messages.append(f\"Column: {key}, Expected dtype: {expected_dtype}, Actual dtype: {actual_dtype}, Value: {value}\")\n",
    "        \n",
    "        # Join all error messages into a single string\n",
    "        full_error_message = \"\\n\".join(error_messages)\n",
    "\n",
    "        logging.error(full_error_message)\n",
    "\n",
    "        raise ValueError(\"Data type mismatch encountered during DataFrame conversion. Detailed log available.\")\n",
    "    \n",
    "    # Path to the metadata Parquet file\n",
    "    parquet_file_path = os.path.join(METADATA_DIR, \"metadata.parquet\")\n",
    "    \n",
    "    # Check if the Parquet file already exists\n",
    "    if os.path.exists(parquet_file_path): \n",
    "        # If it exists, read the existing metadata and append the new data \n",
    "        df_metadata = pd.read_parquet(parquet_file_path) \n",
    "        df_metadata = pd.concat([df_metadata, df_new_metadata], ignore_index=True) \n",
    "    else: \n",
    "        # If it doesn't exist, use the new data as the starting point \n",
    "        df_metadata = df_new_metadata\n",
    "\n",
    "    # drop lda model from dataframe\n",
    "    df_metadata = df_metadata.drop('lda_model', axis=1)\n",
    "\n",
    "    # Save updated metadata DataFrame back to Parquet file\n",
    "    df_metadata.to_parquet(parquet_file_path)\n",
    "    del df_metadata, model_data\n",
    "    #garbage_collection(False, 'Cleaned add_model_data_to_metadata(...)')\n",
    "    #print(\"\\nthis is the value of the parquet file\")\n",
    "    #print(df_metadata)\n",
    "\n",
    "\n",
    "# Function to read a specific text from its zip file based on metadata query\n",
    "def get_text_from_zip(zip_path): \n",
    "    with zipfile.ZipFile(zip_path, 'r') as zf: \n",
    "        return zf.read('text.txt').decode('utf-8')\n",
    "\n",
    "# Example usage: Load metadata and retrieve texts based on some criteria\n",
    "def load_texts_for_analysis(metadata_path, coherence_threshold=0.7): \n",
    "    # Load the metadata into a DataFrame \n",
    "    df_metadata = pd.read_parquet(metadata_path)\n",
    "\n",
    "    # Filter metadata based on some criteria (e.g., coherence > threshold)\n",
    "    filtered_metadata = df_metadata[df_metadata['coherence'] > coherence_threshold]\n",
    "\n",
    "    # Retrieve and decompress associated texts from their zip files\n",
    "    texts = [get_text_from_zip(zip_path) for zip_path in filtered_metadata['text']]\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PERFORMANCE_TRAIN_LOG = os.path.join(LOG_DIR, \"train_model_performance.html\")\n",
    "# INCLUDE EVAL AND TRAINING DATA OUTPUT FILEPATHS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "num_topics = len(range(START_TOPICS, END_TOPICS + 1, STEP_SIZE))\n",
    "\n",
    "# Calculate numeric_alpha for symmetric prior\n",
    "numeric_symmetric = 1.0 / num_topics\n",
    "# Calculate numeric_alpha for asymmetric prior (using best judgment)\n",
    "numeric_asymmetric = 1.0 / (num_topics + np.sqrt(num_topics))\n",
    "# Create the list with numeric values\n",
    "numeric_alpha = [numeric_symmetric, numeric_asymmetric] + np.arange(0.01, 1, 0.3).tolist()\n",
    "numeric_beta = [numeric_symmetric] + np.arange(0.01, 1, 0.3).tolist()\n",
    "\n",
    "\n",
    "# The parameter `alpha` in Latent Dirichlet Allocation (LDA) represents the concentration parameter of the Dirichlet \n",
    "# prior distribution for the topic-document distribution.\n",
    "# It controls the sparsity of the resulting document-topic distributions.\n",
    "\n",
    "# A lower value of `alpha` leads to sparser distributions, meaning that each document is likely to be associated with fewer topics.\n",
    "# Conversely, a higher value of `alpha` encourages documents to be associated with more topics, resulting in denser distributions.\n",
    "\n",
    "# The choice of `alpha` affects the balance between topic diversity and document specificity in LDA modeling.\n",
    "alpha_values = ['symmetric', 'asymmetric']\n",
    "alpha_values += np.arange(0.01, 1, 0.3).tolist()\n",
    "\n",
    "# In Latent Dirichlet Allocation (LDA) topic analysis, the beta parameter represents the concentration \n",
    "# parameter of the Dirichlet distribution used to model the topic-word distribution. It controls the \n",
    "# sparsity of topics by influencing how likely a given word is to be assigned to a particular topic.\n",
    "\n",
    "# A higher value of beta encourages topics to have a more uniform distribution over words, resulting in more \n",
    "# general and diverse topics. Conversely, a lower value of beta promotes sparser topics with fewer dominant words.\n",
    "\n",
    "# The choice of beta can impact the interpretability and granularity of the discovered topics in LDA.\n",
    "beta_values = ['symmetric']\n",
    "beta_values += np.arange(0.01, 1, 0.3).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "def calculate_numeric_alpha(alpha_str, num_topics=num_topics):\n",
    "    if alpha_str == 'symmetric':\n",
    "        return Decimal('1.0') / num_topics\n",
    "    elif alpha_str == 'asymmetric':\n",
    "        return Decimal('1.0') / (num_topics + Decimal(num_topics).sqrt())\n",
    "    else:\n",
    "        # Use Decimal for arbitrary precision\n",
    "        return Decimal(alpha_str)\n",
    "\n",
    "def calculate_numeric_beta(beta_str, num_topics=num_topics):\n",
    "    if beta_str == 'symmetric':\n",
    "        return Decimal('1.0') / num_topics\n",
    "    else:\n",
    "        # Use Decimal for arbitrary precision\n",
    "        return Decimal(beta_str)\n",
    "\n",
    "def validate_alpha_beta(alpha_str, beta_str):\n",
    "    valid_strings = ['symmetric', 'asymmetric']\n",
    "    if isinstance(alpha_str, str) and alpha_str not in valid_strings:\n",
    "        logging.error(f\"Invalid alpha_str value: {alpha_str}. Must be 'symmetric', 'asymmetric', or a numeric value.\")\n",
    "        raise ValueError(f\"Invalid alpha_str value: {alpha_str}. Must be 'symmetric', 'asymmetric', or a numeric value.\")\n",
    "    if isinstance(beta_str, str) and beta_str not in valid_strings:\n",
    "        logging.error(f\"Invalid beta_str value: {beta_str}. Must be 'symmetric', or a numeric value.\")\n",
    "        raise ValueError(f\"Invalid beta_str value: {beta_str}. Must be 'symmetric', or a numeric value.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method futures_create_lda_datasets is designed to read a JSON file containing a list of lists of tokens and yield batches \\\n",
    "of these tokens for training and evaluation purposes. However, there are several reasons why this method might not return \\ \n",
    "exactly N lists of tokens from the data structure: \\\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Data Length: The method assumes that the JSON file contains at least N records (lists of tokens). \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If the actual number of records in the JSON file is less than 25, then data[:25] will return fewer than 25 lists. \\\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Batch Size: The method divides the data into batches according to the batch_size parameter. If batch_size \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;is greater than or equal to 25, then only one batch will be yielded (which could be either 'train' or 'eval' type depending on train_ratio). \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If batch_size is smaller than 25, multiple batches will be yielded until all available data has been used. \\\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Train Ratio: The train_ratio parameter determines how many samples are used for training versus evaluation. Depending on \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;this ratio and the batch size, you may get a different number of 'train' and 'eval' batches.\\\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Loop Conditions: The while loop continues yielding batches until both train_count < num_train_samples and eval_count < num_samples conditions are no longer true. \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This means that if there are fewer than 25 records after applying the train ratio split, you might not get exactly 25 lists even if your initial dataset had more than that. \\\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Indexing Error: There's an error in your cumulative count update logic within each loop iteration: \\\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For training: You should increment by len(train_data_batch) instead of doubling up with both incrementing \\\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;by len(train_data_batch) and then adding it again with cumulative_count += train_count. \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For evaluation: You should increment by just len(eval_data_batch), but instead, you're \\\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;adding both eval count (cumulative_count += eval_count) which leads to an incorrect cumulative count. \\\n",
    "\n",
    "To ensure that you get exactly 25 lists (if available), consider adjusting your code as follows:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Make sure your input JSON file contains at least 25 records. \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set your batch size appropriately so that it divides into your  dataset size evenly. \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Adjust your train/eval split so that it aligns with your goal of getting exactly 25 lists. \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!!! DO NOT EXECUTE THIS CELL OR ANY CELL USING IT WITHOUT FIRSST\n",
    "!!! UPDATING THE OUTPUT FILEPATH FOR THE TRAINING AND EVAL DATA\n",
    "\"\"\"\n",
    "import os\n",
    "from json import load\n",
    "import random\n",
    "\n",
    "def get_num_records(filename):\n",
    "    with open(filename, 'r') as jsonfile:\n",
    "        data = load(jsonfile)\n",
    "        data = data\n",
    "        num_samples = len(data)  # Count the total number of samples\n",
    "    return num_samples\n",
    "\n",
    "import os\n",
    "import json\n",
    "from random import shuffle\n",
    "\n",
    "def load(jsonfile):\n",
    "    return json.load(jsonfile)\n",
    "\n",
    "def futures_create_lda_datasets(filename, train_ratio, batch_size=FUTURES_BATCH_SIZE):\n",
    "    with open(filename, 'r') as jsonfile:\n",
    "        data = load(jsonfile)\n",
    "        print(f\"the number of records read from the JSON file: {len(data)}\")\n",
    "        num_samples = len(data)  # Count the total number of samples\n",
    "        print(f\"the number of documents sampled from the JSON file: {len(data)}\\n\")\n",
    "        \n",
    "        # Shuffle data indices since we can't shuffle actual lines in a file efficiently\n",
    "        indices = list(range(num_samples))\n",
    "        shuffle(indices)\n",
    "        \n",
    "        num_train_samples = int(num_samples * train_ratio)  # Calculate number of samples for training\n",
    "        \n",
    "        cumulative_count = 0  # Initialize cumulative count\n",
    "        # Initialize counters for train and eval datasets\n",
    "        train_count = 0\n",
    "        eval_count = num_train_samples\n",
    "        \n",
    "        # Yield batches as dictionaries for both train and eval datasets along with their sample count\n",
    "        while train_count < num_train_samples or eval_count < num_samples:\n",
    "            if train_count < num_train_samples:\n",
    "                # Yield a training batch\n",
    "                train_indices_batch = indices[train_count:train_count + batch_size]\n",
    "                train_data_batch = [data[idx] for idx in train_indices_batch]\n",
    "                if len(train_data_batch) > 0:\n",
    "                    yield {\n",
    "                        'type': 'train',\n",
    "                        'data': train_data_batch,\n",
    "                        'indices_batch': train_indices_batch,\n",
    "                        'cumulative_count': train_count,\n",
    "                        'num_samples': num_train_samples,\n",
    "                        'whole_dataset': data[:num_train_samples]\n",
    "                    }\n",
    "                    train_count += len(train_data_batch)\n",
    "                    cumulative_count += train_count\n",
    "            \n",
    "            if (eval_count < num_samples or train_count >= num_train_samples):\n",
    "                # Yield an evaluation batch\n",
    "                #print(\"we are in the method to create the futures trying to create the eval data.\")\n",
    "                #print(f\"the eval count is {eval_count} and the train count is {train_count} and the num train samples is {num_train_samples}\\n\")\n",
    "                eval_indices_batch = indices[eval_count:eval_count + batch_size]\n",
    "                eval_data_batch = [data[idx] for idx in eval_indices_batch]\n",
    "                #print(f\"This is the size of the eval_data_batch from the create futures method {len(eval_data_batch)}\\n\")\n",
    "                if len(eval_data_batch) > 0:\n",
    "                    yield {\n",
    "                        'type': 'eval',\n",
    "                        'data': eval_data_batch,\n",
    "                        'indices_batch': eval_indices_batch,\n",
    "                        'cumulative_count': eval_count - num_train_samples,\n",
    "                        'num_samples': num_samples - num_train_samples,\n",
    "                        'whole_dataset': data[num_train_samples:]\n",
    "                    }\n",
    "                    eval_count += len(eval_data_batch)\n",
    "                    cumulative_count += eval_count\n",
    "                \n",
    "    #garbage_collection(False,'futures_create_lda_datasets(...)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and eval dictionaries used in train_model(...) method\n",
    "def create_dictionary(filename):\n",
    "    with open(filename, 'r') as jsonfile:\n",
    "        data = load(jsonfile)\n",
    "        num_samples = len(data)  # Count the total number of samples\n",
    "        logging.info(f\"The min five with bigrams has {num_samples} sentences\")\n",
    "        return data\n",
    "#minfivedict = create_dictionary(DATA_SOURCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vis(ldaModel, filename, corpus, dictionary):\n",
    "    LOGFILE = os.path.join(IMAGE_DIR,filename)\n",
    "\n",
    "    pyLDAvis.disable_notebook()\n",
    "    vis = pyLDAvis.gensim.prepare(ldaModel, corpus, dictionary)\n",
    "\n",
    "    pyLDAvis.save_html(vis, LOGFILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import re\n",
    "# specify the chunk size for LdaModel object\n",
    "# Number of documents to be used in each training chunk\n",
    "CHUNKSIZE = (get_num_records(DATA_SOURCE)//5)\n",
    "def train_model(n_topics: int, alpha_str: list, beta_str: list, data: list, train_eval: str, chunksize=CHUNKSIZE):\n",
    "        models_data = []\n",
    "        coherehce_score_list = []\n",
    "        corpus_batch = []\n",
    "        zipped_texts = []\n",
    "        time_of_method_call = pd.to_datetime('now')\n",
    "\n",
    "        #print(\"this is an investigation into the full datafile\")\n",
    "        #pp.pprint(full_datafile)\n",
    "        # Convert the Delayed object to a Dask Bag and compute it to get the actual data\n",
    "        try:\n",
    "            streaming_documents = dask.compute(*data)\n",
    "            #print(\"these are the streaming documents\")\n",
    "            #print(streaming_documents)\n",
    "            #garbage_collection(False, 'train_model(): streaming_documents = dask.compute(*data)')\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error computing streaming_documents data: {e}\")\n",
    "            raise\n",
    "        #print(f\"This is the dtype for 'streaming_documents' {type(streaming_documents)}.\\n\")  # Should output <class 'tuple'>\n",
    "        #print(streaming_documents[0][0])     # Check the first element to see if it's as expected\n",
    "\n",
    "        # Select documents for current batch\n",
    "        batch_documents = streaming_documents\n",
    "        \n",
    "        # Create a new Gensim Dictionary for the current batch\n",
    "        try:\n",
    "            dictionary_batch = Dictionary(list(batch_documents))\n",
    "            #print(\"The dictionary was cretaed.\")\n",
    "        except TypeError:\n",
    "            print(\"Error: The data structure is not correct.\")\n",
    "        #else:\n",
    "        #    print(\"Dictionary created successfully!\")\n",
    "\n",
    "        #if isinstance(batch_documents[0], list) and all(isinstance(doc, list) for doc in batch_documents[0]):\n",
    "        #bow_out = dictionary_batch.doc2bow(batch_documents[0])\n",
    "        flattened_batch = [item for sublist in batch_documents for item in sublist]\n",
    "        #bow_out = dictionary_batch.doc2bow(flattened_batch)\n",
    "        #else:\n",
    "        #    raise ValueError(f\"Expected batch_documents[0] to be a list of token lists. Instead received {type(batch_documents[0])} with value {batch_documents[0]}\\n\")\n",
    "\n",
    "        # Iterate over each document in batch_documents\n",
    "        number_of_documents = 0\n",
    "        for doc_tokens in batch_documents:\n",
    "            # Create the bag-of-words representation for the current document using the dictionary\n",
    "            bow_out = dictionary_batch.doc2bow(doc_tokens)\n",
    "            # Append this representation to the corpus\n",
    "            corpus_batch.append(bow_out)\n",
    "            number_of_documents += 1\n",
    "        logging.info(f\"There was a total of {number_of_documents} documents added to the corpus_batch.\")\n",
    "            \n",
    "        #logger.info(f\"HERE IS THE TEXT for corpus_batch using LOGGER: {corpus_batch}\\n\")\n",
    "        #except Exception as e:\n",
    "        #    logger.error(f\"An unexpected error occurred with BOW_OUT: {e}\")\n",
    "                \n",
    "        #if isinstance(texts_out[0], list):\n",
    "        #    texts_batch.append(texts_out[0])\n",
    "        #else:\n",
    "        #    logging.error(\"Expected texts_out to be a list of strings (words), got:\", texts_out[0])\n",
    "        #    raise ValueError(\"Expected texts_out to be a list of strings (words), got:\", texts_out[0])\n",
    "                \n",
    "        n_alpha = calculate_numeric_alpha(alpha_str)\n",
    "        n_beta = calculate_numeric_beta(beta_str)\n",
    "        try:\n",
    "            #logger.info(\"we are inside the try block at the beginning\")\n",
    "            lda_model_gensim = LdaModel(corpus=corpus_batch,\n",
    "                                                id2word=dictionary_batch,\n",
    "                                                num_topics=n_topics,\n",
    "                                                alpha= float(n_alpha),\n",
    "                                                eta= float(n_beta),\n",
    "                                                random_state=RANDOM_STATE,\n",
    "                                                passes=PASSES,\n",
    "                                                iterations=ITERATIONS,\n",
    "                                                update_every=UPDATE_EVERY,\n",
    "                                                eval_every=EVAL_EVERY,\n",
    "                                                chunksize=chunksize,\n",
    "                                                per_word_topics=True)\n",
    "            #logger.info(\"we are inside the try block after the constructor\")\n",
    "\n",
    "                                          \n",
    "        except Exception as e:\n",
    "            logging.error(f\"An error occurred during LDA model training: {e}\")\n",
    "            raise  # Optionally re-raise the exception if you want it to propagate further      \n",
    "\n",
    "        ldamodel_bytes = pickle.dumps(lda_model_gensim)\n",
    "\n",
    "        #coherence_score = None  # Assign a default value\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            try:\n",
    "                #coherence_model_lda = CoherenceModel(model=lda_model_gensim, processes=math.floor(CORES*(2/3)), dictionary=dictionary_batch, texts=batch_documents[0], coherence='c_v') \n",
    "                coherence_model_lda = CoherenceModel(model=lda_model_gensim, processes=math.floor(CORES*(1/3)), dictionary=dictionary_batch, texts=batch_documents, coherence='c_v') \n",
    "                coherence_score = coherence_model_lda.get_coherence()\n",
    "                coherehce_score_list.append(coherence_score)\n",
    "            except Exception as e:\n",
    "                logging.error(\"there was an issue calculating coherence score. value 'Inf' has been assigned.\\n\")\n",
    "                coherence_score = float('inf')\n",
    "                coherehce_score_list.append(coherence_score)\n",
    "                #sys.exit()\n",
    "\n",
    "        try:\n",
    "            convergence_score = lda_model_gensim.bound(corpus_batch)\n",
    "        except Exception as e:\n",
    "            logging.error(\"there was an issue calculating convergence score. value 'Inf' has been assigned.\\n\")\n",
    "            convergence_score = float('inf')\n",
    "                    \n",
    "        try:\n",
    "            perplexity_score = lda_model_gensim.log_perplexity(corpus_batch)\n",
    "        except RuntimeWarning as e:\n",
    "            logging.info(\"there was an issue calculating perplexity score. value 'Inf' has been assigned.\\n\")\n",
    "            perplexity_score = float('inf')\n",
    "            #sys.exit()\n",
    "        \n",
    "        # Initialize top_words as an empty list\n",
    "        top_words = []\n",
    "\n",
    "        # Assuming lda_model_gensim is already trained and available\n",
    "        for topic_str, word_probs in lda_model_gensim.show_topics(num_topics=15, num_words=25):\n",
    "            # Extract words from the formatted string using regular expressions\n",
    "            # The pattern assumes that words are within double quotes\n",
    "            words = re.findall(r'\"(.*?)\"', word_probs)\n",
    "            # Extend the top_words list with these individual words\n",
    "            top_words.extend(words)\n",
    "        #pp.pprint(top_words)\n",
    "            \n",
    "       #print(f\"type: {train_eval}, coherence: {coherence_score}, n_topics: {n_topics}, n_alpha: {n_alpha}, alpha_str: {alpha_str}, n_beta: {n_beta}, beta_str: {beta_str}\")\n",
    "        logging.info(f\"type: {train_eval}, coherence: {coherence_score}, n_topics: {n_topics}, n_alpha: {n_alpha}, alpha_str: {alpha_str}, n_beta: {n_beta}, beta_str: {beta_str}\\n      batch documents: {batch_documents}\\n\")     \n",
    "\n",
    "        # transform list of tokens comprising the doc into a single string\n",
    "        string_result = ' '.join(map(str, flattened_batch))\n",
    "\n",
    "\n",
    "        # Convert numeric beta value to string if necessary\n",
    "        if isinstance(beta_str, float):\n",
    "            beta_str = str(beta_str)\n",
    "                \n",
    "        # Convert numeric alpha value to string if necessary\n",
    "        if isinstance(alpha_str, float):\n",
    "            alpha_str = str(alpha_str)\n",
    "\n",
    "        current_increment_data = {\n",
    "                'type': train_eval, \n",
    "                'batch_size': BATCH_SIZE,\n",
    "                'text': [string_result],\n",
    "                'text_sha256': hashlib.sha256(string_result.encode()).hexdigest(),\n",
    "                'text_md5': hashlib.md5(string_result.encode()).hexdigest(),\n",
    "                'convergence': convergence_score,\n",
    "                'perplexity': perplexity_score,\n",
    "                'coherence': coherence_score,\n",
    "                'topics': n_topics,\n",
    "                'alpha_str': [alpha_str],\n",
    "                'n_alpha': calculate_numeric_alpha(alpha_str),\n",
    "                'beta_str': [beta_str],\n",
    "                'n_beta': calculate_numeric_beta(beta_str),\n",
    "                'passes': PASSES,\n",
    "                'iterations': ITERATIONS,\n",
    "                'update_every': UPDATE_EVERY,\n",
    "                'eval_every': EVAL_EVERY,\n",
    "                'chunksize': CHUNKSIZE,\n",
    "                'random_state': RANDOM_STATE,\n",
    "                'per_word_topics': PER_WORD_TOPICS,\n",
    "                'top_words': [top_words],\n",
    "                'lda_model': ldamodel_bytes,\n",
    "                'time': time_of_method_call\n",
    "        }\n",
    "\n",
    "        models_data.append(current_increment_data)\n",
    "        #garbage_collection(False, 'train_model(): convergence and perplexity score calculations')\n",
    "        del batch_documents, streaming_documents, lda_model_gensim, current_increment_data, dictionary_batch\n",
    "\n",
    "        return models_data\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a delayed version of the train_model function\n",
    "@dask.delayed\n",
    "def delayed_train_model(n_topics, alpha_value, beta_value, scattered_data, train_eval_type):\n",
    "    # Call the train_model function here\n",
    "    train_model(n_topics, alpha_value, beta_value, scattered_data, train_eval_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "                    - The `process_completed_future` function is called when all futures in a batch complete within the specified timeout. It \n",
    "                        can be used to continue with your program using both completed training and evaluation futures.\n",
    "                    - The `retry_processing` function is called when there are incomplete futures after iterating through a batch of \n",
    "                        data. It can be used to retry processing with those incomplete futures.\n",
    "                    - The code checks if there are any remaining futures in the lists after completing all iterations. If so, it \n",
    "                        waits for them to complete and handles them accordingly.\n",
    "\"\"\"\n",
    "\n",
    "# List to store parameters of models that failed to complete even after a retry\n",
    "failed_model_params = []\n",
    "\n",
    "# Mapping from futures to their corresponding parameters (n_topics, alpha_value, beta_value)\n",
    "future_to_params = {}\n",
    "def process_completed_futures(completed_train_futures, completed_eval_futures, log_dir):\n",
    "    #print(\"we are in the process_completed_futures method()\")\n",
    "    # Process training futures\n",
    "    for future in completed_train_futures:\n",
    "        try:\n",
    "            # Retrieve the result of the training future\n",
    "            #if isinstance(future.result(), list):\n",
    "            models_data = future.result()  # This should be a list of dictionaries\n",
    "            if not isinstance(models_data, list):\n",
    "                models_data = list(future.result())  # This should be a list of dictionaries\n",
    "            #logging.info(f\"this is the value of the TRAIN MODELS_DATA within the process_completed method: {models_data}\")\n",
    "            #else:\n",
    "            #    models_data = list(future.result())\n",
    "            #print(\"this is the value of models data:\", models_data)\n",
    "            \n",
    "        except TypeError as e:\n",
    "            logging.error(f\"Error occurred during training: {e}\")\n",
    "            #sys.exit()\n",
    "        else:\n",
    "            # Iterate over each model's data and save it\n",
    "            for model_data in models_data:\n",
    "                # Check if models_data is a non-empty list before iterating\n",
    "                if isinstance(models_data, list) and models_data:\n",
    "                    for model_data in models_data:\n",
    "                        #logging.info(f\"this is the value of model TRAIN data: {model_data}\")\n",
    "                        #save_model_and_log(model_data=model_data, log_dir=log_dir, train_or_eval=True)\n",
    "                        add_model_data_to_metadata(model_data)\n",
    "                else:\n",
    "                    # Handle the case where models_data is not as expected\n",
    "                    logging.info(f\"Received unexpected result from TRAIN future: {models_data}\")\n",
    "\n",
    "    # Process evaluation futures\n",
    "    for future in completed_eval_futures:\n",
    "        try:\n",
    "            # Retrieve the result of the training future\n",
    "            #if isinstance(future.result(), list):\n",
    "            models_data = future.result()  # This should be a list of dictionaries\n",
    "            if not isinstance(models_data, list):\n",
    "                models_data = list(future.result())  # This should be a list of dictionaries\n",
    "            #logging.info(f\"this is the value of the EVAL MODELS_DATA within the process_completed method: {models_data}\")\n",
    "            #else:\n",
    "            #    models_data = list(future.result())\n",
    "            #print(\"this is the value of models data:\", models_data)\n",
    "        except TypeError as e:\n",
    "            logging.error(f\"Error occurred during evaluation: {e}\")\n",
    "            sys.exit()\n",
    "        else:\n",
    "            # Iterate over each model's data and save it\n",
    "            for model_data in models_data:\n",
    "                # Check if models_data is a non-empty list before iterating\n",
    "                if isinstance(models_data, list) and models_data:\n",
    "                    for model_data in models_data:\n",
    "                        #logging.info(f\"this is the value of model EVAL data: {model_data}\")\n",
    "                        #save_model_and_log(model_data=model_data, log_dir=log_dir, train_or_eval=False)\n",
    "                        add_model_data_to_metadata(model_data)\n",
    "                else:\n",
    "                    # Handle the case where models_data is not as expected\n",
    "                    logging.info(f\"Received unexpected result from EVAL future: {models_data}\")\n",
    "                \n",
    "    #garbage_collection(False, 'process_completed_futures(...)')\n",
    "    del completed_eval_futures, completed_train_futures, models_data\n",
    "\n",
    "            \n",
    "# Function to retry processing with incomplete futures\n",
    "def retry_processing(incomplete_train_futures, incomplete_eval_futures, timeout=None):\n",
    "    #print(\"we are in the retry_processing method()\")\n",
    "    # Retry processing with incomplete futures using an extended timeout\n",
    "    # Process completed ones after reattempting\n",
    "    #done_train = [f for f in done if f in train_futures]\n",
    "    #done_eval = [f for f in done if f in eval_futures]\n",
    "    # Wait for completion of eval_futures\n",
    "    done_eval, not_done_eval = wait(incomplete_eval_futures, timeout=timeout)  # return_when='FIRST_COMPLETED'\n",
    "    #print(f\"This is the size of the done_eval list: {len(done_eval)} and this is the size of the not_done_eval list: {len(not_done_eval)}\")\n",
    "\n",
    "    # Wait for completion of train_futures\n",
    "    done_train, not_done_train = wait(incomplete_train_futures, timeout=timeout)  # return_when='FIRST_COMPLETED'\n",
    "    #print(f\"This is the size of the done_train list: {len(done_train)} and this is the size of the not_done_train list: {len(not_done_train)}\")\n",
    "\n",
    "    done = done_train.union(done_eval)\n",
    "    not_done = not_done_eval.union(not_done_train)\n",
    "                \n",
    "    #print(f\"WAIT completed in {elapsed_time} minutes\")\n",
    "    #print(f\"This is the size of DONE {len(done)}. And this is the size of NOT_DONE {len(not_done)}\\n\")\n",
    "    #print(f\"this is the value of done_train {done_train}\")\n",
    "\n",
    "    completed_train_futures = [f for f in done_train]\n",
    "    #print(f\"We have completed the TRAIN list comprehension. The size is {len(completed_train_futures)}\")\n",
    "    #print(f\"This is the length of the TRAIN completed_train_futures var {len(completed_train_futures)}\")\n",
    "            \n",
    "    completed_eval_futures = [f for f in done_eval]\n",
    "    #print(f\"We have completed the EVAL list comprehension. The size is {len(completed_eval_futures)}\")\n",
    "    #print(f\"This is the length of the EVAL completed_eval_futures var {len(completed_eval_futures)}\")\n",
    "\n",
    "    #logging.info(f\"This is the size of completed_train_futures {len(completed_train_futures)} and this is the size of completed_eval_futures {len(completed_eval_futures)}\")\n",
    "    if len(completed_eval_futures) > 0 or len(completed_train_futures) > 0:\n",
    "        process_completed_futures(completed_train_futures, completed_eval_futures, LOG_DIR) \n",
    "    \n",
    "    # Record parameters of still incomplete futures for later review\n",
    "    failed_model_params.extend(future_to_params[future] for future in not_done)\n",
    "    print(\"We have exited the retry_preprocessing() method.\")\n",
    "    logging.info(f\"There were {len(not_done_eval)} EVAL documents that couldn't be processed in retry_processing().\")\n",
    "    logging.info(f\"There were {len(not_done_train)} TRAIN documents that couldn't be processed in retry_processing().\")\n",
    "\n",
    "    #garbage_collection(False, 'retry_processing(...)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to keep track of retries for each task\n",
    "task_retries = {}\n",
    "\n",
    "# Function to perform exponential backoff\n",
    "def exponential_backoff(attempt):\n",
    "    return BASE_WAIT_TIME * (2 ** attempt)\n",
    "\n",
    "# Function to handle failed futures and potentially retry them\n",
    "def handle_failed_future(future, future_to_params, train_futures, eval_futures, client):\n",
    "    print(\"We are in the handle_failed_future() method.\\n\")\n",
    "    params = future_to_params[future]\n",
    "    attempt = task_retries.get(params, 0)\n",
    "    \n",
    "    if attempt < MAX_RETRIES:\n",
    "        print(f\"Retrying task {params} (attempt {attempt + 1}/{MAX_RETRIES})\")\n",
    "        wait_time = exponential_backoff(attempt)\n",
    "        sleep(wait_time)  \n",
    "        \n",
    "        task_retries[params] = attempt + 1\n",
    "        \n",
    "        new_future_train = client.submit(train_model, *params)\n",
    "        new_future_eval = client.submit(train_model, *params)\n",
    "        \n",
    "        future_to_params[new_future_train] = params\n",
    "        future_to_params[new_future_eval] = params\n",
    "        \n",
    "        train_futures.append(new_future_train)\n",
    "        eval_futures.append(new_future_eval)\n",
    "    else:\n",
    "        print(f\"Task {params} failed after {MAX_RETRIES} attempts. No more retries.\")\n",
    "\n",
    "    #garbage_collection(False,'handle_failed_future')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous Execution as said by Brunhilda:\n",
    "\n",
    "Asynchronous execution allows you to execute tasks concurrently, without waiting for each task to complete before moving on \\\n",
    "to the next one. This can improve the overall efficiency and speed of your program.\n",
    "\n",
    "In the given code snippet, asynchronous execution is achieved using Dask's as_completed function. This function takes a list \\\n",
    "of futures (representing tasks) and returns an iterator that yields futures as they complete.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;(1) First, you submit all your training and evaluation tasks using client.submit(). These tasks are represented by futures. \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;(2) You add callback functions (callback_train and callback_eval) to these futures using the add_done_callback() method. These callbacks will be executed when their respective futures complete.\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;(3) You create two lists, train_futures and eval_futures, to store the futures for training and evaluation models respectively.\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;(4) After submitting all the tasks, you enter a loop where you iterate over the range of values for n_topics, alpha_value, and beta_value.\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;(5) Inside this loop, you submit the training and evaluation tasks for each combination of parameters using client.submit(). These new futures are added to their respective lists.\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;(6) Next, you use the as_completed function to iterate over both lists of futures (train_futures and eval_futures). This function returns an iterator that yields completed futures as they become available.\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;(7) As each future completes, its associated callback function (callback_train or callback_eval) is executed.\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;(8) Inside these callback functions, you retrieve the result of the completed future using .result(). You can then save the trained or evaluated model using the provided save_model_and_log function.\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;(9) The loop continues until all combinations of parameters have been processed.\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;(10) Finally, after all models have been saved and logged, you close the Dask client. \n",
    "\n",
    "By utilizing asynchronous execution with Dask's as_completed, your program can process multiple tasks concurrently while still ensuring that each model is saved once its associated task has completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask client is connected to a scheduler.\n",
      "Dask workers are running.\n",
      "Creating training and evaluation samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8495 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of records read from the JSON file: 8495\n",
      "the number of documents sampled from the JSON file: 8495\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8599it [00:10, 826.43it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed creation of training and evaluation documents in 0.17 minutes.\n",
      "\n",
      "Data scatter complete...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models:   0%|          | 0/495 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The random sample combinations contains 495\n",
      "this leaves 825 remaining\n",
      "\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 16:36:25,736 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:51019'.\n",
      "2024-09-06 16:36:26,445 - distributed.worker - WARNING - Scheduler was unaware of this worker; shutting down.\n",
      "2024-09-06 16:36:51,037 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:51022'.\n",
      "2024-09-06 16:36:51,117 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51022\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 16:36:51,259 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51022\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:51167 remote=tcp://127.0.0.1:51022>: Stream is closed\n",
      "2024-09-06 16:36:51,637 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51022\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:51155 remote=tcp://127.0.0.1:51022>: Stream is closed\n",
      "2024-09-06 16:36:51,711 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51022\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:51101 remote=tcp://127.0.0.1:51022>: Stream is closed\n",
      "2024-09-06 16:36:51,764 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51022\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:51226 remote=tcp://127.0.0.1:51022>: Stream is closed\n",
      "2024-09-06 16:36:51,820 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51022\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 16:36:51,865 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51022 -> tcp://127.0.0.1:51202\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51022 remote=tcp://127.0.0.1:51226>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 16:36:51,887 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51022 -> tcp://127.0.0.1:51043\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51022 remote=tcp://127.0.0.1:51101>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 16:36:51,911 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51022 -> tcp://127.0.0.1:51040\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51022 remote=tcp://127.0.0.1:51167>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 16:36:52,729 - distributed.worker - WARNING - Scheduler was unaware of this worker; shutting down.\n",
      "2024-09-06 16:36:52,744 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51022 -> tcp://127.0.0.1:51205\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51022 remote=tcp://127.0.0.1:51214>: Stream is closed\n",
      "2024-09-06 16:36:52,769 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51022 -> tcp://127.0.0.1:51031\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51022 remote=tcp://127.0.0.1:51155>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 16:36:52,803 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51022 -> tcp://127.0.0.1:51034\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51022 remote=tcp://127.0.0.1:51186>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 7.52 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models:   6%|         | 29/495 [07:40<2:03:18, 15.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 600\n",
      "In holding pattern until WAIT completes.\n",
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 2.58 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models:  12%|        | 58/495 [10:22<1:11:31,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 16:46:05,213 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51202\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:51616 remote=tcp://127.0.0.1:51202>: Stream is closed\n",
      "2024-09-06 16:46:05,213 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51202\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:52079 remote=tcp://127.0.0.1:51202>: Stream is closed\n",
      "2024-09-06 16:46:05,224 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51202\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:51368 remote=tcp://127.0.0.1:51202>: Stream is closed\n",
      "2024-09-06 16:46:05,230 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51202\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:51704 remote=tcp://127.0.0.1:51202>: Stream is closed\n",
      "2024-09-06 16:46:06,048 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51043\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:51160 remote=tcp://127.0.0.1:51043>: Stream is closed\n",
      "2024-09-06 16:46:06,053 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51043\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:52433 remote=tcp://127.0.0.1:51043>: Stream is closed\n",
      "2024-09-06 16:46:06,120 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51043 -> tcp://127.0.0.1:51031\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51043 remote=tcp://127.0.0.1:51160>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 16:46:06,147 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils_comm.py\", line 459, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils_comm.py\", line 438, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51071 remote=tcp://127.0.0.1:51016>: Stream is closed\n",
      "2024-09-06 16:46:06,164 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:51043'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 5.94 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models:  18%|        | 87/495 [16:30<1:15:45, 11.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 16:52:21,288 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51825\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 16:52:21,347 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51825 -> tcp://127.0.0.1:52562\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51825 remote=tcp://127.0.0.1:52932>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 6.11 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models:  23%|       | 116/495 [22:48<1:15:05, 11.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 16:59:15,540 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51046\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:51174 remote=tcp://127.0.0.1:51046>: Stream is closed\n",
      "2024-09-06 16:59:15,542 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51046\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:51123 remote=tcp://127.0.0.1:51046>: Stream is closed\n",
      "2024-09-06 16:59:15,609 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51046 -> tcp://127.0.0.1:51040\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51046 remote=tcp://127.0.0.1:51174>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 16:59:15,615 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51046 -> tcp://127.0.0.1:51025\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51046 remote=tcp://127.0.0.1:51123>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 6.34 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models:  29%|       | 145/495 [29:16<1:12:26, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n",
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 5.73 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models:  35%|      | 174/495 [35:09<1:06:01, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 17:08:41,313 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:52089\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:52540 remote=tcp://127.0.0.1:52089>: Stream is closed\n",
      "2024-09-06 17:08:41,332 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:52089\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:53521 remote=tcp://127.0.0.1:52089>: Stream is closed\n",
      "2024-09-06 17:08:41,339 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:52089\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:52537 remote=tcp://127.0.0.1:52089>: Stream is closed\n",
      "2024-09-06 17:08:41,347 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:52089\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:53984 remote=tcp://127.0.0.1:52089>: Stream is closed\n",
      "2024-09-06 17:08:41,439 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:52089 -> tcp://127.0.0.1:51025\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:52089 remote=tcp://127.0.0.1:52538>: Stream is closed\n",
      "2024-09-06 17:08:47,489 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:52089\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 2.99 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models:  41%|      | 203/495 [38:22<50:59, 10.48s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 17:15:10,878 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:54336'.\n",
      "2024-09-06 17:15:10,952 - distributed.worker - WARNING - Scheduler was unaware of this worker; shutting down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 7.26 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models:  47%|     | 232/495 [45:47<52:42, 12.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n",
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 5.48 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models:  53%|    | 261/495 [51:22<46:19, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n",
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 5.03 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models:  59%|    | 290/495 [56:30<39:15, 11.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 17:31:41,554 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51031\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:56096 remote=tcp://127.0.0.1:51031>: Stream is closed\n",
      "2024-09-06 17:31:41,571 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51031\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 17:31:41,571 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51031\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 17:31:41,571 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51031\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 17:31:41,651 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51031 -> tcp://127.0.0.1:51025\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51031 remote=tcp://127.0.0.1:51124>: Stream is closed\n",
      "2024-09-06 17:31:41,662 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51031 -> tcp://127.0.0.1:54872\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51031 remote=tcp://127.0.0.1:54886>: Stream is closed\n",
      "2024-09-06 17:31:41,682 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51031 -> tcp://127.0.0.1:55334\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51031 remote=tcp://127.0.0.1:55762>: Stream is closed\n",
      "2024-09-06 17:31:41,686 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51031 -> tcp://127.0.0.1:55776\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51031 remote=tcp://127.0.0.1:56096>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 17:31:41,715 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils_comm.py\", line 459, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils_comm.py\", line 438, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51069 remote=tcp://127.0.0.1:51016>: Stream is closed\n",
      "2024-09-06 17:31:41,726 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:51031'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 4.88 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models:  64%|   | 319/495 [1:01:31<32:42, 11.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 17:39:25,914 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:55334\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:56751 remote=tcp://127.0.0.1:55334>: Stream is closed\n",
      "2024-09-06 17:39:26,020 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:55334 -> tcp://127.0.0.1:53996\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:55334 remote=tcp://127.0.0.1:55759>: Stream is closed\n",
      "2024-09-06 17:39:26,039 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:55334 -> tcp://127.0.0.1:55779\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:55334 remote=tcp://127.0.0.1:56146>: Stream is closed\n",
      "2024-09-06 17:39:27,364 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:55334\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 17:39:27,369 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:55334\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 8.16 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models:  70%|   | 348/495 [1:09:48<31:47, 12.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n",
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 9.21 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models:  76%|  | 377/495 [1:19:07<29:16, 14.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n",
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 6.19 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models:  82%| | 406/495 [1:25:29<21:18, 14.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n",
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 4.26 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models:  88%| | 435/495 [1:29:57<12:49, 12.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 18:04:42,800 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:55779\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:56127 remote=tcp://127.0.0.1:55779>: Stream is closed\n",
      "2024-09-06 18:04:42,804 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:55779\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:58851 remote=tcp://127.0.0.1:55779>: Stream is closed\n",
      "2024-09-06 18:04:42,806 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:55779\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:59156 remote=tcp://127.0.0.1:55779>: Stream is closed\n",
      "2024-09-06 18:04:42,811 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:55779 -> tcp://127.0.0.1:58867\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:55779 remote=tcp://127.0.0.1:59156>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 18:04:42,839 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:55779 -> tcp://127.0.0.1:51205\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:55779 remote=tcp://127.0.0.1:56127>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 18:04:42,843 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:55779 -> tcp://127.0.0.1:58372\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:55779 remote=tcp://127.0.0.1:58851>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 4.38 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models:  94%|| 464/495 [1:34:33<06:06, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n",
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 6.5 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models: 100%|| 493/495 [1:41:14<00:24, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 18:17:18,903 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:56234\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 18:17:18,916 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:56234\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:59845 remote=tcp://127.0.0.1:56234>: Stream is closed\n",
      "2024-09-06 18:17:18,919 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:56234\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:60176 remote=tcp://127.0.0.1:56234>: Stream is closed\n",
      "2024-09-06 18:17:18,962 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:56234 -> tcp://127.0.0.1:58372\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:56234 remote=tcp://127.0.0.1:58854>: Stream is closed\n",
      "2024-09-06 18:17:18,967 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:56234 -> tcp://127.0.0.1:51205\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:56234 remote=tcp://127.0.0.1:56899>: Stream is closed\n",
      "2024-09-06 18:17:19,094 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:56234 -> tcp://127.0.0.1:59853\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 297, in write\n",
      "    raise StreamClosedError()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1777, in get_data\n",
      "    compressed = await comm.write(msg, serializers=serializers)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 307, in write\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:56234 remote=tcp://127.0.0.1:60176>: Stream is closed\n",
      "2024-09-06 18:17:19,155 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:56234\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 5.9 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models: 522it [1:47:17, 12.46s/it]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 18:24:23,771 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:59842'.\n",
      "2024-09-06 18:24:24,097 - distributed.worker - WARNING - Scheduler was unaware of this worker; shutting down.\n",
      "2024-09-06 18:24:29,396 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:58372\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:59828 remote=tcp://127.0.0.1:58372>: Stream is closed\n",
      "2024-09-06 18:24:29,430 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:58372 -> tcp://127.0.0.1:59251\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:58372 remote=tcp://127.0.0.1:59828>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 7.43 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models: 551it [1:54:50, 13.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 18:28:28,642 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51040\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 18:28:28,645 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:51040'.\n",
      "2024-09-06 18:28:28,669 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51040\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:61145 remote=tcp://127.0.0.1:51040>: Stream is closed\n",
      "2024-09-06 18:28:28,676 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51040 -> tcp://127.0.0.1:60944\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51040 remote=tcp://127.0.0.1:61145>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 18:28:28,695 - distributed.worker - WARNING - Scheduler was unaware of this worker; shutting down.\n",
      "2024-09-06 18:28:28,697 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51040 -> tcp://127.0.0.1:51034\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51040 remote=tcp://127.0.0.1:51194>: Stream is closed\n",
      "2024-09-06 18:28:28,721 - tornado.application - ERROR - Exception in callback functools.partial(<function TCPServer._handle_connection.<locals>.<lambda> at 0x0000017BDDBC9800>, <Task finished name='Task-7146672' coro=<BaseTCPListener._handle_stream() done, defined at c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py:654> exception=ValueError('invalid operation on non-started TCPListener')>)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\ioloop.py\", line 750, in _run_callback\n",
      "    ret = callback()\n",
      "          ^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\tcpserver.py\", line 387, in <lambda>\n",
      "    gen.convert_yielded(future), lambda f: f.result()\n",
      "                                           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 660, in _handle_stream\n",
      "    logger.debug(\"Incoming connection from %r to %r\", address, self.contact_address)\n",
      "                                                               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 696, in contact_address\n",
      "    host, port = self.get_host_port()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 677, in get_host_port\n",
      "    self._check_started()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 652, in _check_started\n",
      "    raise ValueError(\"invalid operation on non-started TCPListener\")\n",
      "ValueError: invalid operation on non-started TCPListener\n",
      "2024-09-06 18:28:28,775 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51040\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1481, in connect\n",
      "    return await self._connect(addr=addr, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "                ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:61220 remote=tcp://127.0.0.1:51040>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 2.88 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models: 580it [1:57:53, 11.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 18:33:49,290 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:60944'.\n",
      "2024-09-06 18:33:49,307 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:60944\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:61293 remote=tcp://127.0.0.1:60944>: Stream is closed\n",
      "2024-09-06 18:33:49,404 - distributed.worker - WARNING - Scheduler was unaware of this worker; shutting down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 5.73 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models: 609it [2:03:45, 11.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 18:39:14,973 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51205\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:60930 remote=tcp://127.0.0.1:51205>: Stream is closed\n",
      "2024-09-06 18:39:14,977 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51205\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:61776 remote=tcp://127.0.0.1:51205>: Stream is closed\n",
      "2024-09-06 18:39:14,977 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51205\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:55322 remote=tcp://127.0.0.1:51205>: Stream is closed\n",
      "2024-09-06 18:39:14,977 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51205\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:51816 remote=tcp://127.0.0.1:51205>: Stream is closed\n",
      "2024-09-06 18:39:14,986 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51205\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:60392 remote=tcp://127.0.0.1:51205>: Stream is closed\n",
      "2024-09-06 18:39:14,990 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51205 -> tcp://127.0.0.1:60381\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51205 remote=tcp://127.0.0.1:60930>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 18:39:14,992 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51205 -> tcp://127.0.0.1:54875\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51205 remote=tcp://127.0.0.1:55322>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 18:39:14,994 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51205 -> tcp://127.0.0.1:61298\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51205 remote=tcp://127.0.0.1:61776>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 18:39:15,013 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51205 -> tcp://127.0.0.1:61790\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51205 remote=tcp://127.0.0.1:62125>: Stream is closed\n",
      "2024-09-06 18:39:15,018 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51205 -> tcp://127.0.0.1:51034\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51205 remote=tcp://127.0.0.1:51818>: Stream is closed\n",
      "2024-09-06 18:39:15,022 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51205 -> tcp://127.0.0.1:59248\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51205 remote=tcp://127.0.0.1:59836>: Stream is closed\n",
      "2024-09-06 18:39:15,227 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51205 -> tcp://127.0.0.1:60373\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 297, in write\n",
      "    raise StreamClosedError()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1777, in get_data\n",
      "    compressed = await comm.write(msg, serializers=serializers)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 307, in write\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51205 remote=tcp://127.0.0.1:60392>: Stream is closed\n",
      "2024-09-06 18:39:15,228 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51205 -> tcp://127.0.0.1:51025\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 297, in write\n",
      "    raise StreamClosedError()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1777, in get_data\n",
      "    compressed = await comm.write(msg, serializers=serializers)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 307, in write\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51205 remote=tcp://127.0.0.1:51816>: Stream is closed\n",
      "2024-09-06 18:39:15,248 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51205\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 18:39:15,251 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51205\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 18:39:15,255 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51205\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 5.23 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models: 638it [2:09:06, 11.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 18:45:09,607 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59248\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:62189 remote=tcp://127.0.0.1:59248>: Stream is closed\n",
      "2024-09-06 18:45:09,615 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59248\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:59819 remote=tcp://127.0.0.1:59248>: Stream is closed\n",
      "2024-09-06 18:45:09,624 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59248\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:62264 remote=tcp://127.0.0.1:59248>: Stream is closed\n",
      "2024-09-06 18:45:09,636 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:59248 -> tcp://127.0.0.1:51025\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:59248 remote=tcp://127.0.0.1:59819>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 18:45:09,682 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:59248 -> tcp://127.0.0.1:51034\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:59248 remote=tcp://127.0.0.1:60357>: Stream is closed\n",
      "2024-09-06 18:45:09,689 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:59248 -> tcp://127.0.0.1:61298\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:59248 remote=tcp://127.0.0.1:61778>: Stream is closed\n",
      "2024-09-06 18:45:09,692 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:59248 -> tcp://127.0.0.1:59251\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:59248 remote=tcp://127.0.0.1:59829>: Stream is closed\n",
      "2024-09-06 18:45:09,692 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:59248 -> tcp://127.0.0.1:61790\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:59248 remote=tcp://127.0.0.1:62189>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 18:45:09,700 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:59248 -> tcp://127.0.0.1:60373\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:59248 remote=tcp://127.0.0.1:60390>: Stream is closed\n",
      "2024-09-06 18:45:09,711 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:59248 -> tcp://127.0.0.1:54875\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:59248 remote=tcp://127.0.0.1:59826>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 18:45:09,719 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59248\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:62600 remote=tcp://127.0.0.1:59248>: Stream is closed\n",
      "2024-09-06 18:45:09,723 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59248\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:59840 remote=tcp://127.0.0.1:59248>: Stream is closed\n",
      "2024-09-06 18:45:09,723 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59248\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:59826 remote=tcp://127.0.0.1:59248>: Stream is closed\n",
      "2024-09-06 18:45:09,775 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:59248 -> tcp://127.0.0.1:62261\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:59248 remote=tcp://127.0.0.1:62600>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 18:45:09,785 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:59248 -> tcp://127.0.0.1:60381\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:59248 remote=tcp://127.0.0.1:60398>: Stream is closed\n",
      "2024-09-06 18:45:11,156 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59248\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 18:45:11,156 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59248\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 18:45:11,166 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59248\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 18:45:11,169 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59248\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 18:45:11,174 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59248\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 18:45:13,623 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 7.76 GiB -- Worker memory limit: 11.18 GiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 5.9 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models: 667it [2:15:10, 11.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 18:49:31,493 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:60373'.\n",
      "2024-09-06 18:49:31,593 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:60373\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:63017 remote=tcp://127.0.0.1:60373>: Stream is closed\n",
      "2024-09-06 18:49:31,614 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:60373\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:63018 remote=tcp://127.0.0.1:60373>: Stream is closed\n",
      "2024-09-06 18:49:31,810 - distributed.worker - WARNING - Scheduler was unaware of this worker; shutting down.\n",
      "2024-09-06 18:49:31,835 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:60373 -> tcp://127.0.0.1:62771\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:60373 remote=tcp://127.0.0.1:63018>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 18:49:31,844 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:60373 -> tcp://127.0.0.1:62774\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:60373 remote=tcp://127.0.0.1:63017>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 3.92 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models: 696it [2:19:17, 10.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 18:58:13,912 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 7.53 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 18:58:46,009 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:54875'.\n",
      "2024-09-06 18:58:46,098 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:54875\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:63045 remote=tcp://127.0.0.1:54875>: Stream is closed\n",
      "2024-09-06 18:58:46,105 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:54875\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 18:58:46,108 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:54875\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:55329 remote=tcp://127.0.0.1:54875>: Stream is closed\n",
      "2024-09-06 18:58:46,108 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:54875\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:55230 remote=tcp://127.0.0.1:54875>: Stream is closed\n",
      "2024-09-06 18:58:46,108 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:54875 -> tcp://127.0.0.1:51037\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:54875 remote=tcp://127.0.0.1:55230>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 18:58:46,117 - distributed.worker - WARNING - Scheduler was unaware of this worker; shutting down.\n",
      "2024-09-06 18:58:46,157 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:54875 -> tcp://127.0.0.1:63136\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:54875 remote=tcp://127.0.0.1:63681>: Stream is closed\n",
      "2024-09-06 18:58:46,160 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:54875 -> tcp://127.0.0.1:51034\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:54875 remote=tcp://127.0.0.1:55329>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 18:58:46,162 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:54875 -> tcp://127.0.0.1:62774\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:54875 remote=tcp://127.0.0.1:63045>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 18:58:56,476 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:63136\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:63824 remote=tcp://127.0.0.1:63136>: Stream is closed\n",
      "2024-09-06 18:58:56,483 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:63136 -> tcp://127.0.0.1:51025\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:63136 remote=tcp://127.0.0.1:63824>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 9.9 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models: 725it [2:29:20, 13.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:03:30,270 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:62257\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 19:03:30,302 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:62257'.\n",
      "2024-09-06 19:03:30,327 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:62257 -> tcp://127.0.0.1:63934\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:62257 remote=tcp://127.0.0.1:64153>: Stream is closed\n",
      "2024-09-06 19:03:30,346 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils_comm.py\", line 459, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils_comm.py\", line 438, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:62260 remote=tcp://127.0.0.1:51016>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 3.51 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models: 754it [2:33:07, 11.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:10:09,086 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:63934\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:64289 remote=tcp://127.0.0.1:63934>: Stream is closed\n",
      "2024-09-06 19:10:09,093 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:63934 -> tcp://127.0.0.1:62774\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:63934 remote=tcp://127.0.0.1:64289>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 19:10:22,158 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:62771'.\n",
      "2024-09-06 19:10:22,309 - distributed.worker - WARNING - Scheduler was unaware of this worker; shutting down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 7.58 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models: 783it [2:40:56, 13.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:15:23,669 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:63133'.\n",
      "2024-09-06 19:15:23,735 - distributed.worker - WARNING - Scheduler was unaware of this worker; shutting down.\n",
      "2024-09-06 19:15:23,770 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:63133\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 19:15:23,791 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:63133 -> tcp://127.0.0.1:64301\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:63133 remote=tcp://127.0.0.1:64307>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 3.86 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models: 812it [2:45:05, 11.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:20:59,387 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 7.67 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:21:04,690 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:64301\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:64920 remote=tcp://127.0.0.1:64301>: Stream is closed\n",
      "2024-09-06 19:21:04,711 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:64301 -> tcp://127.0.0.1:51034\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:64301 remote=tcp://127.0.0.1:64920>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 5.69 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models: 841it [2:50:57, 11.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:26:12,243 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 7.88 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:26:54,865 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:62774\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 467, in read_into\n",
      "    self._try_inline_read()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 835, in _try_inline_read\n",
      "    self._check_closed()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 998, in _check_closed\n",
      "    raise StreamClosedError(real_error=self.error)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:63117 remote=tcp://127.0.0.1:62774>: Stream is closed\n",
      "2024-09-06 19:26:54,880 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:62774\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:63129 remote=tcp://127.0.0.1:62774>: Stream is closed\n",
      "2024-09-06 19:26:54,880 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:62774\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:49891 remote=tcp://127.0.0.1:62774>: Stream is closed\n",
      "2024-09-06 19:26:54,887 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:62774\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:65330 remote=tcp://127.0.0.1:62774>: Stream is closed\n",
      "2024-09-06 19:26:54,893 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:62774 -> tcp://127.0.0.1:64943\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:62774 remote=tcp://127.0.0.1:65330>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 19:26:54,912 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:62774 -> tcp://127.0.0.1:61790\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:62774 remote=tcp://127.0.0.1:63129>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 19:26:54,918 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:62774 -> tcp://127.0.0.1:60381\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:62774 remote=tcp://127.0.0.1:63117>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 19:26:54,920 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:62774 -> tcp://127.0.0.1:49693\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:62774 remote=tcp://127.0.0.1:49891>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 19:26:54,934 - tornado.application - ERROR - Exception in callback functools.partial(<function TCPServer._handle_connection.<locals>.<lambda> at 0x0000017C83E5C9A0>, <Task finished name='Task-10590805' coro=<BaseTCPListener._handle_stream() done, defined at c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py:654> exception=ValueError('invalid operation on non-started TCPListener')>)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\ioloop.py\", line 750, in _run_callback\n",
      "    ret = callback()\n",
      "          ^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\tcpserver.py\", line 387, in <lambda>\n",
      "    gen.convert_yielded(future), lambda f: f.result()\n",
      "                                           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 660, in _handle_stream\n",
      "    logger.debug(\"Incoming connection from %r to %r\", address, self.contact_address)\n",
      "                                                               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 696, in contact_address\n",
      "    host, port = self.get_host_port()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 677, in get_host_port\n",
      "    self._check_started()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 652, in _check_started\n",
      "    raise ValueError(\"invalid operation on non-started TCPListener\")\n",
      "ValueError: invalid operation on non-started TCPListener\n",
      "2024-09-06 19:26:54,938 - tornado.application - ERROR - Exception in callback functools.partial(<function TCPServer._handle_connection.<locals>.<lambda> at 0x0000017CDDD00040>, <Task finished name='Task-10590806' coro=<BaseTCPListener._handle_stream() done, defined at c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py:654> exception=ValueError('invalid operation on non-started TCPListener')>)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\ioloop.py\", line 750, in _run_callback\n",
      "    ret = callback()\n",
      "          ^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\tcpserver.py\", line 387, in <lambda>\n",
      "    gen.convert_yielded(future), lambda f: f.result()\n",
      "                                           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 660, in _handle_stream\n",
      "    logger.debug(\"Incoming connection from %r to %r\", address, self.contact_address)\n",
      "                                                               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 696, in contact_address\n",
      "    host, port = self.get_host_port()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 677, in get_host_port\n",
      "    self._check_started()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 652, in _check_started\n",
      "    raise ValueError(\"invalid operation on non-started TCPListener\")\n",
      "ValueError: invalid operation on non-started TCPListener\n",
      "2024-09-06 19:26:55,222 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:62774\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1481, in connect\n",
      "    return await self._connect(addr=addr, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "                ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:50015 remote=tcp://127.0.0.1:62774>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 19:26:55,225 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:62774\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1481, in connect\n",
      "    return await self._connect(addr=addr, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "                ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:50016 remote=tcp://127.0.0.1:62774>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 5.57 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models: 870it [2:56:40, 11.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:30:47,646 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:61790'.\n",
      "2024-09-06 19:30:47,871 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:61790\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 467, in read_into\n",
      "    self._try_inline_read()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 835, in _try_inline_read\n",
      "    self._check_closed()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 998, in _check_closed\n",
      "    raise StreamClosedError(real_error=self.error)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:62251 remote=tcp://127.0.0.1:61790>: Stream is closed\n",
      "2024-09-06 19:30:47,871 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:61790\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 467, in read_into\n",
      "    self._try_inline_read()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 835, in _try_inline_read\n",
      "    self._check_closed()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 998, in _check_closed\n",
      "    raise StreamClosedError(real_error=self.error)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:62183 remote=tcp://127.0.0.1:61790>: Stream is closed\n",
      "2024-09-06 19:30:47,904 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:61790\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:50282 remote=tcp://127.0.0.1:61790>: Stream is closed\n",
      "2024-09-06 19:30:47,908 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:61790\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:49335 remote=tcp://127.0.0.1:61790>: Stream is closed\n",
      "2024-09-06 19:30:47,911 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:61790\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:65332 remote=tcp://127.0.0.1:61790>: Stream is closed\n",
      "2024-09-06 19:30:47,915 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:61790\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:62184 remote=tcp://127.0.0.1:61790>: Stream is closed\n",
      "2024-09-06 19:30:47,927 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:61790 -> tcp://127.0.0.1:51025\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:61790 remote=tcp://127.0.0.1:62184>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 19:30:47,946 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:61790 -> tcp://127.0.0.1:50137\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:61790 remote=tcp://127.0.0.1:50282>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 19:30:47,984 - distributed.worker - WARNING - Scheduler was unaware of this worker; shutting down.\n",
      "2024-09-06 19:30:47,988 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:61790 -> tcp://127.0.0.1:65337\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:61790 remote=tcp://127.0.0.1:49335>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 19:30:48,061 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:61790 -> tcp://127.0.0.1:64943\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:61790 remote=tcp://127.0.0.1:65332>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 19:30:48,066 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:61790 -> tcp://127.0.0.1:51037\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:61790 remote=tcp://127.0.0.1:62251>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 19:30:48,071 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:61790 -> tcp://127.0.0.1:51034\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:61790 remote=tcp://127.0.0.1:62183>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 19:30:48,171 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:61790\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:64929 remote=tcp://127.0.0.1:61790>: Stream is closed\n",
      "2024-09-06 19:30:48,179 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:61790 -> tcp://127.0.0.1:64304\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:61790 remote=tcp://127.0.0.1:64929>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 3.44 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models: 899it [3:00:21, 10.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:34:37,451 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:50140'.\n",
      "2024-09-06 19:34:37,533 - distributed.worker - WARNING - Scheduler was unaware of this worker; shutting down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 3.82 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models: 928it [3:04:24,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:39:03,172 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 7.67 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:39:21,333 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:64943\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 19:39:21,354 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:64943\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:65325 remote=tcp://127.0.0.1:64943>: Stream is closed\n",
      "2024-09-06 19:39:21,354 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:64943\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:65326 remote=tcp://127.0.0.1:64943>: Stream is closed\n",
      "2024-09-06 19:39:21,360 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:64943\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:65227 remote=tcp://127.0.0.1:64943>: Stream is closed\n",
      "2024-09-06 19:39:21,367 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:64943'.\n",
      "2024-09-06 19:39:21,405 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:64943 -> tcp://127.0.0.1:51037\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:64943 remote=tcp://127.0.0.1:65227>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 19:39:21,407 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:64943 -> tcp://127.0.0.1:60381\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:64943 remote=tcp://127.0.0.1:65325>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 19:39:21,408 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:64943 -> tcp://127.0.0.1:64304\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:64943 remote=tcp://127.0.0.1:65326>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 19:39:21,410 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:64943 -> tcp://127.0.0.1:59251\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:64943 remote=tcp://127.0.0.1:65320>: Stream is closed\n",
      "2024-09-06 19:39:21,414 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils_comm.py\", line 459, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils_comm.py\", line 438, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:64958 remote=tcp://127.0.0.1:51016>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 4.04 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating and saving models: 957it [3:08:43,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:45:20,937 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 7.98 GiB -- Worker memory limit: 11.18 GiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 6.25 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:46:13,063 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51034\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:50835 remote=tcp://127.0.0.1:51034>: Stream is closed\n",
      "2024-09-06 19:46:13,069 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51034\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:50850 remote=tcp://127.0.0.1:51034>: Stream is closed\n",
      "2024-09-06 19:46:13,099 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51034 -> tcp://127.0.0.1:50503\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51034 remote=tcp://127.0.0.1:50850>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 19:46:13,109 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51034 -> tcp://127.0.0.1:50506\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51034 remote=tcp://127.0.0.1:50835>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 19:46:13,675 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:51034'.\n",
      "2024-09-06 19:46:13,705 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils_comm.py\", line 459, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils_comm.py\", line 438, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51064 remote=tcp://127.0.0.1:51016>: Stream is closed\n",
      "2024-09-06 19:46:13,706 - tornado.application - ERROR - Exception in callback functools.partial(<function TCPServer._handle_connection.<locals>.<lambda> at 0x0000017C27AA27A0>, <Task finished name='Task-11727788' coro=<BaseTCPListener._handle_stream() done, defined at c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py:654> exception=ValueError('invalid operation on non-started TCPListener')>)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\ioloop.py\", line 750, in _run_callback\n",
      "    ret = callback()\n",
      "          ^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\tcpserver.py\", line 387, in <lambda>\n",
      "    gen.convert_yielded(future), lambda f: f.result()\n",
      "                                           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 660, in _handle_stream\n",
      "    logger.debug(\"Incoming connection from %r to %r\", address, self.contact_address)\n",
      "                                                               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 696, in contact_address\n",
      "    host, port = self.get_host_port()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 677, in get_host_port\n",
      "    self._check_started()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 652, in _check_started\n",
      "    raise ValueError(\"invalid operation on non-started TCPListener\")\n",
      "ValueError: invalid operation on non-started TCPListener\n",
      "2024-09-06 19:46:13,708 - tornado.application - ERROR - Exception in callback functools.partial(<function TCPServer._handle_connection.<locals>.<lambda> at 0x0000017C58BDC860>, <Task finished name='Task-11727789' coro=<BaseTCPListener._handle_stream() done, defined at c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py:654> exception=ValueError('invalid operation on non-started TCPListener')>)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\ioloop.py\", line 750, in _run_callback\n",
      "    ret = callback()\n",
      "          ^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\tcpserver.py\", line 387, in <lambda>\n",
      "    gen.convert_yielded(future), lambda f: f.result()\n",
      "                                           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 660, in _handle_stream\n",
      "    logger.debug(\"Incoming connection from %r to %r\", address, self.contact_address)\n",
      "                                                               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 696, in contact_address\n",
      "    host, port = self.get_host_port()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 677, in get_host_port\n",
      "    self._check_started()\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 652, in _check_started\n",
      "    raise ValueError(\"invalid operation on non-started TCPListener\")\n",
      "ValueError: invalid operation on non-started TCPListener\n",
      "2024-09-06 19:46:23,473 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51034\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1481, in connect\n",
      "    return await self._connect(addr=addr, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "                ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51833 remote=tcp://127.0.0.1:51034>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 19:46:23,481 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51034\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1481, in connect\n",
      "    return await self._connect(addr=addr, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "                ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51832 remote=tcp://127.0.0.1:51034>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 19:46:29,681 - distributed.worker.memory - WARNING - gc.collect() took 4.188s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:46:29,681 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 8.98 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:46:30,350 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 8.92 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:46:35,364 - distributed.worker.memory - WARNING - gc.collect() took 4.219s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:46:35,372 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 8.98 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:46:39,572 - distributed.worker.memory - WARNING - gc.collect() took 4.188s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:46:39,573 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 8.98 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:46:43,732 - distributed.worker.memory - WARNING - gc.collect() took 4.156s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:46:43,734 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 8.98 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:46:44,072 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51034\n",
      "ConnectionRefusedError: [Errno 10061] Unknown error\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 342, in connect\n",
      "    comm = await wait_for(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils.py\", line 1923, in wait_for\n",
      "    return await fut\n",
      "           ^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 559, in connect\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x0000017C9D46DCD0>: ConnectionRefusedError: [Errno 10061] Unknown error\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1481, in connect\n",
      "    return await self._connect(addr=addr, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 368, in connect\n",
      "    raise OSError(\n",
      "OSError: Timed out trying to connect to tcp://127.0.0.1:51034 after 30 s\n",
      "2024-09-06 19:46:48,291 - distributed.worker.memory - WARNING - gc.collect() took 4.203s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:46:48,292 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 8.94 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:46:52,475 - distributed.worker.memory - WARNING - gc.collect() took 4.188s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:46:52,476 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 8.94 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:46:56,681 - distributed.worker.memory - WARNING - gc.collect() took 4.188s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:46:56,681 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 8.94 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:47:00,877 - distributed.worker.memory - WARNING - gc.collect() took 4.188s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:47:00,878 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 8.94 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:47:05,047 - distributed.worker.memory - WARNING - gc.collect() took 4.156s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:47:05,048 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 8.94 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:47:09,199 - distributed.worker.memory - WARNING - gc.collect() took 4.109s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:47:09,199 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 8.94 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:47:13,379 - distributed.worker.memory - WARNING - gc.collect() took 4.156s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:47:13,380 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 8.94 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:47:13,625 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 8.84 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:47:14,081 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 8.77 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:47:14,081 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 8.77 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:47:14,085 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 8.77 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:47:14,581 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 8.68 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:47:14,581 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 8.68 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:47:14,589 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 8.68 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:47:14,590 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 8.68 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:47:14,591 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 8.68 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:47:14,591 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 8.68 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:47:24,590 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:50855'.\n",
      "2024-09-06 19:47:24,593 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils_comm.py\", line 459, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils_comm.py\", line 438, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50862 remote=tcp://127.0.0.1:51016>: Stream is closed\n",
      "Creating and saving models: 986it [3:16:23, 11.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n",
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:50:06,541 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:50506\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:50827 remote=tcp://127.0.0.1:50506>: Stream is closed\n",
      "2024-09-06 19:50:06,555 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:50506'.\n",
      "2024-09-06 19:50:06,557 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:50506 -> tcp://127.0.0.1:64304\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:50506 remote=tcp://127.0.0.1:50827>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 19:50:06,638 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils_comm.py\", line 459, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils_comm.py\", line 438, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50522 remote=tcp://127.0.0.1:51016>: Stream is closed\n",
      "2024-09-06 19:50:06,855 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51317\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:51839 remote=tcp://127.0.0.1:51317>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 2.64 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:50:07,103 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51317 -> tcp://127.0.0.1:52025\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51317 remote=tcp://127.0.0.1:52120>: Stream is closed\n",
      "2024-09-06 19:50:07,127 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51317 -> tcp://127.0.0.1:64304\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 297, in write\n",
      "    raise StreamClosedError()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1777, in get_data\n",
      "    compressed = await comm.write(msg, serializers=serializers)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 307, in write\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51317 remote=tcp://127.0.0.1:51839>: Stream is closed\n",
      "2024-09-06 19:50:07,130 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51317\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "Creating and saving models: 1015it [3:19:23,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 650\n",
      "In holding pattern until WAIT completes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:51:51,645 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 7.79 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:56:52,787 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 8.61 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:59:18,032 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51025\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-06 19:59:18,168 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:51025'.\n",
      "2024-09-06 19:59:18,413 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51025\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:60931 remote=tcp://127.0.0.1:51025>: Stream is closed\n",
      "2024-09-06 19:59:19,499 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51025 -> tcp://127.0.0.1:60381\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51025 remote=tcp://127.0.0.1:60931>: ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "2024-09-06 19:59:19,544 - distributed.worker - WARNING - Scheduler was unaware of this worker; shutting down.\n",
      "2024-09-06 19:59:19,838 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51025 -> tcp://127.0.0.1:51981\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51025 remote=tcp://127.0.0.1:52221>: Stream is closed\n",
      "2024-09-06 19:59:19,946 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51025\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:52208 remote=tcp://127.0.0.1:51025>: Stream is closed\n",
      "2024-09-06 19:59:20,069 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51025 -> tcp://127.0.0.1:52025\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51025 remote=tcp://127.0.0.1:52208>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 19:59:25,167 - distributed.worker.memory - WARNING - gc.collect() took 4.312s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:59:25,167 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 9.02 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:59:29,513 - distributed.worker.memory - WARNING - gc.collect() took 4.312s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:59:29,513 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 9.02 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:59:34,265 - distributed.worker.memory - WARNING - gc.collect() took 4.266s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:59:34,265 - distributed.worker.memory - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 9.21 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:59:38,633 - distributed.worker.memory - WARNING - gc.collect() took 4.375s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:59:38,633 - distributed.worker.memory - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 9.21 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:59:42,948 - distributed.worker.memory - WARNING - gc.collect() took 4.312s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:59:42,948 - distributed.worker.memory - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 9.21 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:59:47,255 - distributed.worker.memory - WARNING - gc.collect() took 4.297s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:59:47,256 - distributed.worker.memory - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 9.21 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:59:51,652 - distributed.worker.memory - WARNING - gc.collect() took 4.344s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:59:51,652 - distributed.worker.memory - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 9.21 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 19:59:55,949 - distributed.worker.memory - WARNING - gc.collect() took 4.188s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 19:59:55,951 - distributed.worker.memory - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 9.21 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:00,740 - distributed.worker.memory - WARNING - gc.collect() took 4.219s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 20:00:00,743 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 9.16 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:05,199 - distributed.worker.memory - WARNING - gc.collect() took 4.328s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 20:00:05,199 - distributed.worker.memory - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 9.17 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:05,314 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51025\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils.py\", line 1923, in wait_for\n",
      "    return await fut\n",
      "           ^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 546, in connect\n",
      "    stream = await self.client.connect(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\tcpclient.py\", line 279, in connect\n",
      "    af, addr, stream = await connector.start(connect_timeout=timeout)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 342, in connect\n",
      "    comm = await wait_for(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils.py\", line 1922, in wait_for\n",
      "    async with asyncio.timeout(timeout):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\asyncio\\timeouts.py\", line 111, in __aexit__\n",
      "    raise TimeoutError from exc_val\n",
      "TimeoutError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1481, in connect\n",
      "    return await self._connect(addr=addr, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 368, in connect\n",
      "    raise OSError(\n",
      "OSError: Timed out trying to connect to tcp://127.0.0.1:51025 after 30 s\n",
      "2024-09-06 20:00:05,315 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51025\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils.py\", line 1923, in wait_for\n",
      "    return await fut\n",
      "           ^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 546, in connect\n",
      "    stream = await self.client.connect(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\tcpclient.py\", line 279, in connect\n",
      "    af, addr, stream = await connector.start(connect_timeout=timeout)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 342, in connect\n",
      "    comm = await wait_for(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils.py\", line 1922, in wait_for\n",
      "    async with asyncio.timeout(timeout):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\asyncio\\timeouts.py\", line 111, in __aexit__\n",
      "    raise TimeoutError from exc_val\n",
      "TimeoutError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1481, in connect\n",
      "    return await self._connect(addr=addr, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 368, in connect\n",
      "    raise OSError(\n",
      "OSError: Timed out trying to connect to tcp://127.0.0.1:51025 after 30 s\n",
      "2024-09-06 20:00:05,317 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:52261\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils.py\", line 1923, in wait_for\n",
      "    return await fut\n",
      "           ^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 546, in connect\n",
      "    stream = await self.client.connect(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\tcpclient.py\", line 279, in connect\n",
      "    af, addr, stream = await connector.start(connect_timeout=timeout)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 342, in connect\n",
      "    comm = await wait_for(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils.py\", line 1922, in wait_for\n",
      "    async with asyncio.timeout(timeout):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\asyncio\\timeouts.py\", line 111, in __aexit__\n",
      "    raise TimeoutError from exc_val\n",
      "TimeoutError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1481, in connect\n",
      "    return await self._connect(addr=addr, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 368, in connect\n",
      "    raise OSError(\n",
      "OSError: Timed out trying to connect to tcp://127.0.0.1:52261 after 30 s\n",
      "2024-09-06 20:00:05,318 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:52261\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils.py\", line 1923, in wait_for\n",
      "    return await fut\n",
      "           ^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 546, in connect\n",
      "    stream = await self.client.connect(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\tcpclient.py\", line 279, in connect\n",
      "    af, addr, stream = await connector.start(connect_timeout=timeout)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 342, in connect\n",
      "    comm = await wait_for(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils.py\", line 1922, in wait_for\n",
      "    async with asyncio.timeout(timeout):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\asyncio\\timeouts.py\", line 111, in __aexit__\n",
      "    raise TimeoutError from exc_val\n",
      "TimeoutError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1481, in connect\n",
      "    return await self._connect(addr=addr, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 368, in connect\n",
      "    raise OSError(\n",
      "OSError: Timed out trying to connect to tcp://127.0.0.1:52261 after 30 s\n",
      "2024-09-06 20:00:09,610 - distributed.worker.memory - WARNING - gc.collect() took 4.234s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2024-09-06 20:00:09,610 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 9.14 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:09,658 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:51025\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils.py\", line 1923, in wait_for\n",
      "    return await fut\n",
      "           ^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 546, in connect\n",
      "    stream = await self.client.connect(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\tcpclient.py\", line 279, in connect\n",
      "    af, addr, stream = await connector.start(connect_timeout=timeout)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 342, in connect\n",
      "    comm = await wait_for(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils.py\", line 1922, in wait_for\n",
      "    async with asyncio.timeout(timeout):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\asyncio\\timeouts.py\", line 111, in __aexit__\n",
      "    raise TimeoutError from exc_val\n",
      "TimeoutError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1481, in connect\n",
      "    return await self._connect(addr=addr, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 368, in connect\n",
      "    raise OSError(\n",
      "OSError: Timed out trying to connect to tcp://127.0.0.1:51025 after 30 s\n",
      "2024-09-06 20:00:10,301 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 8.90 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:10,364 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 8.74 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:10,368 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 8.74 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:10,557 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 8.69 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:10,564 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 8.69 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:10,564 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 8.69 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:10,572 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 8.69 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:10,572 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 8.69 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:10,582 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 8.69 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:11,551 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 8.61 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:11,566 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 8.63 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:12,722 - distributed.worker.memory - WARNING - Worker is at 84% memory usage. Pausing worker.  Process memory: 9.42 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:14,172 - distributed.worker.memory - WARNING - Worker is at 91% memory usage. Pausing worker.  Process memory: 10.25 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:14,172 - distributed.worker.memory - WARNING - Worker is at 91% memory usage. Pausing worker.  Process memory: 10.25 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:15,700 - distributed.worker.memory - WARNING - Worker is at 99% memory usage. Pausing worker.  Process memory: 11.12 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:15,701 - distributed.worker.memory - WARNING - Worker is at 99% memory usage. Pausing worker.  Process memory: 11.12 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:15,702 - distributed.worker.memory - WARNING - Worker is at 99% memory usage. Pausing worker.  Process memory: 11.12 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:15,702 - distributed.worker.memory - WARNING - Worker is at 99% memory usage. Pausing worker.  Process memory: 11.12 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:15,703 - distributed.worker.memory - WARNING - Worker is at 99% memory usage. Pausing worker.  Process memory: 11.12 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:15,704 - distributed.worker.memory - WARNING - Worker is at 99% memory usage. Pausing worker.  Process memory: 11.12 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:17,292 - distributed.worker.memory - WARNING - Worker is at 98% memory usage. Pausing worker.  Process memory: 11.00 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:17,292 - distributed.worker.memory - WARNING - Worker is at 98% memory usage. Pausing worker.  Process memory: 11.00 GiB -- Worker memory limit: 11.18 GiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of the done_eval list: 6 and this is the size of the not_done_eval list: 0\n",
      "This is the size of the done_train list: 23 and this is the size of the not_done_train list: 0\n",
      "WAIT completed in 9.82 minutes\n",
      "This is the size of DONE 29. And this is the size of NOT_DONE 0\n",
      "\n",
      "We have completed the TRAIN list comprehension. The size is 23\n",
      "This is the length of the TRAIN completed_train_futures var 23\n",
      "We have completed the EVAL list comprehension. The size is 6\n",
      "This is the length of the EVAL completed_eval_futures var 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 20:00:24,072 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 8.92 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:24,435 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 8.81 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:24,459 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 8.76 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:24,584 - distributed.worker.memory - WARNING - Worker is at 76% memory usage. Resuming worker. Process memory: 8.54 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:24,594 - distributed.worker.memory - WARNING - Worker is at 76% memory usage. Resuming worker. Process memory: 8.55 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:25,115 - distributed.worker.memory - WARNING - Worker is at 74% memory usage. Resuming worker. Process memory: 8.38 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:25,116 - distributed.worker.memory - WARNING - Worker is at 74% memory usage. Resuming worker. Process memory: 8.38 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:25,119 - distributed.worker.memory - WARNING - Worker is at 74% memory usage. Resuming worker. Process memory: 8.38 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:25,120 - distributed.worker.memory - WARNING - Worker is at 74% memory usage. Resuming worker. Process memory: 8.38 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:25,122 - distributed.worker.memory - WARNING - Worker is at 74% memory usage. Resuming worker. Process memory: 8.38 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:27,550 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 8.71 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:28,480 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 8.94 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:29,736 - distributed.worker.memory - WARNING - Worker is at 85% memory usage. Pausing worker.  Process memory: 9.51 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:29,737 - distributed.worker.memory - WARNING - Worker is at 85% memory usage. Pausing worker.  Process memory: 9.51 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:30,326 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Pausing worker.  Process memory: 9.70 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:30,330 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Pausing worker.  Process memory: 9.70 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:30,330 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Pausing worker.  Process memory: 9.70 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:30,331 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Pausing worker.  Process memory: 9.70 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:30,331 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Pausing worker.  Process memory: 9.70 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:30,333 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Pausing worker.  Process memory: 9.70 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:31,722 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Pausing worker.  Process memory: 9.65 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:31,722 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Pausing worker.  Process memory: 9.65 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:35,217 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 8.84 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:35,239 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 8.92 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:35,574 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 8.86 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:35,769 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 8.81 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:35,786 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 8.86 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:36,431 - distributed.worker.memory - WARNING - Worker is at 75% memory usage. Resuming worker. Process memory: 8.47 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:36,730 - distributed.active_memory_manager - WARNING - Tried retiring worker tcp://127.0.0.1:52261, but 547 tasks could not be moved as there are no suitable workers to receive them. The worker will not be retired.\n",
      "2024-09-06 20:00:36,902 - distributed.worker.memory - WARNING - Worker is at 76% memory usage. Resuming worker. Process memory: 8.52 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:36,911 - distributed.worker.memory - WARNING - Worker is at 76% memory usage. Resuming worker. Process memory: 8.53 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:36,948 - distributed.scheduler - WARNING - Could not retire worker 'tcp://127.0.0.1:52261': unique data could not be moved to any other worker (stimulus_id='retire-workers-1725667236.7237887')\n",
      "2024-09-06 20:00:37,340 - distributed.worker.memory - WARNING - Worker is at 76% memory usage. Resuming worker. Process memory: 8.51 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:37,341 - distributed.worker.memory - WARNING - Worker is at 76% memory usage. Resuming worker. Process memory: 8.51 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:37,341 - distributed.worker.memory - WARNING - Worker is at 76% memory usage. Resuming worker. Process memory: 8.51 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:41,542 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 8.73 GiB -- Worker memory limit: 11.18 GiB\n",
      "2024-09-06 20:00:42,552 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://127.0.0.1:64304, {...})' coro=<Worker.gather_dep() done, defined at c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker_state_machine.py:3609>> ended with CancelledError\n",
      "2024-09-06 20:00:42,558 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://127.0.0.1:52282, {...})' coro=<Worker.gather_dep() done, defined at c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker_state_machine.py:3609>> ended with CancelledError\n",
      "2024-09-06 20:00:42,806 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:52025 -> tcp://127.0.0.1:52261\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:52025 remote=tcp://127.0.0.1:52992>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 20:00:42,989 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://127.0.0.1:51981, {...})' coro=<Worker.gather_dep() done, defined at c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker_state_machine.py:3609>> ended with CancelledError\n",
      "2024-09-06 20:00:42,989 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://127.0.0.1:52025, {...})' coro=<Worker.gather_dep() done, defined at c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker_state_machine.py:3609>> ended with CancelledError\n",
      "2024-09-06 20:00:42,989 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://127.0.0.1:50503, {...})' coro=<Worker.gather_dep() done, defined at c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker_state_machine.py:3609>> ended with CancelledError\n",
      "2024-09-06 20:00:42,989 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://127.0.0.1:60381, {...})' coro=<Worker.gather_dep() done, defined at c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker_state_machine.py:3609>> ended with CancelledError\n",
      "2024-09-06 20:00:42,989 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://127.0.0.1:51037, {...})' coro=<Worker.gather_dep() done, defined at c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker_state_machine.py:3609>> ended with CancelledError\n",
      "2024-09-06 20:00:43,011 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:51037 -> tcp://127.0.0.1:52261\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51037 remote=tcp://127.0.0.1:52990>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 20:00:43,159 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:64304 -> tcp://127.0.0.1:52261\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:64304 remote=tcp://127.0.0.1:52917>: Stream is closed\n",
      "2024-09-06 20:00:43,191 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:50503 -> tcp://127.0.0.1:52261\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:50503 remote=tcp://127.0.0.1:52303>: ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "2024-09-06 20:00:43,231 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:52282 -> tcp://127.0.0.1:52261\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:52282 remote=tcp://127.0.0.1:52915>: Stream is closed\n",
      "2024-09-06 20:00:43,282 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:60381 -> tcp://127.0.0.1:52261\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 297, in write\n",
      "    raise StreamClosedError()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1777, in get_data\n",
      "    compressed = await comm.write(msg, serializers=serializers)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 307, in write\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:60381 remote=tcp://127.0.0.1:52878>: Stream is closed\n",
      "2024-09-06 20:00:44,401 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils_comm.py\", line 459, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils_comm.py\", line 438, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52286 remote=tcp://127.0.0.1:51016>: Stream is closed\n",
      "2024-09-06 20:00:46,323 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:52261' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'train_model-b5bdfd1ef1d23484a812e324257e220e', 'train_model-dd937cdbb88009a63b473daf02648f7b', 'train_model-ccc1b0617c97fda21f36e05234c4f5f5', 'train_model-e546b49197200038a7f25df940298410', 'train_model-88d24899e6c70fbeddf54a6420e04fb2'} (stimulus_id='handle-worker-cleanup-1725667246.322488')\n",
      "2024-09-06 20:00:46,333 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:52261' caused the cluster to lose scattered data, which can't be recovered: {'list-fc6d4df973a08e5fd5e4cd32c051f50c', 'list-1117346262b2188712f348e6573e6ef6', 'list-b97230151cc4f60fafe8a1e4e2113e83', 'list-ea300cc1248377bdc902d94b2954f76a', 'list-b81488c8336e77e7492dfdc34633f0c5', 'list-c0de58572b5aa5b20ebeb122c58bfe4a', 'list-928e436ec499ec7ad59e124746d0b79f', 'list-e1880fad2f4bc8659153906a434e36f1', 'list-00646380cdd91f0f087383d3d69d983a', 'list-3596bdbe369463404c6c17a22c7e9754', 'list-5efd7e5a91d899793f20349faf63d73e', 'list-95a72315805ca32b690a5d831e8665be', 'list-b8fb2ffe2b4faa99355e7e17d322efb7', 'list-994183b8f785e4374142c0d58adc3828', 'list-38f1e160c9a273c8ac04a007258c8c02', 'list-19af44a8e9053bd5c717bbbf820f39cf', 'list-b81679371fe1fc3c264c6d5a2f6c2f47', 'list-9492d835c3582c9c4b820654f0b3f03f', 'list-494fdc8ffc953fe8be98ce053087727f', 'list-fadd41aa1f7dcc023de07738f31e9259', 'list-535e77d5201502cb4444ac73b4b4f61c', 'list-9e2a87556da37fc3fbdec45e26898c59', 'list-ddb6ae594a828ba8ba642b77d47b7a7d', 'list-a235e50dd5f0008ee9623387c477f985', 'list-efa5c2e6558be6209816994948173c40', 'list-b25aaa75ada93151786b5937854867b7', 'list-70c634b191182cf679c3d6a014af7e71', 'list-3085c498848ae74f8795c509126bff4b', 'list-f34b0d360d6a4ae2efd75d68de137ece', 'list-e157fed2bdd817d0ff249dbc8b011a16', 'list-5517ddac57874f10ff434657a52aae81', 'list-65d5b11a833336b1ade60950cfb1d276', 'list-c5301a21a9d0df047e2ae6d3914fed72', 'list-7a4757461d8fa3475f8e0c0c81bc5505', 'list-a4cee5528946131c4995bedee543cd13', 'list-4b6828c8be9a4ff964db202810848572', 'list-67c055df72300af4c47e8ec04c728780', 'list-a8a3647fee6dd9696666042eaa2cbbd2', 'list-45edb815867d513e34e7ead40c8c4a8a', 'list-e1866a9db230cb7c8fa42a7f2761bd8a', 'list-17716b2ffdef6767c2f467511e83ca55', 'list-4b14f082e845480336370a26d91425db', 'list-8b826881d4ccb301e24302d867f8973f', 'list-a484fc38d4b5a65e29afc1306573f853', 'list-972628d5215de8ac449b0c4cd61e5eb4', 'list-af189c7628f67b4efa545f9b7824b7ea', 'list-b2931c9e0822cbd8a8185707cf260b62', 'list-7642743e01236061257d8803cd29258f', 'list-1ef4e7bee3e8094213d6929b8e0175ef', 'list-5faa51b8cc13a3e63ead74c3a0957c0c', 'list-e7160be556398e9263829e4d09b40979', 'list-afda040890b12114f7a7ef3aa2eb5c89', 'list-d01723a337c62ecb91e001b99eba62d9', 'list-49b057e9870f54efd1e116de76b4e119', 'list-c808c13b5acbb196256d122dccc3f5a0', 'list-72d8ca3875df939bae506e5a2e8ee0c4', 'list-9daa15f4f225c0a8e939e479080593bd', 'list-4447c63feeb90b43cb8965143ed2f8e2', 'list-75ba5d0f0a42c35d6092cbd5d4da9a44', 'list-cbca3d1bfbb26338364ddb4675378f82', 'list-72e1908d96776bfb10a85ffd5f473ef5', 'list-da9de56779435308f42a5c7f0d30404b', 'list-2227394ce8a502c7e748b062351e1c30', 'list-ddb58efcd9e567160ecca9c8810960be', 'list-99c7e5fb367fc03f9a9ebe19ecd3b7a0', 'list-05377871b5f24498261c7add8d1a7bd5', 'list-a1c4baa4dc1d6278b97b979657e34088', 'list-5ff356f642d6ac41e8928ea3ba13e013', 'list-e3d5b567a29a3dedfb303e66f1124500', 'list-4ca2573444ec034546697f68167385d2', 'list-915987b71b9da8aaa004423b57becc38', 'list-dea873cd3f3f048793280ccfe787068e', 'list-097b82be796322e3db795c4e9e54287d', 'list-1d25b58bd3bd21d9f8465723246d025d', 'list-bc8a91e3cd05b8019897ae0297c14840', 'list-8db0369e6f275cf7bfc5d214bfb9cca6', 'list-bfac1985c0bc035f9e5e5f9d452f0551', 'list-1c3344ba8b03a289c2a0a3ccff5912bb', 'list-72b51d171c75dd2a906da186ae2f3b61', 'list-e371731c869f6c34494399563b244771', 'list-b1e75be43e93d41ae654fb2b02dcd22c', 'list-ed88676551178776cd3c09b637c9d258', 'list-945fff5fffd5d1c591de912f1c4e3d72', 'list-b0d3676d9b231882f98b0acea2c041b5', 'list-d35c389f480e5bb3c9e73eec87eba04b', 'list-dae62c80b2ca4882bd834d63391fd358', 'list-b6a99798cf9caa479bf0f257385aec26', 'list-9b364105da4de446e78f321f03a867b1', 'list-34a3df0d28c812da6f1940e6c54132fe', 'list-ce343139490a295c4fa13152ae928dd3', 'list-66b49b2d14b581b5c5eaba289fd5faa0', 'list-824d1a110dd40249e3a41c6a81d9e835', 'list-5f79a42f208cc1a5ee0e8952b36082ec', 'list-01754cb0dfa972375c0ef9b27302808d', 'list-fae82394f9c5c556f5447c28db2a29df', 'list-b5389be3fcc6c544a09002c02055f856', 'list-944a8465ae844a0a6fa79a901c6820dd', 'list-bd8efa113d80a9cb2d03842a00d77d2d', 'list-25d05a72dca39e35d2aa284945fc77eb', 'list-0f577801a28b82ad120efc48b3759ef4', 'list-f9ea50e4b924250bd7b2021ffcf8f416', 'list-5a97fc82f69da31d01c482533bf6570f', 'list-7031c3ffde718de8bbab52689737a603', 'list-9556e1aff49a0a1663e32051486c7090', 'list-bf5a8293f731980fe4e464b75490221d', 'list-1c5230957ecb471c5092255a9bcc0c33', 'list-d4ec39011caf76e40c614fc62efbf806', 'list-905ace5906174004030e5785305b0ae3', 'list-7c1b5005e2832960c3ce93bd9aec0285', 'list-039cf493125fcb887301038867d5f881', 'list-05d7537da76e89f19dfeab23df1beac0', 'list-b0057da6d5b2ea420f923f258053ed32', 'list-3959d5a3f59032a6fdef08e6dfe23624', 'list-98dc9a22f055b94261735767a7957c3e', 'list-d160a2690659ffebfe147e1597859ed0', 'list-cb526220a7f6c928a1c16f93f839b84a', 'list-e82c9502d7420c8ca39a455c262a82ea', 'list-78ee1d5380e85304250747409ef56fa0', 'list-e8bdea78bf2678955ffa1467f8fefb9a', 'list-f1de346bd1ac0ff4375c525c1d6a4f47', 'list-afc94ef2a5cb638959a2fb5cddd0faeb', 'list-7b49c95fb63d3de475a1c245835df854', 'list-afc9841604bb88e1ecd3fa2199cf3503', 'list-03748fad375fd01a297573c2a7b82d23', 'list-de5e8c73aca51143dd34ae61691cf5a4', 'list-2e97fc370868466ba95d84a20c658b39', 'list-358bb659e638d6cb041edee431c58fdd', 'list-ac2819c577ed62c599d44267cc05041c', 'list-c38f4f6e8967f9d419921b9e8de67524', 'list-f573035d021e2f3f295cc66fe63dd9aa', 'list-68754ba83fef1ca741a3253db34a4cc4', 'list-ecf115ab57fa5e9b7568353486627488', 'list-42e814258535507445dfacfb5b928aa7', 'list-083509d25319bcbd84a0fb2f57b882d7', 'list-691f69bff5c38319817e726d8607917f', 'list-8751d845e2b1a6537e0ebac54192b824', 'list-1714f93467df45f409d8f27f85a05260', 'list-420020b6bb8a8e1a77a92d574573cbe7', 'list-c8d26a4f231635b974dff10476cc14b8', 'list-8ceef7c090ac3c69c5412d67a809b724', 'list-4de41e2ffe9a40c179165457610b2fb9', 'list-a313d018fd5cd9ca4acd37f231a58569', 'list-d0c45963e75ed9d02a9c9a74caf61331', 'list-0d0e867b416d57812f641a76738c4506', 'list-ec1957e893986d429198df110e4b4cfc', 'list-364a774e2d781eb563e9bce50e675456', 'list-b18b161606161ba6478e55d479f862a4', 'list-3738234707b15a42a8826f72927b7c2d', 'list-990fbfac1f7d14673ad78737a65c3993', 'list-90fa7184afdba0a1e56cb5e49e2e845e', 'list-94f6f43ded5b9598fc4d32947dfabb3b', 'list-1d358faaf3e1fc846abd4b4f5c8f5e66', 'list-b2036639182e978d5ab9e6cca5a9759b', 'list-471621d3d3408a3d680e5285371ca64a', 'list-09653d860ce3bdd3428cf089be0fc97a', 'list-61ac11a99d99d1e2a2c1b9273c4ba59b', 'list-4a67310ca0404aefcda839a13143b24f', 'list-7039c221db36ae6562986b364bc7a72c', 'list-37ba279ad90d577fcc069da871b42418', 'list-a8c23dd681ab97f7d07de2ca63e18ceb', 'list-8b91d9f5f8315b9a9478fd61b8341184', 'list-f439316a3e8fd73cd05c87bfddf7774a', 'list-fc8c33d80d379448c64c8e4dc66529d4', 'list-0eeeaa8eb4626eb279465b3c0b46e9dd', 'list-a366d9581b8ef8287a450455b82f9ece', 'list-2e46b1a3a454efb8c3eecaa12f75c706', 'list-76943c5b1bc1a9a234599676e2a44096', 'list-45d7aaee259acfe83bf880322767f4c6', 'list-6de2361906e877333a4f77ad3ab88a29', 'list-e6c44e333e75c8a94f92de4f303bf11e', 'list-43625f16d17431f90d7e9b75f215f434', 'list-d620dec7b60785636dea3c6a68d6f167', 'list-93b9adbb053f4628435dbb5f85bd7b54', 'list-76d0fbf64c0b86a6266bfe8ea9c9969f', 'list-3bb1773584425a1602e8deb3e33a26a8', 'list-c3ce1d998a17811c78bb0d6f80f365cc', 'list-06d3fd9b16d0da8c14a8d103ad509ad4', 'list-eb512a749ceeeb7097ae9b1357eadf67', 'list-f920eb802a3d77140823160c0795046a', 'list-656760b6fb2ec9a47f8c1dc9fe59cc99', 'list-e8631eb1bf6dea268968f3b95b22352d', 'list-e94f075f49229ab11f8cd5c312991b3c', 'list-4c68f6f35c9829192292b1f6623f4820', 'list-34c87bdbfef838cc33f025ad5761829f', 'list-2dc701ac912db8bf7a5192dc18836461', 'list-2d040641f4b3739c6b84dd2efba10729', 'list-60c032e44be6a5cbf32092e72ee5acfa', 'list-889ee795ec3af157cc8f87ed74f20949', 'list-189a58784810a0eb453710a525472940', 'list-b0dfa460527716be719884c006c2938b', 'list-606d4ea264a2b47691f7283b7d36852c', 'list-f7831f97e14bd8e2794c44dac2abb6cd', 'list-8b5bfaa5d10efcec8f694696a3fedf74', 'list-83ad44fa4677cde4917b686a2a04b4b4', 'list-a17a62d380a2278102777210a49fc0d3', 'list-7ccf5a36737f57e1e03a4c737d8053d4', 'list-d2faa8d6a56e21da9233be0658bcad74', 'list-50597529e1cd1e5f8016550d492040d2', 'list-93192cfc0f266f5e4394522ff9fb9e75', 'list-e865a25e0bcf3fa3280d2ee106034323', 'list-05bf2bcb6a6537f0b083aa2dacf1ce8b', 'list-d71234958120f7459b25759390cdbad6', 'list-8c30bea4631ff4d5e33e8b8d71726b90', 'list-24c8981ba4ba9671e3c731f1d4916b60', 'list-94f8f480e6fe26348b25515f7e975010', 'list-175ef776745f93a8f3b15a55c1bc884e', 'list-c420013cf242d8c7ff1e371d47a22d11', 'list-91dc4b7be58ffe6e1c3bf3cb97afd83e', 'list-ab1a77166aad93aa27ba6ca4170740bb', 'list-2f9591a2bdca70eeec66617b5d43824c', 'list-c407368895f9dd7c1b7e042729e6ca46', 'list-c58615a2fdd5c8b536e76c527c93d6e5', 'list-10d0868442d93787f2caa6f6b203b208', 'list-24259c7a2647b9b7241c9a9a56872202', 'list-f5abc7acd921d9ae3ba9583f634b4c9e', 'list-3731f4859086cd555251de916b926a66', 'list-9789c2b788edde8f491dfab04c9e7f7f', 'list-074218d5b7187c62e2bc72ce87655d1f', 'list-aca12c7166a094c9505e05fcc5edff91', 'list-0bcdef058872240aeec27d3f5b3cbf69', 'list-67f4a5580662a9c518f29dae01621799', 'list-ddc48c1b77d3612d2a87f468b022b023', 'list-13ae380ca2fedca87ddb02e452c2bed3', 'list-66cc08d162257c4a7dc7925805e2546a', 'list-9f2b632cc596042b903a7080b589fb9d', 'list-4c9199242f328105c06ec6a19bab02ec', 'list-0ba803197c59530b5f338867d02bb6b2', 'list-2b17980164f8254b91e6fb2f3148c84d', 'list-a4b50424a55783030c809f248b1fae79', 'list-edf3b69caf1636a0cf4a886043a6d792', 'list-075993406210bfb8bc8e5d9079af927c', 'list-540861f67547e0a19ba3a211b9958d6b', 'list-561afb7157c4068f1f0eec21f350a1b3', 'list-d4ba560e149a1ed87f8f1e5ca69ec66f', 'list-475eab412a25a2efd9ac2048c49d1af3', 'list-ffb4f320a8fe5325635f566466f8b00d', 'list-bbffa66f2adf71c35afc184ccf458ea6', 'list-97d66c13e4006108ab981a869f75c6ed', 'list-01c1d6c860f56fb827755f6955c0dacc', 'list-fe3bdb45e5303b32c42e06fd3cb6f47b', 'list-dd3d1ec0fd85154ee21651316312299d', 'list-993a4e19f32d90f2c292c28ca8cb61be', 'list-d339c59dc9b770c55df4666ae70fd269', 'list-4953b014f075174bf75f620d58589c03', 'list-2c179905fbcd58b7b748a155342d48b5', 'list-d61cc3b0192aeb72fe4898763cfa0645', 'list-9c187c6469006808f49a7beba4215ba6', 'list-7e00ea9410283412fc5a376c5bbdb41f', 'list-8612f39884bb7bcbb3b7d4916d43b9d4', 'list-b2626968775c2349a6da13b7b198f45b', 'list-677d1fedb9c16eb7eb6d2adf484ab35e', 'list-d7e1b6de4d3b55c265db22cc899b79ac', 'list-912bb56aa752cb803aa5b16893d4a653', 'list-728743b36ce27b8bc6cf273d568e3cde', 'list-cc5a6ecebb65899c541be982bcedbdbd', 'list-b04bd12acaf920281611698f0f336e22', 'list-d09f632a7cc1eaa549f10499725803d5', 'list-6aee6140eeb4bd67079d187c5bc00d02', 'list-27fff05a54ba0d8404b24f3e1aaf2936', 'list-83fffaf7a79b79f289210869cf8f109f', 'list-d261870c545ba26c0308bca4a26417eb', 'list-c351dcf1a304650164969236e792fade', 'list-6346636fef289dca3846b7a458c34a54', 'list-0f7c25c7f06506516a021eebe655dc80', 'list-74ecaddc8f4cbe4c48215ab2dbc631f5', 'list-59c6bea0b3a2dbb9d78988233fa5671b', 'list-584c6f525daf80a88746ba3f4bf8718b', 'list-32b1237a853ee0584ca35ea91a913a45', 'list-88766a91c51ad70abc3f0877eac3a913', 'list-52c978338d04a70b88c5089b56f8f4af', 'list-81437d5d79af1f1b6126680dede85706', 'list-028552928c4c19683985a84fcaa71fe5', 'list-89f6e3fabd37aaf17c42ed5d67897f3a', 'list-0f358162e6cc17f0b6cd2d419f1267e8', 'list-6e2f415bcdf8299d9f2193235795d025', 'list-28ac302b58ae5b88c99817732d21c860', 'list-6f22119dabcd7eeb30353f9214afbe3d', 'list-6183dfe7ceb4947cf73485723896b101', 'list-5c1e0850893022a946269b138ddc0388', 'list-6b2aa04bee673dbb7de81fc0a7dba5cc', 'list-d54294c7fad38d6447dc51267fb2b9e6', 'list-4321ed8a918d725796bba004dc043ac2', 'list-dc5e02888ff469cb304a5f287f9a98e2', 'list-6bbdd048bf9e91e3879279140ec1cb87', 'list-1d630d1115d3c68a98c70097daed0fdd', 'list-f5d133c64970efb245804bac085aceb5', 'list-ccde83ffeb2002083e5ade4c8e7a3eb7', 'list-3989da9e159daee5da98cb73a77e2dd3', 'list-280c653b1a9d8253408688a5fe20bf74', 'list-35221370f2b3c89e39c197e0dd8b2b70', 'list-fbb537de65fd140bbb6b4053bb5a50e4', 'list-d97005f7bcc8a3030b0990445e5b4acb', 'list-db6a12b050a28a005b83e40ac25a0459', 'list-cb1e7f2253a24e5d62a32088b93269e1', 'list-4d83a725210848f1d0d03f8f04c69713', 'list-27e0d335f8b53eb445a1b0cdd20f294a', 'list-cd284be57a136e58c7da66c6519ca61f', 'list-399864fde06f13a5e1534c4c465488bc', 'list-1bac53f6ab9e42a1d09cfc3f8fbd4359', 'list-5bbec3b2283fa5f4ecbb56487ebc97a4', 'list-68cc524c8f6f6e2e7f37921a1be900f9', 'list-890a3afb2326ee4100d12f41b4c8af22', 'list-aac423cd117ee705c55041aa7275fa55', 'list-2af02f3ec1a8273e7dfb0d49d18b07ce', 'list-e541fe1a62b6eae17ffa3802bfd2f926', 'list-80b315024719ffae6685be109ece577f', 'list-6f8b5c719c9aaa281869c5ac5efe22e8', 'list-f497b4bf4df3b7bf841a31b3d1370bf3', 'list-8c37b9c1e856efc146067372ec47ff2c', 'list-07790246794478d95778efe161d4c04a', 'list-27e1457a3eaac2f4004c2912984b351d', 'list-dc7080c4a4b8964f15996e739f9fa5da', 'list-1ba7ca181f84739aa81c4df3a4d83eaa', 'list-3f23b12c749f966df0b2f017b5a6d20b', 'list-e5722a75ce6d1093fe979dfff13fb2b6', 'list-73fcb240f7a2bf14bda8f492979ecba9', 'list-3734255f3d5b28f5fa6f4b6e9644363e', 'list-16b9b6e0ea1512bcf8d1df71df2e0800', 'list-4b681ca7cf040ca7d7a2096444cd554d', 'list-3d9b5b84ec6a2c107fe5f3389f3800c7', 'list-0b43e9e677a691e310ab63aa4ae85152', 'list-183aceab779496924ad3dce48926460e', 'list-0a905eae44971a8880a6c2a2cfaad454', 'list-94676d820bfc44388a3550f781738a78', 'list-81fc64c6d3aa0de2769ef2d94ffefbd5', 'list-510980fbe0f2f7ec06a11d46c5517f3b', 'list-5d686479d09aa4d23a4a07fcc1fef91d', 'list-bb046195f55a6571026e8b568209f3b0', 'list-86b9c31f1c060eb491b628ed62d5bbef', 'list-38a25122691e6be4d6c92efa461576b0', 'list-ac574fedb3d5e99361ad683cd7b074f6', 'list-415101dc41ed5a8339607de03b845e69', 'list-9705ed5cd856480ef79dc55959f82a05', 'list-5320b133d508cf58f098278d34ecbbbc', 'list-9398483c017548af70c4c7728c8e04a7', 'list-9a5bd7e25cb680436bb6593a101d4583', 'list-716f2355b5fe894d806a3b6ddf1ec146', 'list-0b1cb3d42962886eb8c51c9ea19fec16', 'list-71a143b3743f0169996153b8069bb1e6', 'list-a1da08e2a5a6f5e8e60a74de1eaf1704', 'list-a9d5b5321fa63daa4160b522fa9bbda1', 'list-a4680fcaa1230804b4ea476e67e6af28', 'list-9727f682d3d748ab41aa2cb451840df1', 'list-11e78d64ff5b845cadb7f3bb9925e76c', 'list-509a54471d5526e46637050ea3e72c1f', 'list-4d15ad236c17b9fb09b70caac7a964e0', 'list-d2b61b8848284cd95d77a8a0adc92d9c', 'list-098c221eeadb7dbde6c2022068dbb5ac', 'list-3cbace97241ff06b3c126818bc567c0d', 'list-2655582c9917ccc8dec29f45dda19b6b', 'list-3f0359fa29486f9bb973eb35f97a1ab5', 'list-d2ee86822279150c55128013dcb47a4c', 'list-f625c696c260b97609014ee7c1d53b5e', 'list-9039d368ec4a37ba09044055fe515f66', 'list-c1bcb71144ac1f2ec230bcd6bfb3f2d6', 'list-e64dee9f503d73c6c4099b79b08ed218', 'list-f4007330543976e9708b65b7950bcbcf', 'list-83832d078e41fb5e44fac0599c9ea7fd', 'list-35bc18c310534b885e9402d74b89e190', 'list-fb70d1c5af7f0e50309fe043184ba857', 'list-5bfc94f341c1733c3cf48dc630ad29e8', 'list-c487b194f398c7e3d5dcb4a559e51dd7', 'list-affdd50eb275790e4d9de6dac39dbf16', 'list-91cd95442d3c4d6d63310cefaf526aa1', 'list-abb70a0df227135e047a967044d5a52c', 'list-002923e0577419abbbf77bbe89d8b4d0', 'list-1ca88cbd511846c15add7e887467b4d2', 'list-c8cd096f22773f60a0c0451b3e856325', 'list-d27d722a5c0bc2e6a6720911e50c8585', 'list-ecd5a29862e4da3246ce44a42778d921', 'list-2030c06d404caa2b917f235932f22be8', 'list-8e16b7ced5d4c02b7dfc6a7d73515a3d', 'list-bbb1200a5cac8dafbacc0039ca8a2977', 'list-e1c6fa0b8d7e9934d86880eb4b5812f3', 'list-a5c56d8e906b86a6863e03a6a4f30b73', 'list-37ba8a85f2e5a99e96f7a63f3037b577', 'list-d495444bfee3852ac28505320498d414', 'list-aeddf8182edf7dff9b18a09d6a57cfea', 'list-d53098050ae32f4894d96cf397fc5220', 'list-1141d0f1911186cbac50caf767d8b3aa', 'list-2e519b8a04e97e31e19dc43e03f479d8', 'list-2be6d36cb3309e453eeee65935404c6c', 'list-cb2a7e0b00bc5ae716108608e5d6606c', 'list-f142285deb862f717f82ae84adea4474', 'list-5ce2f77117fedc3e2e2995e3e7713bf1', 'list-436467fc69cfb63f5a04713c575ddf9a', 'list-725f643b330fd09e40c930a75e5c7e18', 'list-4cc852d8901a93efeec4d62a9a87f7d9', 'list-99eb07cbb29c82ee7504270dd89588be', 'list-79863d6d5498c990bb1aee486a412340', 'list-f4c235a349bea59f8ca43f7ec332dfec', 'list-7394fcd0bdede97f912f2e1595c74803', 'list-eb0bb3070203e95ef9e6e732e15e27f5', 'list-080051115aa89cf8bba2057d5fce3e36', 'list-220a73339baa616829881d4eed8ad7bf', 'list-4aeaa9d6f9500742d2e7374c7112aa0c', 'list-d576cddb308e67236e84b94242843c35', 'list-6659c30fc7bfb3e62eacfc4a54377488', 'list-03631e615f24999567c6824dd1b9e2d3', 'list-e3656d5cd397ff0a11cda70951bedec4', 'list-2c86efcd8c1b960faa7f9fee8130017b', 'list-ad760298dbf77d2ce0a91cb16bbbdc7d', 'list-4cdb1f8bb701f9c712d440d5413d1733', 'list-2205a6c24bbc9408df8661d203f6078b', 'list-934ea03480190373a73a61b88ca71404', 'list-ae0d24c30b714caac35fe21178fbb7b3', 'list-4d9680e4f4d5c2f4dafcd72434a4e369', 'list-e3750fcac68cdb945f0a8784a49a0043', 'list-d6f313d302ede17381815b9771dc0676', 'list-739669b7d8acd25f2cae2991d28acfb6', 'list-cca87c7452db5d0d1cbf22f5482b4981', 'list-43e60a6e6f91e8fbc8681cb164b233e7', 'list-3097d39e02f8db4ff53819d6b7aa81ae', 'list-3ebc62b1cbb79099c8ba799b3a9b7dd1', 'list-4ee6f986e3dfe77daf2164a8a3f38a9d', 'list-e96a71ca129f70658e3a9150ef3043de', 'list-b8a61b75d4e273ccb2b6972556db5d2f', 'list-bab3772f51d4e9ed50d46960ca88d0ad', 'list-efe6531051f78125ff61f87add403a39', 'list-273547fdbac8ee325a023c7c378f2e6c', 'list-fa57c9424785ff7c70f1c158d936a223', 'list-cdd702e5ad532f51b7db9c8335adaf24', 'list-90773460131b85aa0b33c32594209b2f', 'list-70e2ef8cacaf3f8ef9191d7298740be7', 'list-8180e2285952604a3fe4622252a0bdbf', 'list-87ebf04b4aab475193fae03d85ed88f9', 'list-7cb60432c98df2dc85ef08422c015b0f', 'list-19c60bbca1a8e730e4c6e2a011037010', 'list-83aa12eefa427bdd28508caf8718df69', 'list-34339f2cb58c0df814ed4442520c5acc', 'list-764a88650e5c2cb8e888a34358d72a8c', 'list-2849421c76fcbb3d091196963943d695', 'list-3587e9a0a8c06dacdf2171c22d58a4bb', 'list-3c360fa6ccfb8050007c2832afdbea77', 'list-e7fb0c264558d89f10000118cc382df7', 'list-6b82fd2f033869d74b39b6c2244cc6ac', 'list-a909a35f50607c92f0f49cbb8fb220ba', 'list-347a79f286ea9ad1e32065ddbf85850e', 'list-999313f3eb3e200bcf653aa4b283b24f', 'list-e1e78021b7589ac5a8f6b2fe02b323fb', 'list-a01c4c0b93b89dc839de84ee3accc462', 'list-8e249d378901dfd28050332e1ffa4a1b', 'list-3d969f75c12df11c5926ecad51125e61', 'list-0b3991103fa8532ea7207592676e0e4c', 'list-0beb192996cbfd461aad4fed1b1affa7', 'list-489e24eba0485552f222849286b14593', 'list-bb6280c26d16a2c6eb4ab673262d34a9', 'list-feec406f29d6838ce64feb09fb086483', 'list-776f40b486258ed2c66adf5eda04246f', 'list-c5c431208a68ede0731dc5773fe50899', 'list-0bb90ae9219ea5b13ed971b769bb834a', 'list-427c3139edb9d64cead82d910661ca68', 'list-d4086794270f0235be5fbaa99cd437ce', 'list-0d10b06c83b31640ba916b0a48c8ebc5', 'list-c915f363bdd4f1dbe97e51192df2c0a6', 'list-b36c6e2111da33b7eb3d2f726545c59c', 'list-1a71f14448b8c5936a8ba512645b1139', 'list-3537ce7ef9a408dcf2818e82e47f4a8e', 'list-3d86307664f9884eb1851575bd9d8f7e', 'list-981ad491d03c784bf4667b68be5dba9f', 'list-8e3446a9555f8469b03fa381d5108873'} (stimulus_id='handle-worker-cleanup-1725667246.322488')\n"
     ]
    },
    {
     "ename": "FutureCancelledError",
     "evalue": "train_model-b5bdfd1ef1d23484a812e324257e220e cancelled for reason: unknown.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFutureCancelledError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 237\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the length of the EVAL completed_eval_futures var \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(completed_eval_futures)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    236\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the size of completed_train_futures \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(completed_train_futures)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and this is the size of completed_eval_futures \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(completed_eval_futures)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 237\u001b[0m \u001b[43mprocess_completed_futures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompleted_train_futures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompleted_eval_futures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOG_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m progress_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(done))\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# Handle failed futures using the previously defined function\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 51\u001b[0m, in \u001b[0;36mprocess_completed_futures\u001b[1;34m(completed_train_futures, completed_eval_futures, log_dir)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m completed_eval_futures:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;66;03m# Retrieve the result of the training future\u001b[39;00m\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;66;03m#if isinstance(future.result(), list):\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m         models_data \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# This should be a list of dictionaries\u001b[39;00m\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(models_data, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     53\u001b[0m             models_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(future\u001b[38;5;241m.\u001b[39mresult())  \u001b[38;5;66;03m# This should be a list of dictionaries\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\client.py:401\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_initialized()\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\client.py:417\u001b[0m, in \u001b[0;36mFuture._result\u001b[1;34m(self, raiseit)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exception, CancelledError)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raiseit:\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exception\n",
      "\u001b[1;31mFutureCancelledError\u001b[0m: train_model-b5bdfd1ef1d23484a812e324257e220e cancelled for reason: unknown."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 20:01:17,092 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:52261\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils.py\", line 1923, in wait_for\n",
      "    return await fut\n",
      "           ^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\tcp.py\", line 546, in connect\n",
      "    stream = await self.client.connect(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\tornado\\tcpclient.py\", line 279, in connect\n",
      "    af, addr, stream = await connector.start(connect_timeout=timeout)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 342, in connect\n",
      "    comm = await wait_for(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\utils.py\", line 1922, in wait_for\n",
      "    async with asyncio.timeout(timeout):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\asyncio\\timeouts.py\", line 111, in __aexit__\n",
      "    raise TimeoutError from exc_val\n",
      "TimeoutError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1481, in connect\n",
      "    return await self._connect(addr=addr, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pqn7\\.conda\\envs\\lda\\Lib\\site-packages\\distributed\\comm\\core.py\", line 368, in connect\n",
      "    raise OSError(\n",
      "OSError: Timed out trying to connect to tcp://127.0.0.1:52261 after 30 s\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    cluster = LocalCluster(\n",
    "            n_workers=CORES,\n",
    "            threads_per_worker=THREADS_PER_CORE,\n",
    "            processes=False,\n",
    "            memory_limit=RAM_MEMORY_LIMIT,\n",
    "            local_directory=DASK_DIR,\n",
    "            #dashboard_address=None,\n",
    "            dashboard_address=\":8787\",\n",
    "            protocol=\"tcp\",\n",
    "    )\n",
    "\n",
    "\n",
    "    # Create the distributed client\n",
    "    client = Client(cluster)\n",
    "\n",
    "    client.cluster.adapt(minimum=CORES, maximum=MAXIMUM_CORES)\n",
    "    \n",
    "    # Get information about workers from scheduler\n",
    "    workers_info = client.scheduler_info()[\"workers\"]\n",
    "\n",
    "    # Iterate over workers and set their memory limits\n",
    "    for worker_id, worker_info in workers_info.items():\n",
    "        worker_info[\"memory_limit\"] = RAM_MEMORY_LIMIT\n",
    "\n",
    "    # Verify that memory limits have been set correctly\n",
    "    #for worker_id, worker_info in workers_info.items():\n",
    "    #    print(f\"Worker {worker_id}: Memory Limit - {worker_info['memory_limit']}\")\n",
    "\n",
    "    # Check if the Dask client is connected to a scheduler:\n",
    "    if client.status == \"running\":\n",
    "        print(\"Dask client is connected to a scheduler.\")\n",
    "        # Scatter the embedding vectors across Dask workers\n",
    "    else:\n",
    "        print(\"Dask client is not connected to a scheduler.\")\n",
    "        print(\"The system is shutting down.\")\n",
    "        client.close()\n",
    "        cluster.close()\n",
    "        sys.exit()\n",
    "\n",
    "    # Check if Dask workers are running:\n",
    "    if len(client.scheduler_info()[\"workers\"]) > 0:\n",
    "        print(\"Dask workers are running.\")\n",
    "    else:\n",
    "        print(\"No Dask workers are running.\")\n",
    "        print(\"The system is shutting down.\")\n",
    "        client.close()\n",
    "        cluster.close()\n",
    "        sys.exit()\n",
    "\n",
    "    print(\"Creating training and evaluation samples...\")\n",
    "    \n",
    "    started = time()\n",
    "    \n",
    "    scattered_train_data_futures = []\n",
    "    scattered_eval_data_futures = []\n",
    "\n",
    "    total_num_samples = get_num_records(DATA_SOURCE)\n",
    "\n",
    "    whole_train_dataset = None\n",
    "    whole_eval_dataset = None\n",
    "\n",
    "    with tqdm(total=total_num_samples) as pbar:\n",
    "        # Process each batch as it is generated\n",
    "        for batch_info in futures_create_lda_datasets(DATA_SOURCE, TRAIN_RATIO):\n",
    "            if batch_info['type'] == 'train':\n",
    "                # Handle training data\n",
    "                #print(\"We are inside the IF/ELSE block for producing TRAIN scatter.\")\n",
    "                try:\n",
    "                    scattered_future = client.scatter(batch_info['data'])\n",
    "                    scattered_train_data_futures.append(scattered_future)\n",
    "                except Exception as e:\n",
    "                    print(\"there was an issue with creating the TRAIN scattered_future list\")\n",
    "                \n",
    "                if whole_train_dataset is None:\n",
    "                    whole_train_dataset = batch_info['whole_dataset']\n",
    "            elif batch_info['type'] == 'eval':\n",
    "                # Handle evaluation data\n",
    "                #print(\"We are inside the IF/ELSE block for producing EVAL scatter.\")\n",
    "                try:\n",
    "                    scattered_future = client.scatter(batch_info['data'])\n",
    "                    scattered_eval_data_futures.append(scattered_future)\n",
    "                except Exception as e:\n",
    "                    print(\"there was an issue with creating the EVAL scattererd_future list.\")\n",
    "                    print(e)\n",
    "                    \n",
    "                \n",
    "                if whole_eval_dataset is None:\n",
    "                    whole_eval_dataset = batch_info['whole_dataset']\n",
    "\n",
    "            # Update the progress bar with the cumulative count of samples processed\n",
    "            #pbar.update(batch_info['cumulative_count'] - pbar.n)\n",
    "            pbar.update(len(batch_info['data']))\n",
    "\n",
    "        pbar.close()  # Ensure closure of the progress bar\n",
    "\n",
    "    print(f\"Completed creation of training and evaluation documents in {round((time() - started)/60,2)} minutes.\\n\")\n",
    "   \n",
    "    print(\"Data scatter complete...\\n\")\n",
    "    #garbage_collection(False, 'scattering training and eval data')\n",
    "    #del scattered_future\n",
    "    #del whole_train_dataset, whole_eval_dataset # these variables are not used at all\n",
    "\n",
    "    train_futures = []  # List to store futures for training\n",
    "    eval_futures = []  # List to store futures for evaluation\n",
    "   \n",
    "    num_topics = len(range(START_TOPICS, END_TOPICS + 1, STEP_SIZE))\n",
    "    num_alpha_values = len(alpha_values)\n",
    "    num_beta_values = len(beta_values)\n",
    "\n",
    "    TOTAL_MODELS = (num_topics * num_alpha_values * num_beta_values) * 2\n",
    "\n",
    "    #progress_bar = tqdm(total=TOTAL_MODELS, desc=\"Creating and saving models\")\n",
    "\n",
    "    train_eval = ['eval', 'train']\n",
    "\n",
    "    # Create a list of all combinations of n_topics, alpha_value, beta_value, and train_eval\n",
    "    combinations = list(itertools.product(range(START_TOPICS, END_TOPICS + 1, STEP_SIZE), alpha_values, beta_values, train_eval))\n",
    "\n",
    "    # Separate the combinations into two lists based on 'train' and 'eval'\n",
    "    train_combinations = [combo for combo in combinations if combo[-1] == 'train']\n",
    "    eval_combinations = [combo for combo in combinations if combo[-1] == 'eval']\n",
    "\n",
    "    # Calculate the sample size for each category\n",
    "    sample_size = min(len(train_combinations), len(eval_combinations))\n",
    "\n",
    "    # Select random combinations from each category\n",
    "    random_train_combinations = random.sample(train_combinations, sample_size)\n",
    "    random_eval_combinations = random.sample(eval_combinations, sample_size)\n",
    "\n",
    "    # Combine the randomly selected train and eval combinations\n",
    "    random_combinations = random_eval_combinations+ random_train_combinations\n",
    "    sample_size = max(1, int(len(combinations) * 0.375))\n",
    "\n",
    "    # Select random_combinations conditionally\n",
    "    random_combinations = random.sample(combinations, sample_size) if sample_size < len(combinations) else combinations\n",
    "    progress_bar = tqdm(total=len(random_combinations), desc=\"Creating and saving models\")\n",
    "    print(f\"The random sample combinations contains {len(random_combinations)}\")\n",
    "\n",
    "    # Determine which combinations were not drawn by using set difference\n",
    "    undrawn_combinations = list(set(combinations) - set(random_combinations))\n",
    "\n",
    "    print(f\"this leaves {len(undrawn_combinations)} remaining\\n\")\n",
    "\n",
    "    # Create empty lists to store all future objects for training and evaluation\n",
    "    train_futures = []\n",
    "    eval_futures = []\n",
    "    \n",
    "    # Convert total memory from GB to bytes (1 GB = 1024^3 bytes)\n",
    "    TOTAL_MEMORY_BYTES = 128 * (1024 ** 3)\n",
    "\n",
    "    # Iterate over the combinations and submit tasks\n",
    "    for n_topics, alpha_value, beta_value, train_eval_type in random_combinations:\n",
    "\n",
    "        # determine if throttling is needed\n",
    "        logging.info(\"\\nEvaluating if adaptive throttling is necessary (method exponential backoff)...\")\n",
    "        started, throttle_attempt = time(), 0\n",
    "\n",
    "        while throttle_attempt < MAX_RETRIES and not all(worker['metrics']['cpu'] < CPU_UTILIZATION_THRESHOLD for worker in client.scheduler_info()['workers'].values()):\n",
    "            logging.info(f\"Adaptive throttling (attempt {throttle_attempt} of {MAX_RETRIES-1}\")\n",
    "            #logging.info(f\"for LdaModel hyperparameters combination -- type: {train_eval_type}, topic: {n_topics}, ALPHA: {alpha_value} and ETA {beta_value}\")\n",
    "            sleep(exponential_backoff(throttle_attempt))\n",
    "            throttle_attempt += 1\n",
    "\n",
    "        logging.info(f\"Adaptive throttling (method: exponential backoff) {'completed in {:.2f} seconds'.format(time() - started) if throttle_attempt else 'was not necessary...'}\\n\")\n",
    "\n",
    "        #logging.info(f\"for LdaModel hyperparameters combination -- type: {train_eval_type}, topic: {n_topics}, ALPHA: {alpha_value} and ETA {beta_value}\")\n",
    "        # Submit a future for each scattered data object in the training list\n",
    "        #if train_eval_type == 'train':\n",
    "        # Submit a future for each scattered data object in the training list\n",
    "        for scattered_data in scattered_train_data_futures:\n",
    "            future = client.submit(train_model, n_topics, alpha_value, beta_value, scattered_data, 'train')\n",
    "            train_futures.append(future)\n",
    "            logging.info(f\"The training value is being appended to the train_futures list. Size: {len(train_futures)}\")\n",
    "\n",
    "        # Submit a future for each scattered data object in the evaluation list\n",
    "        #if train_eval_type == 'eval':\n",
    "        for scattered_data in scattered_eval_data_futures:\n",
    "            future = client.submit(train_model, n_topics, alpha_value, beta_value, scattered_data, 'eval')\n",
    "            eval_futures.append(future)\n",
    "            logging.info(f\"The evaluation value is being appended to the eval_futures list. Size: {len(eval_futures)}\")\n",
    "        #garbage_collection(False, 'client.submit(train_model(...) train and eval)')\n",
    "\n",
    "\n",
    "        # Map the created futures to their parameters so we can identify them later if needed\n",
    "        for future in train_futures:\n",
    "            future_to_params[future] = ('train',n_topics, alpha_value, beta_value)\n",
    "\n",
    "        # Do the same for eval_futures\n",
    "        for future in eval_futures:\n",
    "            future_to_params[future] = ('eval', n_topics, alpha_value, beta_value)\n",
    "\n",
    "        #train_futures.append(all_train_futures)\n",
    "        #eval_futures.append(all_eval_futures)\n",
    "        #print(f\"This is the size of the eval_futures {len(eval_futures)}\")\n",
    "        #print(f\"this is the eval futures: {eval_futures}\\n\\n\")\n",
    "            \n",
    "        # Check if it's time to process futures based on BATCH_SIZE\n",
    "        #if int(len(train_futures)/3) >= (BATCH_SIZE % 10):\n",
    "        train_eval_count = train_futures + eval_futures\n",
    "        if int(len(train_eval_count)) >= (BATCH_SIZE % 10):\n",
    "            print(\"In holding pattern until WAIT completes.\")\n",
    "            started = time()\n",
    "                \n",
    "            #done, not_done = wait(train_futures + eval_futures, timeout=None)        # Wait for all reattempted futures with an extended timeout (e.g., 120 seconds)\n",
    "\n",
    "            # Process completed ones after reattempting\n",
    "            #done_train = [f for f in done if f in train_futures]\n",
    "            #done_eval = [f for f in done if f in eval_futures]\n",
    "            # Wait for completion of eval_futures\n",
    "            done_eval, not_done_eval = wait(eval_futures, timeout=None)  # return_when='FIRST_COMPLETED'\n",
    "            print(f\"This is the size of the done_eval list: {len(done_eval)} and this is the size of the not_done_eval list: {len(not_done_eval)}\")\n",
    "\n",
    "            # Wait for completion of train_futures\n",
    "            done_train, not_done_train = wait(train_futures, timeout=None)  # return_when='FIRST_COMPLETED'\n",
    "            print(f\"This is the size of the done_train list: {len(done_train)} and this is the size of the not_done_train list: {len(not_done_train)}\")\n",
    "\n",
    "            done = done_train.union(done_eval)\n",
    "            not_done = not_done_eval.union(not_done_train)\n",
    "                \n",
    "            elapsed_time = round(((time() - started) / 60), 2)\n",
    "            print(f\"WAIT completed in {elapsed_time} minutes\")\n",
    "            print(f\"This is the size of DONE {len(done)}. And this is the size of NOT_DONE {len(not_done)}\\n\")\n",
    "            #print(f\"this is the value of done_train {done_train}\")\n",
    "\n",
    "            completed_train_futures = [f for f in done_train]\n",
    "            print(f\"We have completed the TRAIN list comprehension. The size is {len(completed_train_futures)}\")\n",
    "            print(f\"This is the length of the TRAIN completed_train_futures var {len(completed_train_futures)}\")\n",
    "            \n",
    "            completed_eval_futures = [f for f in done_eval]\n",
    "            print(f\"We have completed the EVAL list comprehension. The size is {len(completed_eval_futures)}\")\n",
    "            print(f\"This is the length of the EVAL completed_eval_futures var {len(completed_eval_futures)}\")\n",
    "\n",
    "            logging.info(f\"This is the size of completed_train_futures {len(completed_train_futures)} and this is the size of completed_eval_futures {len(completed_eval_futures)}\")\n",
    "            process_completed_futures(completed_train_futures, completed_eval_futures, LOG_DIR)\n",
    "            progress_bar.update(len(done))\n",
    "\n",
    "            # Handle failed futures using the previously defined function\n",
    "            for future in not_done:\n",
    "                failed_future_timer = time()\n",
    "                print(\"Handling of failed future method has been initiated.\")\n",
    "                handle_failed_future(future, future_to_params, train_futures,  eval_futures, client)\n",
    "                elapsed_time = round(((time() - started) / 60), 2)\n",
    "                print(f\"It took {elapsed_time} minutes to handle the failed future.\")\n",
    "\n",
    "\n",
    "            # If no tasks are pending (i.e., all have been processed), consider increasing BATCH_SIZE.\n",
    "            completed_tasks = 0\n",
    "            completed_tasks += len(done_train) + len(done_eval)\n",
    "\n",
    "            # If no tasks are pending (i.e., all have been processed), consider increasing BATCH_SIZE.\n",
    "            if completed_tasks >= len(train_futures) + len(eval_futures):\n",
    "                BATCH_SIZE = int(math.ceil(BATCH_SIZE * INCREASE_FACTOR)) if int(math.ceil(BATCH_SIZE * INCREASE_FACTOR)) < MAX_BATCH_SIZE else MAX_BATCH_SIZE\n",
    "                print(f\"Increasing batch size to {BATCH_SIZE}\")\n",
    "\n",
    "            # If there are any tasks that were not done, consider decreasing BATCH_SIZE.\n",
    "            else:\n",
    "                BATCH_SIZE = max(1, int(BATCH_SIZE * DECREASE_FACTOR)) if max(1, int(BATCH_SIZE * DECREASE_FACTOR)) > 0 else BATCH_SIZE\n",
    "                print(f\"Decreasing batch size to {BATCH_SIZE}\")\n",
    "\n",
    "            # reset lists to empty for next iteration of models\n",
    "            train_futures.clear()\n",
    "            eval_futures.clear()\n",
    "\n",
    "            #defensive programming to ensure utility model lists are empty\n",
    "            done.clear()\n",
    "            not_done.clear()\n",
    "            done_train.clear()\n",
    "            done_eval.clear()\n",
    "            not_done_eval.clear()\n",
    "            not_done_train.clear()\n",
    "         \n",
    "    #garbage_collection(False, \"Cleaning WAIT -> done, not_done\")     \n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # After all loops have finished running...\n",
    "    if len(train_futures) > 0 or len(eval_futures) > 0:\n",
    "        print(\"we are in the first IF statement for retry_processing()\")\n",
    "        retry_processing(train_futures, eval_futures, TIMEOUT)\n",
    "\n",
    "\n",
    "    # Now give one more chance with extended timeout only to those that were incomplete previously\n",
    "    if len(failed_model_params) > 0:\n",
    "        print(\"Retrying incomplete models with extended timeout...\")\n",
    "        \n",
    "        # Create new lists for retrying futures\n",
    "        retry_train_futures = []\n",
    "        retry_eval_futures = []\n",
    "\n",
    "        # Resubmit tasks only for those that failed in the first attempt\n",
    "        for params in failed_model_params:\n",
    "            n_topics, alpha_value, beta_value = params\n",
    "            \n",
    "            with performance_report(filename=PERFORMANCE_TRAIN_LOG):\n",
    "                future_train_retry = client.submit(train_model, n_topics, alpha_value, beta_value, scattered_train_data_futures, 'train')\n",
    "                future_eval_retry = client.submit(train_model, n_topics, alpha_value, beta_value, scattered_eval_data_futures, 'eval')\n",
    "\n",
    "            retry_train_futures.append(future_train_retry)\n",
    "            retry_eval_futures.append(future_eval_retry)\n",
    "\n",
    "            # Keep track of these new futures as well\n",
    "            future_to_params[future_train_retry] = params\n",
    "            future_to_params[future_eval_retry] = params\n",
    "\n",
    "        # Clear the list of failed model parameters before reattempting\n",
    "        failed_model_params.clear()\n",
    "\n",
    "        # Wait for all reattempted futures with an extended timeout (e.g., 120 seconds)\n",
    "        done, not_done = wait(retry_train_futures + retry_eval_futures ) #, timeout=EXTENDED_TIMEOUT)\n",
    "\n",
    "        # Process completed ones after reattempting\n",
    "        process_completed_futures([f for f in done if f in retry_train_futures],\n",
    "                                [f for f in done if f in retry_eval_futures],\n",
    "                                LOG_DIR)\n",
    "        \n",
    "        progress_bar.update(len(done))\n",
    "\n",
    "        # Record parameters of still incomplete futures after reattempting for later review\n",
    "        for future in not_done:\n",
    "            failed_model_params.append(future_to_params[future])\n",
    "\n",
    "        # At this point `failed_model_params` contains the parameters of all models that didn't complete even after a retry\n",
    "\n",
    "    #client.close()\n",
    "    print(\"The training and evaluation loop has completed.\")\n",
    "\n",
    "    if len(failed_model_params) > 0:\n",
    "        # You can now review `failed_model_params` to see which models did not complete successfully.\n",
    "        logging.error(\"The following model parameters did not complete even after a second attempt:\")\n",
    "    #    perf_logger.info(\"The following model parameters did not complete even after a second attempt:\")\n",
    "        for params in failed_model_params:\n",
    "            logging.error(params)\n",
    "    #        perf_logger.info(params)\n",
    "            \n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided code snippet is part of a larger program that appears to be running machine learning model training and evaluation tasks in parallel using Dask, a flexible parallel computing library for analytic computing. The code manages the execution of these tasks, handling retries for incomplete tasks, and tracking failures.\n",
    "\n",
    "The script begins by initializing an empty list called failed_model_params to store the parameters of models that fail to complete even after a retry. It also creates a dictionary named future_to_params to map \"futures\" (a representation of an asynchronous execution) to their corresponding model parameters.\n",
    "\n",
    "Two functions are defined: process_completed_futures, which processes completed futures, and retry_processing, which attempts to reprocess incomplete futures with an extended timeout period.\n",
    "\n",
    "The main part of the script sets up multiple training and evaluation tasks across different combinations of hyperparameters (n_topics, alpha_value, and beta_value). These tasks are submitted to a Dask client asynchronously using the client.submit method. Each task returns a future, which is then mapped to its parameters in the future_to_params dictionary for later reference.\n",
    "\n",
    "The script uses batch processing controlled by a variable called BATCH_SIZE. Once enough futures have been accumulated, or when all loops have finished running, it waits for all futures within each batch to complete using Dask's wait function with a specified timeout (TIMEOUT). Completed futures are processed while those that remain incomplete are recorded in the failed_model_params list for further action.\n",
    "\n",
    "After processing each batch, if there are any remaining futures (either from incomplete batches or from the final iteration), they are retried using the previously defined retry_processing function with the same timeout value.\n",
    "\n",
    "If there are still models that failed after this first attempt, they get one more chance. The script prints out a message indicating it will retry these incomplete models with an extended timeout (EXTENDED_TIMEOUT). It resubmits these tasks and waits again for completion. Any models that remain incomplete after this second attempt are added back into the failed_model_params.\n",
    "\n",
    "Finally, once all retries have been exhausted and progress has been tracked via a progress bar (tqdm), the Dask client is closed. The script prints out and logs information about any model parameters that did not complete successfully even after two attempts.\n",
    "\n",
    "In summary, this code automates the process of submitting parallelized machine learning training and evaluation jobs over various hyperparameter combinations, handles timeouts by retrying incomplete jobs,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pa\n",
    "\n",
    "# Uncomment the next two lines if you want to view the file's schema.\n",
    "# parquetFile = pa.ParquetFile('test.parquet')\n",
    "# print(parquetFile.schema)\n",
    "\n",
    "df = pd.read_parquet(r'C:\\_harvester\\data\\lda-models\\2010s_html\\metadata\\metadata.parquet')\n",
    "df.to_csv(r'C:\\_harvester\\data\\lda-models\\2010s_html\\metadata\\metadata.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
